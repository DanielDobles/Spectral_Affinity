{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity: GPU-Accelerated Mastering & Curation 2.2\n",
                "### *\"The Ultimate AI Librarian for Camelot-based Flow + High-Speed GPU Analysis\"*\n",
                "\n",
                "Este cuaderno utiliza la **GPU de Kaggle** para acelerar dr√°sticamente el an√°lisis de audio y procesa el **Mastering (Matchering 2.0)** en paralelo utilizando m√∫ltiples n√∫cleos de CPU.\n",
                "\n",
                "**La Soluci√≥n Acelerada:**\n",
                "1. üß† **GPU Neural Analysis**: Key, BPM y Energ√≠a calculados en r√°fagas de 32 temas usando **Wav2Vec2 (MERT)** y **CQT** en CUDA.\n",
                "2. üéöÔ∏è **Parallel Mastering**: Ejecuci√≥n de Matchering 2.0 en paralelo (multi-threading) para triplicar la velocidad de exportaci√≥n.\n",
                "3. üîÄ **BPM-Harmonic Flow**: Secuenciaci√≥n autom√°tica de menos a m√°s BPM siguiendo la Rueda de Camelot.\n",
                "4. üìÇ **Auto-Organization**: Organizaci√≥n instant√°nea en carpetas por estilos sem√°nticos.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üõ†Ô∏è High-Speed Setup\n",
                "try:\n",
                "    import matchering as mg\n",
                "except:\n",
                "    !pip install -q transformers torch torchaudio nnAudio librosa pandas scikit-learn tqdm matchering soundfile\n",
                "\n",
                "import os, torch, torchaudio, librosa, shutil, json, time, warnings, re\n",
                "import numpy as np; import pandas as pd\n",
                "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
                "from tqdm.auto import tqdm\n",
                "import torchaudio.transforms as T\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
                "from sklearn.preprocessing import normalize; from sklearn.cluster import KMeans\n",
                "from IPython.display import display, FileLink, HTML\n",
                "import matchering as mg\n",
                "\n",
                "warnings.filterwarnings(\"ignore\"); os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "SAMPLE_RATE = 24000\n",
                "MAX_WORKERS = os.cpu_count() or 4 # Para el mastering paralelo\n",
                "print(f\"üåå GPU ACCELERATION: {DEVICE.upper()} ACTIVE\")\n",
                "print(f\"‚öôÔ∏è CPU CORES FOR MASTERING: {MAX_WORKERS}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† 1. Motor de An√°lisis Neuronal (GPU Power)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CAMELOT_MAP = {\n",
                "    'C Major': '08B', 'C# Major': '03B', 'D Major': '10B', 'D# Major': '05B', 'E Major': '12B', 'F Major': '07B',\n",
                "    'F# Major': '02B', 'G Major': '09B', 'G# Major': '04B', 'A Major': '11B', 'A# Major': '06B', 'B Major': '01B',\n",
                "    'C Minor': '05A', 'C# Minor': '12A', 'D Minor': '07A', 'D# Minor': '02A', 'E Minor': '09A', 'F Minor': '04A',\n",
                "    'F# Minor': '11A', 'G Minor': '06A', 'G# Minor': '01A', 'A Minor': '08A', 'A# Minor': '03A', 'B Minor': '10A'\n",
                "}\n",
                "\n",
                "class NeuralAnalyzer:\n",
                "    def __init__(self, device='cuda'):\n",
                "        from nnAudio.Spectrogram import CQT1992v2\n",
                "        self.device = device\n",
                "        self.cqt = CQT1992v2(sr=SAMPLE_RATE, n_bins=84, bins_per_octave=12, verbose=False).to(device)\n",
                "        self.proc = Wav2Vec2FeatureExtractor.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True)\n",
                "        self.mert = AutoModel.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True).to(device).eval()\n",
                "        major = torch.tensor([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], device=device)\n",
                "        minor = torch.tensor([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major,i) for i in range(12)] + [torch.roll(minor,i) for i in range(12)]).t()\n",
                "        self.resampler = T.Resample(orig_freq=44100, new_freq=SAMPLE_RATE).to(device) # Resampler base GPU\n",
                "\n",
                "    def analyze_batch(self, paths):\n",
                "        def load_one(p):\n",
                "            try:\n",
                "                w, s = torchaudio.load(p)\n",
                "                # Pre-resample r√°pido si es posible, o normalizamos en batch\n",
                "                return w.mean(0), s, os.path.basename(p), p\n",
                "            except: return None\n",
                "\n",
                "        with ThreadPoolExecutor(max_workers=8) as pl: results = list(pl.map(load_one, paths))\n",
                "        valid = [r for r in results if r is not None]\n",
                "        if not valid: return []\n",
                "\n",
                "        # Procesamiento de audio en GPU para an√°lisis\n",
                "        batch_waves = []\n",
                "        for w, s, fname, fpath in valid:\n",
                "            w_gpu = w.to(self.device)\n",
                "            if s != SAMPLE_RATE:\n",
                "                # Resampling en GPU\n",
                "                r = T.Resample(s, SAMPLE_RATE).to(self.device)\n",
                "                w_gpu = r(w_gpu)\n",
                "            batch_waves.append(w_gpu)\n",
                "\n",
                "        m_len = max([w.shape[0] for w in batch_waves])\n",
                "        t = torch.zeros(len(batch_waves), m_len, device=self.device)\n",
                "        for i, w in enumerate(batch_waves): t[i, :w.shape[0]] = w\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt(t)\n",
                "            energy = spec.pow(2).mean(dim=(1,2)).cpu().numpy()\n",
                "            chroma = spec.view(len(batch_waves), 7, 12, -1).sum(dim=(1,3))\n",
                "            chroma = chroma / (chroma.norm(dim=1,keepdim=True)+1e-6)\n",
                "            best = torch.argmax(torch.matmul(chroma, self.profiles), dim=1).cpu().numpy()\n",
                "            \n",
                "            embs = []\n",
                "            for i in range(len(batch_waves)):\n",
                "                sl = int(SAMPLE_RATE*15); s = batch_waves[i][:sl].cpu().numpy()\n",
                "                iv = self.proc(s, sampling_rate=SAMPLE_RATE, return_tensors='pt').input_values.to(self.device)\n",
                "                embs.append(self.mert(iv).last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist())\n",
                "\n",
                "        pc = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
                "        batch_meta = []\n",
                "        for i, (w_orig, s_orig, fname, fpath) in enumerate(valid):\n",
                "            k = pc[best[i]%12]; m = 'Major' if best[i]<12 else 'Minor'\n",
                "            # BPM en CPU (librosa es muy preciso para esto)\n",
                "            y_np = batch_waves[i][:SAMPLE_RATE*45].cpu().numpy()\n",
                "            tp, _ = librosa.beat.beat_track(y=y_np, sr=SAMPLE_RATE)\n",
                "            batch_meta.append({\n",
                "                'path': fpath, 'file': fname, 'camelot': CAMELOT_MAP.get(f\"{k} {m}\", \"08A\"),\n",
                "                'bpm': int(round(tp.item() if hasattr(tp, 'item') else tp)),\n",
                "                'energy': float(energy[i]), 'duration': len(batch_waves[i])/SAMPLE_RATE, 'embedding': embs[i]\n",
                "            })\n",
                "        return batch_meta"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéöÔ∏è 2. Parallel Mastering Engine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def apply_mastering_worker(target, reference, output_path):\n",
                "    \"\"\"Worker individual para Matchering.\"\"\"\n",
                "    try:\n",
                "        mg.process(target=target, reference=reference, results=[mg.pcm24(output_path)])\n",
                "        return True\n",
                "    exceptException as e:\n",
                "        print(f\"  ‚ö†Ô∏è Error: {e}\")\n",
                "        return False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÄ 3. L√≥gica de Flujo Arm√≥nico"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(c):\n",
                "    n, a = int(c[:2]), c[2]\n",
                "    return [f'{str(n).zfill(2)}{a}', f'{str((n%12)+1).zfill(2)}{a}', f'{str(((n-2)%12)+1).zfill(2)}{a}', f\"{str(n).zfill(2)}{'A' if a=='B' else 'B'}\"]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target_dur_sec=3600):\n",
                "    if not tracks: return []\n",
                "    pool = sorted(tracks, key=lambda x: x['bpm'])\n",
                "    cur = pool.pop(0); ordered = [cur]; dur = cur['duration']\n",
                "    while pool and dur < target_dur_sec:\n",
                "        ck = get_next_harmonic(cur['camelot'])\n",
                "        idx = next((i for i,t in enumerate(pool) if t['camelot'] in ck or t['camelot']==cur['camelot']), 0)\n",
                "        nxt = pool.pop(idx); ordered.append(nxt); dur += nxt['duration']; cur = nxt\n",
                "    return ordered, pool\n",
                "\n",
                "def clean_name(n): return re.sub(r'[\\-\\_\\.]+?', ' ', re.sub(r'^[\\w\\-]+?-', '', os.path.basename(n).rsplit('.',1)[0])).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ 4. Lanzamiento del Motor (GPU + Parallel CPU)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_DIR = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "if not os.path.exists(INPUT_DIR): INPUT_DIR = 'Slavic Data_Set'\n",
                "REF_FILE = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUT_DIR = '/kaggle/working/MASTERED_CURATION_RESULTS'\n",
                "SET_DURATION = 60 * 60; N_GROUPS = 3\n",
                "\n",
                "os.makedirs(OUT_DIR, exist_ok=True)\n",
                "files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(('.mp3','.wav','.flac')) and 'REF' not in f.upper() ]\n",
                "\n",
                "print(f\"üß† Analizando {len(files)} temas en GPU...\")\n",
                "analyzer = NeuralAnalyzer(device=DEVICE)\n",
                "library = []\n",
                "for i in tqdm(range(0, len(files), 32)): library.extend(analyzer.analyze_batch(files[i:i+32]))\n",
                "\n",
                "print(\"üîç Clustering Sem√°ntico...\")\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "clusters = {i: [library[j] for j,l in enumerate(KMeans(n_clusters=N_GROUPS, n_init=10).fit_predict(X)) if l==i] for i in range(N_GROUPS)}\n",
                "\n",
                "print(f\"\\n‚ö° MASTERING PARALELO EN CPU ({MAX_WORKERS} canciones simult√°neas)...\")\n",
                "for ci, tracks in clusters.items():\n",
                "    group_name = f'Group_{chr(65+ci)}'; pool = tracks; set_idx = 1\n",
                "    while pool:\n",
                "        set_dir = os.path.join(OUT_DIR, group_name, f'Set_{set_idx}'); os.makedirs(set_dir, exist_ok=True)\n",
                "        oset, pool = sequence_chromatic_set(pool, SET_DURATION)\n",
                "        \n",
                "        # Tareas para el pool paralelo\n",
                "        master_tasks = []\n",
                "        for j, t in enumerate(oset):\n",
                "            out_name = f\"{str(j+1).zfill(2)} - [{t['camelot']}] {t['bpm']}BPM {clean_name(t['path'])}.wav\"\n",
                "            master_tasks.append((t['path'], REF_FILE, os.path.join(set_dir, out_name)))\n",
                "        \n",
                "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
                "            futures = [executor.submit(apply_mastering_worker, *task) for task in master_tasks]\n",
                "            list(tqdm(as_completed(futures), total=len(futures), desc=f\"Mastering {group_name} Set {set_idx}\", leave=False))\n",
                "        set_idx += 1\n",
                "\n",
                "shutil.make_archive('SPECTRAL_AFFINITY_MASTERED', 'zip', OUT_DIR)\n",
                "display(HTML(f\"<h3>üöÄ <a href='SPECTRAL_AFFINITY_MASTERED.zip'>DESCARGAR LIBRER√çA MASTERIZADA</a></h3>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}