{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Spectral Affinity: GPU-Accelerated Neural Mixer\n",
                "\n",
                "This edition is engineered for **Extreme Performance** using **GPU Acceleration** and **Parallel Batch Processing**.\n",
                "\n",
                "**âš¡ Upgrades:**\n",
                "- **GPU DSP (nnAudio):** Uses your Graphics Card (CUDA) to calculate CQT Spectrograms instantly.\n",
                "- **Parallel I/O:** Loads files in background threads while the GPU crunches numbers.\n",
                "- **Batch Processing:** Analyzes multiple songs simultaneously (Matrix operations).\n",
                "- **AI Precision:** Uses Harmonic Pitch Class Profiles (HPCP) on the GPU for industry-leading Key detection.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. ðŸŽï¸ Turbo-Charge Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import warnings\n",
                "\n",
                "# Suppress noise\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"âš™ï¸ Initializing High-Performance Environment...\")\n",
                "\n",
                "# Install GPU Audio libraries\n",
                "# nnAudio: GPU-accelerated spectrograms (CQT, Mel, STFT)\n",
                "try:\n",
                "    import nnAudio\n",
                "except ImportError:\n",
                "    !pip install -q nnAudio torch torchaudio librosa numpy tqdm\n",
                "\n",
                "import torch\n",
                "import torchaudio\n",
                "from nnAudio.Spectrogram import CQT1992v2\n",
                "import numpy as np\n",
                "import librosa\n",
                "from tqdm.auto import tqdm\n",
                "import glob\n",
                "import shutil\n",
                "import re\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "import gc\n",
                "\n",
                "# Check GPU\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"ðŸ”¥ PREFERRED ACCELERATOR: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU (Slow)'}\")\n",
                "print(f\"ðŸš€ TORCH VERSION: {torch.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. ðŸ§  GPU-Neural Analyzer Engine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HarmonicBrainGPU:\n",
                "    def __init__(self, device='cuda', sample_rate=22050, batch_size=8):\n",
                "        self.device = device\n",
                "        self.sr = sample_rate\n",
                "        self.batch_size = batch_size\n",
                "        \n",
                "        print(\"ðŸ§  Loading Neural DSP layers to VRAM...\")\n",
                "        # Initialize CQT (Constant-Q Transform) on GPU\n",
                "        # This replaces standard FFT for musical accuracy\n",
                "        self.cqt_layer = CQT1992v2(sr=self.sr, fmin=32.7, n_bins=84, bins_per_octave=12, hop_length=512)\n",
                "        self.cqt_layer.to(self.device)\n",
                "        \n",
                "        # Define Key Profiles (Krumhansl-Schmuckler) as GPU Tensors\n",
                "        self.major_profile = torch.tensor(\n",
                "            [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88], \n",
                "            device=self.device\n",
                "        )\n",
                "        self.minor_profile = torch.tensor(\n",
                "            [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17], \n",
                "            device=self.device\n",
                "        )\n",
                "        \n",
                "        # Pre-calculate rolled profiles for all 12 keys to do matrix multiplication\n",
                "        self.profiles_matrix = self._create_profile_matrix()\n",
                "        \n",
                "    def _create_profile_matrix(self):\n",
                "        # Create a (24, 12) matrix of all key profiles (12 Major + 12 Minor)\n",
                "        profiles = []\n",
                "        # Majors\n",
                "        for i in range(12):\n",
                "            profiles.append(torch.roll(self.major_profile, i))\n",
                "        # Minors\n",
                "        for i in range(12):\n",
                "            profiles.append(torch.roll(self.minor_profile, i))\n",
                "            \n",
                "        return torch.stack(profiles).t() # Tranpose for MatMul: (12, 24)\n",
                "\n",
                "    def process_batch(self, audio_batch, durations):\n",
                "        # audio_batch: List of numpy arrays\n",
                "        # Stack into padded tensor\n",
                "        max_len = max([len(x) for x in audio_batch])\n",
                "        batch_tensor = torch.zeros(len(audio_batch), max_len, device=self.device)\n",
                "        \n",
                "        for i, audio in enumerate(audio_batch):\n",
                "            # Convert part to tensor and copy to GPU\n",
                "            # We limit analysis to first 2 minutes to save VRAM if needed, \n",
                "            # but let's try full duration for accuracy or cap at 4M samples (~3 mins)\n",
                "            limit = min(len(audio), 4_000_000) \n",
                "            batch_tensor[i, :limit] = torch.from_numpy(audio[:limit]).to(self.device)\n",
                "\n",
                "        # 1. CQT Spectrogram (GPU)\n",
                "        # Output: (Batch, FreqBins, Time)\n",
                "        cqt_spec = self.cqt_layer(batch_tensor)\n",
                "        \n",
                "        # 2. Chroma Generation (Fold bins into 12 pitch classes)\n",
                "        # CQT maps frequency logarithmically, so we can reshape to (Batch, Octaves, 12, Time)\n",
                "        # Then sum over octaves and time.\n",
                "        # Simple approach with CQT1992v2 (84 bins = 7 octaves * 12 bins)\n",
                "        batch_size, n_bins, time_steps = cqt_spec.shape\n",
                "        # Reshape to (Batch, 7, 12, Time) and sum over Octaves (dim 1) and Time (dim 3)\n",
                "        chroma = cqt_spec.view(batch_size, 7, 12, -1).sum(dim=(1, 3))\n",
                "        \n",
                "        # Normalize chroma vectors\n",
                "        chroma = chroma / (chroma.norm(dim=1, keepdim=True) + 1e-6)\n",
                "        \n",
                "        # 3. Key Classification (Matrix Multiplication)\n",
                "        # (Batch, 12) @ (12, 24) -> (Batch, 24)\n",
                "        correlations = torch.matmul(chroma, self.profiles_matrix)\n",
                "        best_indices = torch.argmax(correlations, dim=1).cpu().numpy()\n",
                "        \n",
                "        results = []\n",
                "        pitch_classes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
                "        \n",
                "        for i, idx in enumerate(best_indices):\n",
                "            if idx < 12:\n",
                "                key = pitch_classes[idx]\n",
                "                mode = 'Major'\n",
                "            else:\n",
                "                key = pitch_classes[idx - 12]\n",
                "                mode = 'Minor'\n",
                "            \n",
                "            results.append({\n",
                "                'key': key,\n",
                "                'mode': mode,\n",
                "                'duration': durations[i]\n",
                "            })\n",
                "            \n",
                "        # Clean up VRAM\n",
                "        del batch_tensor, cqt_spec, correlations\n",
                "        return results\n",
                "    \n",
                "    def estimate_bpm_cpu(self, audio_arrays):\n",
                "        # BPM is cleaner on CPU via Librosa (Temple runs are hard on GPU without complex models)\n",
                "        # We run this in parallel threads alongside GPU work if possible, or usually just fast enough sequential\n",
                "        bpms = []\n",
                "        for y in audio_arrays:\n",
                "            if len(y) > 0:\n",
                "                # Use a slice for speed\n",
                "                onset_env = librosa.onset.onset_strength(y=y, sr=self.sr)\n",
                "                tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=self.sr)\n",
                "                bpms.append(tempo[0])\n",
                "            else:\n",
                "                bpms.append(120.0)\n",
                "        return bpms\n",
                "\n",
                "def get_camelot_code(key, mode):\n",
                "    # Standard Camelot Map\n",
                "    camelot_map = {\n",
                "        ('B', 'Major'): '01B', ('F#', 'Major'): '02B', ('C#', 'Major'): '03B', ('G#', 'Major'): '04B',\n",
                "        ('D#', 'Major'): '05B', ('A#', 'Major'): '06B', ('F', 'Major'): '07B', ('C', 'Major'): '08B',\n",
                "        ('G', 'Major'): '09B', ('D', 'Major'): '10B', ('A', 'Major'): '11B', ('E', 'Major'): '12B',\n",
                "        ('G#', 'Minor'): '01A', ('D#', 'Minor'): '02A', ('A#', 'Minor'): '03A', ('F', 'Minor'): '04A',\n",
                "        ('C', 'Minor'): '05A', ('G', 'Minor'): '06A', ('D', 'Minor'): '07A', ('A', 'Minor'): '08A',\n",
                "        ('E', 'Minor'): '09A', ('B', 'Minor'): '10A', ('F#', 'Minor'): '11A', ('C#', 'Minor'): '12A'\n",
                "    }\n",
                "    # Common replacements just in case\n",
                "    if key == 'Ob': key = 'C#' \n",
                "    return camelot_map.get((key, mode), \"00X\")\n",
                "\n",
                "def clean_filename(filename):\n",
                "    if '.' not in filename: return filename\n",
                "    name_body, ext = filename.rsplit('.', 1)\n",
                "    patterns = [r\"^Slavic-\", r\"^Theme_OST-\", r\"^My_Workspace-\", r\"^audio-\", r\"[\\(\\.\\-_\\s]?[0-9a-fA-F]{8}-.*$\"]\n",
                "    for p in patterns: name_body = re.sub(p, \"\", name_body, flags=re.IGNORECASE)\n",
                "    name_body = name_body.replace(\"_\", \" \").strip(\" -(_)\")\n",
                "    name_body = re.sub(r\"\\s+\", \" \", name_body).strip()\n",
                "    return f\"{name_body if name_body else 'Unnamed'}.{ext}\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. ðŸš¦ Orchestrator (Parallel Batch I/O)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIG ---\n",
                "INPUT_DIR = \"/kaggle/input/datasets/danieldobles/ost-songs\"\n",
                "OUTPUT_DIR = \"/kaggle/working/harmonic_sets_gpu\"\n",
                "TARGET_SET_DURATION = 60 * 60 \n",
                "BATCH_SIZE = 16  # Process 16 songs at once on GPU\n",
                "SAMPLE_RATE = 22050\n",
                "# --------------\n",
                "\n",
                "def load_audio_file(path):\n",
                "    try:\n",
                "        # Fast load, mono, fixed sample rate\n",
                "        y, _ = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
                "        duration = len(y) / SAMPLE_RATE\n",
                "        return y, duration, path\n",
                "    except:\n",
                "        return None, 0, path\n",
                "\n",
                "print(\"ðŸ” Scanning...\")\n",
                "audio_extensions = ['*.mp3', '*.wav', '*.flac', '*.m4a']\n",
                "file_paths = []\n",
                "for ext in audio_extensions:\n",
                "    file_paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\n",
                "file_paths = list(set(file_paths))\n",
                "print(f\"ðŸ’¿ Found {len(file_paths)} tracks.\")\n",
                "\n",
                "if not file_paths:\n",
                "    print(\"âŒ Empty library.\")\n",
                "else:\n",
                "    # Initialize Brain\n",
                "    brain = HarmonicBrainGPU(device=device, sample_rate=SAMPLE_RATE, batch_size=BATCH_SIZE)\n",
                "    \n",
                "    library_data = []\n",
                "    \n",
                "    # We iterate chunks of file paths\n",
                "    chunks = [file_paths[i:i + BATCH_SIZE] for i in range(0, len(file_paths), BATCH_SIZE)]\n",
                "    \n",
                "    print(f\"\\nðŸš€ Starting GPU Batch Processing ({len(chunks)} batches)...\")\n",
                "    \n",
                "    with ThreadPoolExecutor(max_workers=4) as loader_pool:\n",
                "        # Loop through batches\n",
                "        for chunk_idx, chunk_paths in enumerate(tqdm(chunks, desc=\"ðŸ”¥ Processing Batches\")):\n",
                "            \n",
                "            # 1. Parallel Load CPU (While GPU is busy with prev, theoretically, but here sequential loop)\n",
                "            # Loading is usually the bottleneck, so we parallelize it.\n",
                "            loaded_batch = list(loader_pool.map(load_audio_file, chunk_paths))\n",
                "            \n",
                "            # Filter failed loads\n",
                "            valid_batch = [x for x in loaded_batch if x[0] is not None]\n",
                "            if not valid_batch: continue\n",
                "            \n",
                "            audio_arrays = [x[0] for x in valid_batch]\n",
                "            durations = [x[1] for x in valid_batch]\n",
                "            paths = [x[2] for x in valid_batch]\n",
                "            \n",
                "            # 2. GPU Analysis (Key)\n",
                "            key_results = brain.process_batch(audio_arrays, durations)\n",
                "            \n",
                "            # 3. CPU Analysis (BPM) - Fast Calc\n",
                "            bpms = brain.estimate_bpm_cpu(audio_arrays)\n",
                "            \n",
                "            # 4. Aggregate\n",
                "            for i, res in enumerate(key_results):\n",
                "                camelot = get_camelot_code(res['key'], res['mode'])\n",
                "                library_data.append({\n",
                "                    \"path\": paths[i],\n",
                "                    \"camelot\": camelot,\n",
                "                    \"bpm\": bpms[i],\n",
                "                    \"duration\": res['duration']\n",
                "                })\n",
                "            \n",
                "            # Clean up RAM immediately\n",
                "            del audio_arrays, loaded_batch\n",
                "            if chunk_idx % 5 == 0: gc.collect()\n",
                "\n",
                "    # --- CLUSTERING & EXPORT ---\n",
                "    print(\"\\nðŸŽ§ Clustering Mixes...\")\n",
                "    library_data.sort(key=lambda x: (x['camelot'], x['bpm']))\n",
                "    \n",
                "    if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "    \n",
                "    sets = []\n",
                "    current = []\n",
                "    cur_dur = 0\n",
                "    \n",
                "    for track in library_data:\n",
                "        current.append(track)\n",
                "        cur_dur += track['duration']\n",
                "        if cur_dur >= TARGET_SET_DURATION:\n",
                "            sets.append(current)\n",
                "            current = []\n",
                "            cur_dur = 0\n",
                "    if current: sets.append(current)\n",
                "    \n",
                "    total_sets = 0\n",
                "    for i, s in enumerate(sets):\n",
                "        set_dir = os.path.join(OUTPUT_DIR, f\"Set_{str(i+1).zfill(2)}\")\n",
                "        os.makedirs(set_dir, exist_ok=True)\n",
                "        total_sets += 1\n",
                "        \n",
                "        for idx, t in enumerate(s):\n",
                "            clean = clean_filename(os.path.basename(t['path']))\n",
                "            new_name = f\"{str(idx+1).zfill(2)} - [{t['camelot']} - {int(t['bpm'])}BPM] {clean}\"\n",
                "            shutil.copy2(t['path'], os.path.join(set_dir, new_name))\n",
                "            \n",
                "    print(f\"\\nâœ… DONE. Generated {total_sets} sets.\")\n",
                "    \n",
                "    # Zip & Download\n",
                "    zip_name = \"gpu_harmonic_mixes.zip\"\n",
                "    !zip -0 -rq {zip_name} harmonic_sets_gpu\n",
                "    \n",
                "    display(HTML(f\"<h3>ðŸš€ <a href='{zip_name}' target='_blank'>DOWNLOAD GPU MIXES</a></h3>\"))\n",
                "    display(HTML(f\"<script>setTimeout(function(){{ document.querySelector('a[href=\\\"{zip_name}\\\"]').click(); }}, 1500);</script>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}