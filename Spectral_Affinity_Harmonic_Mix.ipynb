{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity: Harmonic Mix & Curation Engine 2.0\n",
                "### *\"The Ultimate AI Librarian for Camelot-based Flow + Mastering\"*\n",
                "\n",
                "Este cuaderno combina la **Curadur√≠a Inteligente** con un **Mastering Adaptativo** (Matchering 2.0) y **Restauraci√≥n Arm√≥nica** (Pedalboard).\n",
                "\n",
                "**La Soluci√≥n:**\n",
                "1. üß† **Neural Analysis**: Key (Camelot), BPM, Energ√≠a y Textura Sem√°ntica (MERT).\n",
                "2. ‚ú® **Harmonic Restoration**: Suno corta el audio a los 16kHz. Usamos **Excitaci√≥n Arm√≥nica** para devolver el brillo natural sin artefactos de IA.\n",
                "3. üéöÔ∏è **Matchering 2.0**: Copiamos el \"alma\" (EQ, RMS, Ancho Est√©reo) de una referencia profesional y se la aplicamos a tus temas.\n",
                "4. üîÄ **Harmonic Flow**: Secuenciaci√≥n autom√°tica siguiendo la Rueda de Camelot.\n",
                "5. üìÇ **Auto-Organization**: Generaci√≥n de carpetas con sets listos para pinchar.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üõ†Ô∏è Setup\n",
                "try:\n",
                "    import matchering as mg\n",
                "    from pedalboard import Pedalboard\n",
                "except:\n",
                "    !pip install -q transformers torch torchaudio nnAudio librosa pandas scikit-learn tqdm matchering pedalboard soundfile\n",
                "\n",
                "import os, torch, torchaudio, librosa, shutil, json, time, warnings, re\n",
                "import numpy as np; import pandas as pd\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from tqdm.auto import tqdm\n",
                "import torchaudio.transforms as T\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
                "from sklearn.preprocessing import normalize; from sklearn.cluster import KMeans\n",
                "from IPython.display import display, FileLink, HTML\n",
                "import matchering as mg\n",
                "from pedalboard import Pedalboard, HighpassFilter, Distortion, Gain, HighShelfFilter\n",
                "import pedalboard.io\n",
                "\n",
                "warnings.filterwarnings(\"ignore\"); os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "SAMPLE_RATE = 24000 # Para an√°lisis\n",
                "print(f\"üåå MASTERING & CURATION ENGINE READY ON: {DEVICE.upper()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† 1. Motor de An√°lisis Neuronal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CAMELOT_MAP = {\n",
                "    'C Major': '08B', 'C# Major': '03B', 'D Major': '10B', 'D# Major': '05B', 'E Major': '12B', 'F Major': '07B',\n",
                "    'F# Major': '02B', 'G Major': '09B', 'G# Major': '04B', 'A Major': '11B', 'A# Major': '06B', 'B Major': '01B',\n",
                "    'C Minor': '05A', 'C# Minor': '12A', 'D Minor': '07A', 'D# Minor': '02A', 'E Minor': '09A', 'F Minor': '04A',\n",
                "    'F# Minor': '11A', 'G Minor': '06A', 'G# Minor': '01A', 'A Minor': '08A', 'A# Minor': '03A', 'B Minor': '10A'\n",
                "}\n",
                "\n",
                "class NeuralAnalyzer:\n",
                "    def __init__(self, device='cuda'):\n",
                "        from nnAudio.Spectrogram import CQT1992v2\n",
                "        self.device = device\n",
                "        self.cqt = CQT1992v2(sr=SAMPLE_RATE, n_bins=84, bins_per_octave=12, verbose=False).to(device)\n",
                "        self.proc = Wav2Vec2FeatureExtractor.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True)\n",
                "        self.mert = AutoModel.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True).to(device).eval()\n",
                "        major = torch.tensor([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], device=device)\n",
                "        minor = torch.tensor([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major,i) for i in range(12)] + [torch.roll(minor,i) for i in range(12)]).t()\n",
                "\n",
                "    def analyze_batch(self, paths):\n",
                "        def load_one(p):\n",
                "            try:\n",
                "                w, s = torchaudio.load(p)\n",
                "                if s != SAMPLE_RATE: w = T.Resample(s, SAMPLE_RATE)(w)\n",
                "                w = w.mean(0)\n",
                "                return w, os.path.basename(p), p\n",
                "            except: return None\n",
                "\n",
                "        with ThreadPoolExecutor(max_workers=8) as pl: results = list(pl.map(load_one, paths))\n",
                "        valid = [r for r in results if r is not None]\n",
                "        if not valid: return []\n",
                "\n",
                "        m_len = max([r[0].shape[0] for r in valid])\n",
                "        t = torch.zeros(len(valid), m_len, device=self.device)\n",
                "        for i, r in enumerate(valid): t[i, :r[0].shape[0]] = r[0].to(self.device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt(t)\n",
                "            energy = spec.pow(2).mean(dim=(1,2)).cpu().numpy()\n",
                "            chroma = spec.view(len(valid), 7, 12, -1).sum(dim=(1,3))\n",
                "            chroma = chroma / (chroma.norm(dim=1,keepdim=True)+1e-6)\n",
                "            best = torch.argmax(torch.matmul(chroma, self.profiles), dim=1).cpu().numpy()\n",
                "            \n",
                "            embs = []\n",
                "            for i in range(len(valid)):\n",
                "                sl = int(SAMPLE_RATE*15); s = valid[i][0][:sl].cpu().numpy()\n",
                "                iv = self.proc(s, sampling_rate=SAMPLE_RATE, return_tensors='pt').input_values.to(self.device)\n",
                "                embs.append(self.mert(iv).last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist())\n",
                "\n",
                "        pc = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
                "        batch_meta = []\n",
                "        for i, (w, fname, fpath) in enumerate(valid):\n",
                "            k = pc[best[i]%12]; m = 'Major' if best[i]<12 else 'Minor'\n",
                "            y_np = w.numpy().squeeze(); tempo, _ = librosa.beat.beat_track(y=y_np[:SAMPLE_RATE*45], sr=SAMPLE_RATE)\n",
                "            batch_meta.append({\n",
                "                'path': fpath, 'file': fname, 'camelot': CAMELOT_MAP.get(f\"{k} {m}\", \"08A\"),\n",
                "                'bpm': int(tempo.item()) if hasattr(tempo, 'item') else int(tempo),\n",
                "                'energy': float(energy[i]), 'duration': len(w)/SAMPLE_RATE, 'embedding': embs[i]\n",
                "            })\n",
                "        return batch_meta"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚ú® 2. Recuperaci√≥n Arm√≥nica y Mastering Adaptativo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def harmonic_exciter(input_path, output_path, drive=1.8, mix=0.12):\n",
                "    \"\"\"Genera arm√≥nicos superiores naturales (>16kHz) usando Pedalboard.\"\"\"\n",
                "    with pedalboard.io.AudioFile(input_path) as f:\n",
                "        audio = f.read(f.frames)\n",
                "        sr = f.samplerate\n",
                "    \n",
                "    # Creamos un board para los arm√≥nicos\n",
                "    # Procesamos en serie para evitar problemas de fase fuera del plugin\n",
                "    board = Pedalboard([\n",
                "        HighpassFilter(cutoff_frequency_hz=10000), \n",
                "        Distortion(drive_db=drive),               \n",
                "        HighpassFilter(cutoff_frequency_hz=12000), \n",
                "        Gain(gain_db=-4)\n",
                "    ])\n",
                "    \n",
                "    harmonics = board(audio, sr)\n",
                "    # Mezcla simple pero efectiva, harmonics ya viene filtrado\n",
                "    processed = audio + (harmonics * mix)\n",
                "    \n",
                "    with pedalboard.io.AudioFile(output_path, 'w', sr, processed.shape[0]) as f:\n",
                "        f.write(processed)\n",
                "\n",
                "def apply_mastering(target, reference, output_path):\n",
                "    \"\"\"Interfaz corregida para Matchering 2.0 (Output 24-bit).\"\"\"\n",
                "    try:\n",
                "        mg.process(\n",
                "            target=target, \n",
                "            reference=reference, \n",
                "            results=[mg.pcm24(output_path)]\n",
                "        )\n",
                "        return True\n",
                "    except Exception as e:\n",
                "        print(f\"  ‚ö†Ô∏è Error en Matchering: {e}\")\n",
                "        return False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÄ 3. L√≥gica de Flujo Arm√≥nico Crom√°tico"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(c):\n",
                "    n, a = int(c[:2]), c[2]\n",
                "    return [f'{str(n).zfill(2)}{a}', f'{str((n%12)+1).zfill(2)}{a}', f'{str(((n-2)%12)+1).zfill(2)}{a}', f\"{str(n).zfill(2)}{'A' if a=='B' else 'B'}\"]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target_dur_sec=3600):\n",
                "    if not tracks: return []\n",
                "    pool = list(tracks); cur = pool.pop(0); ordered = [cur]; dur = cur['duration']\n",
                "    \n",
                "    while pool and dur < target_dur_sec:\n",
                "        ck = get_next_harmonic(cur['camelot'])\n",
                "        \n",
                "        def get_score(t):\n",
                "            h = 1.0 if t['camelot'] in ck else (0.8 if t['camelot']==cur['camelot'] else 0.0)\n",
                "            b = max(0, 1.0 - (abs(t['bpm'] - cur['bpm']) / 40.0))\n",
                "            s = np.dot(cur['embedding'], t['embedding']) / (np.linalg.norm(cur['embedding']) * np.linalg.norm(t['embedding']) + 1e-9)\n",
                "            return h * 0.5 + s * 0.3 + b * 0.2\n",
                "        \n",
                "        # Encontramos el mejor manualmente para evitar re-odernar toda la lista (O(n) vs O(n log n))\n",
                "        best_idx = 0\n",
                "        max_s = -1\n",
                "        for i, t in enumerate(pool):\n",
                "            sc = get_score(t)\n",
                "            if sc > max_s:\n",
                "                max_s = sc\n",
                "                best_idx = i\n",
                "        \n",
                "        nxt = pool.pop(best_idx)\n",
                "        ordered.append(nxt)\n",
                "        dur += nxt['duration']\n",
                "        cur = nxt\n",
                "    return ordered, pool\n",
                "\n",
                "def clean_name(n): \n",
                "    name = os.path.basename(n).rsplit('.', 1)[0]\n",
                "    return re.sub(r'[\\-\\_\\.]+?', ' ', re.sub(r'^[\\w\\-]+?-', '', name)).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ 4. Lanzamiento del Motor (Harmonic Mix + Mastering)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_DIR = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "if not os.path.exists(INPUT_DIR): INPUT_DIR = 'Slavic Data_Set'\n",
                "\n",
                "# Buscamos el archivo de referencia profesional\n",
                "potential_refs = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if 'REF' in f.upper()]\n",
                "REF_FILE = potential_refs[0] if potential_refs else None\n",
                "\n",
                "OUT_DIR = '/kaggle/working/MASTERED_CURATION_RESULTS'\n",
                "TEMP_DIR = '/kaggle/working/tmp_processing'\n",
                "SET_DURATION = 60 * 60 # 60 minutes\n",
                "N_GROUPS = 3\n",
                "\n",
                "os.makedirs(OUT_DIR, exist_ok=True)\n",
                "os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(('.mp3','.wav','.flac')) and 'REF' not in f.upper() ]\n",
                "\n",
                "print(f\"üß† Analizando {len(files)} temas...\")\n",
                "analyzer = NeuralAnalyzer(device=DEVICE)\n",
                "library = []\n",
                "for i in tqdm(range(0, len(files), 16)): library.extend(analyzer.analyze_batch(files[i:i+16]))\n",
                "\n",
                "print(\"üîç Segmentando por Estilo Sem√°ntico...\")\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "labels = KMeans(n_clusters=N_GROUPS, n_init=10).fit_predict(X)\n",
                "clusters = {i: [library[j] for j,l in enumerate(labels) if l==i] for i in range(N_GROUPS)}\n",
                "\n",
                "print(f\"\\nüî• Procesando grupos en {N_GROUPS} Sonic Clusters...\")\n",
                "if REF_FILE: print(f\"üìè Usando Referencia: {os.path.basename(REF_FILE)}\")\n",
                "\n",
                "for ci, tracks in clusters.items():\n",
                "    group_name = f'Group_{chr(65+ci)}'\n",
                "    pool = sorted(tracks, key=lambda x: x['energy'], reverse=True)\n",
                "    set_idx = 1\n",
                "    \n",
                "    while pool:\n",
                "        set_dir = os.path.join(OUT_DIR, group_name, f'Set_{set_idx}')\n",
                "        os.makedirs(set_dir, exist_ok=True)\n",
                "        oset, pool = sequence_chromatic_set(pool, SET_DURATION)\n",
                "        \n",
                "        print(f\"\\nüìÇ {group_name} | Set {set_idx} ({len(oset)} tracks)\")\n",
                "        for j, t in tqdm(enumerate(oset), total=len(oset), desc=\"Processing Audio\", leave=False):\n",
                "            base_name = clean_name(t['path'])\n",
                "            out_name = f\"{str(j+1).zfill(2)} - [{t['camelot']}] {base_name}.wav\"\n",
                "            final_path = os.path.join(set_dir, out_name)\n",
                "            \n",
                "            # 1. Recuperaci√≥n Arm√≥nica (Pedalboard)\n",
                "            tmp_h = os.path.join(TEMP_DIR, f\"proc_{ci}_{j}.wav\")\n",
                "            harmonic_exciter(t['path'], tmp_h)\n",
                "            \n",
                "            # 2. Matchering 2.0 (EQ, RMS, Stereo Matching)\n",
                "            if REF_FILE:\n",
                "                apply_mastering(tmp_h, REF_FILE, final_path)\n",
                "            else:\n",
                "                shutil.move(tmp_h, final_path)\n",
                "            \n",
                "            if os.path.exists(tmp_h): os.remove(tmp_h)\n",
                "            \n",
                "        set_idx += 1\n",
                "\n",
                "# Cleanup & Zip\n",
                "shutil.rmtree(TEMP_DIR)\n",
                "shutil.make_archive('SPECTRAL_AFFINITY_MASTERED', 'zip', OUT_DIR)\n",
                "display(HTML(f\"<h3>üöÄ <a href='SPECTRAL_AFFINITY_MASTERED.zip'>DESCARGAR LIBRER√çA MASTERIZADA</a></h3>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}