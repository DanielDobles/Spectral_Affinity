{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14813013,"sourceType":"datasetVersion","datasetId":9471315}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b8aaad7a-f604-4b86-94e6-141c14d8b75f","cell_type":"markdown","source":"# ğŸš€ Spectral Affinity: GPU-Accelerated Neural Mixer\n\nThis edition is engineered for **Extreme Performance** using **GPU Acceleration** and **Parallel Batch Processing**.\n\n**âš¡ Upgrades:**\n- **GPU DSP (nnAudio):** Uses your Graphics Card (CUDA) to calculate CQT Spectrograms instantly.\n- **Parallel I/O:** Loads files in background threads while the GPU crunches numbers.\n- **Batch Processing:** Analyzes multiple songs simultaneously (Matrix operations).\n- **AI Precision:** Uses Harmonic Pitch Class Profiles (HPCP) on the GPU for industry-leading Key detection.\n\n---","metadata":{}},{"id":"828b2053-58ae-45f4-a54f-56c2701e9383","cell_type":"markdown","source":"### 1. ğŸï¸ Turbo-Charge Environment","metadata":{}},{"id":"4003301f-67dd-49bc-a3ab-ff81e14227bd","cell_type":"code","source":"import os\nimport warnings\n\n# Suppress noise\nwarnings.filterwarnings('ignore')\n\nprint(\"âš™ï¸ Initializing High-Performance Environment...\")\n\n# Install GPU Audio libraries\n# nnAudio: GPU-accelerated spectrograms (CQT, Mel, STFT)\ntry:\n    import nnAudio\nexcept ImportError:\n    !pip install -q nnAudio torch torchaudio librosa numpy tqdm\n\nimport torch\nimport torchaudio\nfrom nnAudio.Spectrogram import CQT1992v2\nimport numpy as np\nimport librosa\nfrom tqdm.auto import tqdm\nimport glob\nimport shutil\nimport re\nfrom concurrent.futures import ThreadPoolExecutor\nimport gc\n\n# Check GPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"ğŸ”¥ PREFERRED ACCELERATOR: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU (Slow)'}\")\nprint(f\"ğŸš€ TORCH VERSION: {torch.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T02:54:58.413503Z","iopub.execute_input":"2026-02-12T02:54:58.414217Z","iopub.status.idle":"2026-02-12T02:54:58.420716Z","shell.execute_reply.started":"2026-02-12T02:54:58.414184Z","shell.execute_reply":"2026-02-12T02:54:58.420002Z"}},"outputs":[{"name":"stdout","text":"âš™ï¸ Initializing High-Performance Environment...\nğŸ”¥ PREFERRED ACCELERATOR: Tesla T4\nğŸš€ TORCH VERSION: 2.8.0+cu126\n","output_type":"stream"}],"execution_count":7},{"id":"d590798a-4135-4e35-ba8b-517325b95d94","cell_type":"markdown","source":"### 2. ğŸ§  GPU-Neural Analyzer Engine","metadata":{}},{"id":"85d8a90b-7136-449f-9365-2822d283bf66","cell_type":"code","source":"class HarmonicBrainGPU:\n    def __init__(self, device='cuda', sample_rate=22050, batch_size=8):\n        self.device = device\n        self.sr = sample_rate\n        self.batch_size = batch_size\n        \n        print(\"ğŸ§  Loading Neural DSP layers to VRAM...\")\n        # Initialize CQT (Constant-Q Transform) on GPU\n        # This replaces standard FFT for musical accuracy\n        self.cqt_layer = CQT1992v2(sr=self.sr, fmin=32.7, n_bins=84, bins_per_octave=12, hop_length=512)\n        self.cqt_layer.to(self.device)\n        \n        # Define Key Profiles (Krumhansl-Schmuckler) as GPU Tensors\n        self.major_profile = torch.tensor(\n            [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88], \n            device=self.device\n        )\n        self.minor_profile = torch.tensor(\n            [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17], \n            device=self.device\n        )\n        \n        # Pre-calculate rolled profiles for all 12 keys to do matrix multiplication\n        self.profiles_matrix = self._create_profile_matrix()\n        \n    def _create_profile_matrix(self):\n        # Create a (24, 12) matrix of all key profiles (12 Major + 12 Minor)\n        profiles = []\n        # Majors\n        for i in range(12):\n            profiles.append(torch.roll(self.major_profile, i))\n        # Minors\n        for i in range(12):\n            profiles.append(torch.roll(self.minor_profile, i))\n            \n        return torch.stack(profiles).t() # Tranpose for MatMul: (12, 24)\n\n    def process_batch(self, audio_batch, durations):\n        # audio_batch: List of numpy arrays\n        # Stack into padded tensor\n        max_len = max([len(x) for x in audio_batch])\n        batch_tensor = torch.zeros(len(audio_batch), max_len, device=self.device)\n        \n        for i, audio in enumerate(audio_batch):\n            # Convert part to tensor and copy to GPU\n            # We limit analysis to first 2 minutes to save VRAM if needed, \n            # but let's try full duration for accuracy or cap at 4M samples (~3 mins)\n            limit = min(len(audio), 4_000_000) \n            batch_tensor[i, :limit] = torch.from_numpy(audio[:limit]).to(self.device)\n\n        # 1. CQT Spectrogram (GPU)\n        # Output: (Batch, FreqBins, Time)\n        cqt_spec = self.cqt_layer(batch_tensor)\n        \n        # 2. Chroma Generation (Fold bins into 12 pitch classes)\n        # CQT maps frequency logarithmically, so we can reshape to (Batch, Octaves, 12, Time)\n        # Then sum over octaves and time.\n        # Simple approach with CQT1992v2 (84 bins = 7 octaves * 12 bins)\n        batch_size, n_bins, time_steps = cqt_spec.shape\n        # Reshape to (Batch, 7, 12, Time) and sum over Octaves (dim 1) and Time (dim 3)\n        chroma = cqt_spec.view(batch_size, 7, 12, -1).sum(dim=(1, 3))\n        \n        # Normalize chroma vectors\n        chroma = chroma / (chroma.norm(dim=1, keepdim=True) + 1e-6)\n        \n        # 3. Key Classification (Matrix Multiplication)\n        # (Batch, 12) @ (12, 24) -> (Batch, 24)\n        correlations = torch.matmul(chroma, self.profiles_matrix)\n        best_indices = torch.argmax(correlations, dim=1).cpu().numpy()\n        \n        results = []\n        pitch_classes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n        \n        for i, idx in enumerate(best_indices):\n            if idx < 12:\n                key = pitch_classes[idx]\n                mode = 'Major'\n            else:\n                key = pitch_classes[idx - 12]\n                mode = 'Minor'\n            \n            results.append({\n                'key': key,\n                'mode': mode,\n                'duration': durations[i]\n            })\n            \n        # Clean up VRAM\n        del batch_tensor, cqt_spec, correlations\n        return results\n    \n    def estimate_bpm_cpu(self, audio_arrays):\n        # BPM is cleaner on CPU via Librosa (Temple runs are hard on GPU without complex models)\n        # We run this in parallel threads alongside GPU work if possible, or usually just fast enough sequential\n        bpms = []\n        for y in audio_arrays:\n            if len(y) > 0:\n                # Use a slice for speed\n                onset_env = librosa.onset.onset_strength(y=y, sr=self.sr)\n                tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=self.sr)\n                bpms.append(tempo[0])\n            else:\n                bpms.append(120.0)\n        return bpms\n\ndef get_camelot_code(key, mode):\n    # Standard Camelot Map\n    camelot_map = {\n        ('B', 'Major'): '01B', ('F#', 'Major'): '02B', ('C#', 'Major'): '03B', ('G#', 'Major'): '04B',\n        ('D#', 'Major'): '05B', ('A#', 'Major'): '06B', ('F', 'Major'): '07B', ('C', 'Major'): '08B',\n        ('G', 'Major'): '09B', ('D', 'Major'): '10B', ('A', 'Major'): '11B', ('E', 'Major'): '12B',\n        ('G#', 'Minor'): '01A', ('D#', 'Minor'): '02A', ('A#', 'Minor'): '03A', ('F', 'Minor'): '04A',\n        ('C', 'Minor'): '05A', ('G', 'Minor'): '06A', ('D', 'Minor'): '07A', ('A', 'Minor'): '08A',\n        ('E', 'Minor'): '09A', ('B', 'Minor'): '10A', ('F#', 'Minor'): '11A', ('C#', 'Minor'): '12A'\n    }\n    # Common replacements just in case\n    if key == 'Ob': key = 'C#' \n    return camelot_map.get((key, mode), \"00X\")\n\ndef clean_filename(filename):\n    if '.' not in filename: return filename\n    name_body, ext = filename.rsplit('.', 1)\n    patterns = [r\"^Slavic-\", r\"^Theme_OST-\", r\"^My_Workspace-\", r\"^audio-\", r\"[\\(\\.\\-_\\s]?[0-9a-fA-F]{8}-.*$\"]\n    for p in patterns: name_body = re.sub(p, \"\", name_body, flags=re.IGNORECASE)\n    name_body = name_body.replace(\"_\", \" \").strip(\" -(_)\")\n    name_body = re.sub(r\"\\s+\", \" \", name_body).strip()\n    return f\"{name_body if name_body else 'Unnamed'}.{ext}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T02:54:58.421866Z","iopub.execute_input":"2026-02-12T02:54:58.422078Z","iopub.status.idle":"2026-02-12T02:54:58.440640Z","shell.execute_reply.started":"2026-02-12T02:54:58.422061Z","shell.execute_reply":"2026-02-12T02:54:58.440030Z"}},"outputs":[],"execution_count":8},{"id":"38891dc8-6663-4cb0-83f9-4b5b2fcbc836","cell_type":"markdown","source":"### 3. ğŸš¦ Orchestrator (Parallel Batch I/O)","metadata":{}},{"id":"36cee895-8c5d-40ba-a52a-f38af627a5c2","cell_type":"code","source":"# --- CONFIG ---\nINPUT_DIR = \"/kaggle/input/datasets/danieldobles/ost-songs\"\nOUTPUT_DIR = \"/kaggle/working/harmonic_sets_gpu\"\nTARGET_SET_DURATION = 60 * 60 \nBATCH_SIZE = 16  # Process 16 songs at once on GPU\nSAMPLE_RATE = 22050\n# --------------\n\ndef load_audio_file(path):\n    try:\n        # Fast load, mono, fixed sample rate\n        y, _ = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n        duration = len(y) / SAMPLE_RATE\n        return y, duration, path\n    except:\n        return None, 0, path\n\nprint(\"ğŸ” Scanning...\")\naudio_extensions = ['*.mp3', '*.wav', '*.flac', '*.m4a']\nfile_paths = []\nfor ext in audio_extensions:\n    file_paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\nfile_paths = list(set(file_paths))\nprint(f\"ğŸ’¿ Found {len(file_paths)} tracks.\")\n\nif not file_paths:\n    print(\"âŒ Empty library.\")\nelse:\n    # Initialize Brain\n    brain = HarmonicBrainGPU(device=device, sample_rate=SAMPLE_RATE, batch_size=BATCH_SIZE)\n    \n    library_data = []\n    \n    # We iterate chunks of file paths\n    chunks = [file_paths[i:i + BATCH_SIZE] for i in range(0, len(file_paths), BATCH_SIZE)]\n    \n    print(f\"\\nğŸš€ Starting GPU Batch Processing ({len(chunks)} batches)...\")\n    \n    with ThreadPoolExecutor(max_workers=4) as loader_pool:\n        # Loop through batches\n        for chunk_idx, chunk_paths in enumerate(tqdm(chunks, desc=\"ğŸ”¥ Processing Batches\")):\n            \n            # 1. Parallel Load CPU (While GPU is busy with prev, theoretically, but here sequential loop)\n            # Loading is usually the bottleneck, so we parallelize it.\n            loaded_batch = list(loader_pool.map(load_audio_file, chunk_paths))\n            \n            # Filter failed loads\n            valid_batch = [x for x in loaded_batch if x[0] is not None]\n            if not valid_batch: continue\n            \n            audio_arrays = [x[0] for x in valid_batch]\n            durations = [x[1] for x in valid_batch]\n            paths = [x[2] for x in valid_batch]\n            \n            # 2. GPU Analysis (Key)\n            key_results = brain.process_batch(audio_arrays, durations)\n            \n            # 3. CPU Analysis (BPM) - Fast Calc\n            bpms = brain.estimate_bpm_cpu(audio_arrays)\n            \n            # 4. Aggregate\n            for i, res in enumerate(key_results):\n                camelot = get_camelot_code(res['key'], res['mode'])\n                library_data.append({\n                    \"path\": paths[i],\n                    \"camelot\": camelot,\n                    \"bpm\": bpms[i],\n                    \"duration\": res['duration']\n                })\n            \n            # Clean up RAM immediately\n            del audio_arrays, loaded_batch\n            if chunk_idx % 5 == 0: gc.collect()\n\n    # --- CLUSTERING & EXPORT ---\n    print(\"\\nğŸ§ Clustering Mixes...\")\n    library_data.sort(key=lambda x: (x['camelot'], x['bpm']))\n    \n    if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n    \n    sets = []\n    current = []\n    cur_dur = 0\n    \n    for track in library_data:\n        current.append(track)\n        cur_dur += track['duration']\n        if cur_dur >= TARGET_SET_DURATION:\n            sets.append(current)\n            current = []\n            cur_dur = 0\n    if current: sets.append(current)\n    \n    total_sets = 0\n    for i, s in enumerate(sets):\n        set_dir = os.path.join(OUTPUT_DIR, f\"Set_{str(i+1).zfill(2)}\")\n        os.makedirs(set_dir, exist_ok=True)\n        total_sets += 1\n        \n        for idx, t in enumerate(s):\n            clean = clean_filename(os.path.basename(t['path']))\n            new_name = f\"{str(idx+1).zfill(2)} - [{t['camelot']} - {int(t['bpm'])}BPM] {clean}\"\n            shutil.copy2(t['path'], os.path.join(set_dir, new_name))\n            \n    print(f\"\\nâœ… DONE. Generated {total_sets} sets.\")\n    \n    # Zip & Download\n    zip_name = \"gpu_harmonic_mixes.zip\"\n    !zip -0 -rq {zip_name} harmonic_sets_gpu\n    \n    display(HTML(f\"<h3>ğŸš€ <a href='{zip_name}' target='_blank'>DOWNLOAD GPU MIXES</a></h3>\"))\n    display(HTML(f\"<script>setTimeout(function(){{ document.querySelector('a[href=\\\"{zip_name}\\\"]').click(); }}, 1500);</script>\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T02:54:58.444537Z","iopub.execute_input":"2026-02-12T02:54:58.445008Z","iopub.status.idle":"2026-02-12T02:58:11.904976Z","shell.execute_reply.started":"2026-02-12T02:54:58.444987Z","shell.execute_reply":"2026-02-12T02:58:11.904078Z"}},"outputs":[{"name":"stdout","text":"ğŸ” Scanning...\nğŸ’¿ Found 163 tracks.\nğŸ§  Loading Neural DSP layers to VRAM...\nCQT kernels created, time used = 0.0637 seconds\n\nğŸš€ Starting GPU Batch Processing (11 batches)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"ğŸ”¥ Processing Batches:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116945ef5f3b4e17b9fff7c43498f2a1"}},"metadata":{}},{"name":"stdout","text":"\nğŸ§ Clustering Mixes...\n\nâœ… DONE. Generated 11 sets.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>ğŸš€ <a href='gpu_harmonic_mixes.zip' target='_blank'>DOWNLOAD GPU MIXES</a></h3>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<script>setTimeout(function(){ document.querySelector('a[href=\"gpu_harmonic_mixes.zip\"]').click(); }, 1500);</script>"},"metadata":{}}],"execution_count":9}]}