{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "ef36b960",
            "metadata": {},
            "source": [
                "# ü•á Spectral Affinity: Ultimate GPU Harmonic Mixer (v3.0)\n",
                "\n",
                "This is the most advanced version of the pipeline, featuring **GPU-Neural DSP**, **Persistent Caching**, and **Energy-Based Clustering**.\n",
                "\n",
                "**üöÄ Professional Features:**\n",
                "- **üíæ Persistent Intelligence:** Saves analysis to a JSON cache. Never re-analyze the same song twice.\n",
                "- **üî• GPU-Accelerated (nnAudio):** Real-time Neural CQT and Key detection on CUDA.\n",
                "- **‚ö° Ultra-Batching:** Processes the library in large batches for maximum GPU saturation.\n",
                "- **üìà Energy Mapping:** Detects spectral energy to ensure your sets build up intensity correctly.\n",
                "- **üì¶ Smart Sets:** Generates ~60min sets with harmonic flow and BPM/Energy progression.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bfde53ba",
            "metadata": {},
            "source": [
                "### 1. üõ†Ô∏è Setup & High-Performance Engines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b81b7b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import warnings\n",
                "import json\n",
                "import torch\n",
                "import torchaudio\n",
                "import numpy as np\n",
                "import librosa\n",
                "import glob\n",
                "import shutil\n",
                "import re\n",
                "import gc\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, FileLink, display\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# üì¶ Install Missing GPU libs\n",
                "try:\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "except:\n",
                "    !pip install -q nnAudio\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"üî• ACCELERATOR: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aa4434af",
            "metadata": {},
            "source": [
                "### 2. üß† Neural Brain & Cache Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33e04755",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralBrainGPU:\n",
                "    def __init__(self, device='cuda', sr=22050, cache_file='spectral_cache.json'):\n",
                "        self.device = device\n",
                "        self.sr = sr\n",
                "        self.cache_file = cache_file\n",
                "        self.cache = self._load_cache()\n",
                "        \n",
                "        # Initialize Neural Layers\n",
                "        self.cqt_layer = CQT1992v2(sr=self.sr, n_bins=84, bins_per_octave=12).to(self.device)\n",
                "        \n",
                "        # Key Profiles (Krumhansl-Schmuckler)\n",
                "        major = torch.tensor([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88], device=device)\n",
                "        minor = torch.tensor([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17], device=device)\n",
                "        \n",
                "        self.profiles = torch.stack([torch.roll(major, i) for i in range(12)] + \n",
                "                                    [torch.roll(minor, i) for i in range(12)]).t()\n",
                "\n",
                "    def _load_cache(self):\n",
                "        if os.path.exists(self.cache_file):\n",
                "            with open(self.cache_file, 'r') as f: return json.load(f)\n",
                "        return {}\n",
                "\n",
                "    def save_cache(self):\n",
                "        with open(self.cache_file, 'w') as f: json.dump(self.cache, f)\n",
                "\n",
                "    def process_batch(self, batch_data):\n",
                "        # batch_data: list of (path, audio_numpy, duration)\n",
                "        paths = [x[0] for x in batch_data]\n",
                "        audios = [x[1] for x in batch_data]\n",
                "        durations = [x[2] for x in batch_data]\n",
                "        \n",
                "        # GPU Matrix Prep\n",
                "        max_len = 22050 * 120 # Cap analysis at 2 mins for speed/VRAM\n",
                "        batch_tensor = torch.zeros(len(audios), max_len, device=self.device)\n",
                "        for i, a in enumerate(audios):\n",
                "            l = min(len(a), max_len)\n",
                "            batch_tensor[i, :l] = torch.from_numpy(a[:l]).to(self.device)\n",
                "\n",
                "        # 1. GPU CQT & Chroma\n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt_layer(batch_tensor)\n",
                "            # spec shape: (Batch, Bins, Time)\n",
                "            # Extract Energy (RMS) for intensity mapping\n",
                "            energy = spec.pow(2).mean(dim=(1, 2)).cpu().numpy()\n",
                "            \n",
                "            # Simple Chroma (sum octaves)\n",
                "            chroma = spec.view(len(audios), 7, 12, -1).sum(dim=(1, 3))\n",
                "            chroma = chroma / (chroma.norm(dim=1, keepdim=True) + 1e-6)\n",
                "            \n",
                "            # Key Match\n",
                "            corrs = torch.matmul(chroma, self.profiles)\n",
                "            best_idx = torch.argmax(corrs, dim=1).cpu().numpy()\n",
                "\n",
                "        # 2. Results\n",
                "        pc = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
                "        batch_results = []\n",
                "        \n",
                "        for i in range(len(audios)):\n",
                "            idx = best_idx[i]\n",
                "            res = {\n",
                "                'key': pc[idx % 12],\n",
                "                'mode': 'major' if idx < 12 else 'minor',\n",
                "                'energy': float(energy[i]),\n",
                "                'duration': float(durations[i]),\n",
                "                'path': paths[i]\n",
                "            }\n",
                "            # Fast BPM estimate on CPU while GPU is idle\n",
                "            onset = librosa.onset.onset_strength(y=audios[i][:22050*60], sr=22050)\n",
                "            res['bpm'] = float(librosa.beat.tempo(onset_envelope=onset, sr=22050)[0])\n",
                "            batch_results.append(res)\n",
                "            \n",
                "        return batch_results\n",
                "\n",
                "def get_camelot(key, mode):\n",
                "    c_map = {\n",
                "        ('B', 'major'): '01B', ('F#', 'major'): '02B', ('C#', 'major'): '03B', ('G#', 'major'): '04B',\n",
                "        ('D#', 'major'): '05B', ('A#', 'major'): '06B', ('F', 'major'): '07B', ('C', 'major'): '08B',\n",
                "        ('G', 'major'): '09B', ('D', 'major'): '10B', ('A', 'major'): '11B', ('E', 'major'): '12B',\n",
                "        ('G#', 'minor'): '01A', ('D#', 'minor'): '02A', ('A#', 'minor'): '03A', ('F', 'minor'): '04A',\n",
                "        ('C', 'minor'): '05A', ('G', 'minor'): '06A', ('D', 'minor'): '07A', ('A', 'minor'): '08A',\n",
                "        ('E', 'minor'): '09A', ('B', 'minor'): '10A', ('F#', 'minor'): '11A', ('C#', 'minor'): '12A'\n",
                "    }\n",
                "    return c_map.get((key, mode.lower()), \"00X\")\n",
                "\n",
                "def clean_name(n):\n",
                "    n = os.path.basename(n)\n",
                "    name = n.rsplit('.', 1)[0]\n",
                "    name = re.sub(r\"^[\\w\\-]+?-\", \"\", name)\n",
                "    name = re.sub(r\"[\\-\\_\\.]+?\", \" \", name).strip()\n",
                "    return f\"{name}.{n.rsplit('.', 1)[1]}\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "14736141",
            "metadata": {},
            "source": [
                "### 3. üöÄ High-Speed Pipeline Execution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03ed5e05",
            "metadata": {},
            "outputs": [],
            "source": [
                "# CONFIG\n",
                "INPUT_DIR = \"/kaggle/input/datasets/danieldobles/ost-songs\"\n",
                "OUTPUT_DIR = \"/kaggle/working/pro_sets\"\n",
                "BATCH_SIZE = 24\n",
                "TARGET_DUR = 60 * 60\n",
                "\n",
                "brain = SpectralBrainGPU(device=device)\n",
                "\n",
                "print(\"üîç Scanning Library...\")\n",
                "paths = []\n",
                "for ext in ['*.mp3', '*.wav', '*.flac', '*.m4a']:\n",
                "    paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\n",
                "paths = list(set(paths))\n",
                "\n",
                "# 1. Filter against Cache\n",
                "to_analyze = [p for p in paths if p not in brain.cache]\n",
                "print(f\"üì¶ Total: {len(paths)} | üß† Cached: {len(paths)-len(to_analyze)} | üöÄ New: {len(to_analyze)}\")\n",
                "\n",
                "if to_analyze:\n",
                "    chunks = [to_analyze[i:i+BATCH_SIZE] for i in range(0, len(to_analyze), BATCH_SIZE)]\n",
                "    with ThreadPoolExecutor(max_workers=4) as pool:\n",
                "        for chunk in tqdm(chunks, desc=\"üî• Analying Batches\"):\n",
                "            # Load CPU\n",
                "            def load(p):\n",
                "                try: \n",
                "                    y, _ = librosa.load(p, sr=22050); return (p, y, len(y)/22050)\n",
                "                except: return None\n",
                "            \n",
                "            batch_data = [x for x in list(pool.map(load, chunk)) if x is not None]\n",
                "            if not batch_data: continue\n",
                "            \n",
                "            # GPU Crunch\n",
                "            results = brain.process_batch(batch_data)\n",
                "            for r in results:\n",
                "                brain.cache[r['path']] = r\n",
                "            brain.save_cache()\n",
                "            gc.collect()\n",
                "\n",
                "# 2. Final Logic (Clustering)\n",
                "library = [brain.cache[p] for p in paths if p in brain.cache]\n",
                "# Sorting: Camelot -> Energy -> BPM\n",
                "library.sort(key=lambda x: (get_camelot(x['key'], x['mode']), x['energy'], x['bpm']))\n",
                "\n",
                "if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "os.makedirs(OUTPUT_DIR)\n",
                "\n",
                "sets, current, dur = [], [], 0\n",
                "for t in library:\n",
                "    current.append(t)\n",
                "    dur += t['duration']\n",
                "    if dur >= TARGET_DUR:\n",
                "        sets.append(current); current, dur = [], 0\n",
                "if current: sets.append(current)\n",
                "\n",
                "for i, s in enumerate(sets):\n",
                "    s_dir = os.path.join(OUTPUT_DIR, f\"SET_{str(i+1).zfill(2)}\")\n",
                "    os.makedirs(s_dir, exist_ok=True)\n",
                "    for idx, t in enumerate(s):\n",
                "        cam = get_camelot(t['key'], t['mode'])\n",
                "        meta = f\"[{cam} - {int(t['bpm'])}BPM]\"\n",
                "        shutil.copy2(t['path'], os.path.join(s_dir, f\"{str(idx+1).zfill(2)} - {meta} {clean_name(t['path'])}\"))\n",
                "\n",
                "print(f\"‚úÖ SUCCESS! Generated {len(sets)} professional sets.\")\n",
                "zip_name = \"SpectralAffinity_ProMixes.zip\"\n",
                "!zip -0 -rq {zip_name} pro_sets\n",
                "display(HTML(f\"<h3>üöÄ <a href='{zip_name}' id='dl'>DOWNLOAD FINAL MIXES</a></h3>\"))\n",
                "display(HTML(\"<script>setTimeout(() => document.getElementById('dl').click(), 1000);</script>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
