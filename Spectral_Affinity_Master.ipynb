{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity Master v6.3\n",
                "### 9-Stage Ultimate Suno Master Pipeline\n",
                "\n",
                "| # | Stage | Tech | Effect |\n",
                "|---|-------|------|--------|\n",
                "| 1 | üßπ Neural Clean | DeepFilterNet 3 | AI artifact removal |\n",
                "| 2 | üéõÔ∏è Spectral Shaper | STFT Stabilizer | Resonance / harshness control |\n",
                "| 3 | üåÄ Phase Shaper | STFT Phase | Phase coherence (-1 tight ‚Üê 0 ‚Üí +1 analog) |\n",
                "| 4 | üîÄ Stereo Wider | M/S + Haas | Synthetic stereo for mono Suno tracks |\n",
                "| 5 | üîä Mono-Bass | Linkwitz-Riley | Sub-bass phase ‚Üí mono |\n",
                "| 6 | üí• Transient Punch | Envelope Mask | Restore attack dynamics |\n",
                "| 7 | ‚ú® Spectre Restore | Harmonic Exciter | 48kHz high-end recovery |\n",
                "| 8 | üèùÔ∏è Affinity Grouping | MERT + K-Means | Neural semantic clustering |\n",
                "| 9 | üéöÔ∏è Mastering Match | Matchering | Reference loudness & tone |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-header",
            "metadata": {},
            "source": [
                "### 1. üõ†Ô∏è Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc\n",
                "import numpy as np\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, display\n",
                "import torchaudio.transforms as T\n",
                "import torchaudio.functional as F\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.cluster import KMeans as skKMeans\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f'üî• {torch.cuda.get_device_name(0) if device==\"cuda\" else \"CPU\"}')\n",
                "\n",
                "try:\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "except:\n",
                "    !pip install -q nnAudio transformers\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
                "\n",
                "HAS_DFN = False\n",
                "try:\n",
                "    from df.enhance import init_df, enhance as df_enhance; HAS_DFN = True\n",
                "except:\n",
                "    !pip install -q deepfilternet\n",
                "    try: from df.enhance import init_df, enhance as df_enhance; HAS_DFN = True\n",
                "    except: pass\n",
                "\n",
                "HAS_MATCHERING = False\n",
                "try:\n",
                "    import matchering as mg; HAS_MATCHERING = True\n",
                "except:\n",
                "    !pip install -q matchering\n",
                "    try: import matchering as mg; HAS_MATCHERING = True\n",
                "    except: pass\n",
                "\n",
                "try: from cuml.cluster import KMeans as cuKMeans; HAS_CUML = True\n",
                "except: HAS_CUML = False\n",
                "\n",
                "print(f\"{'‚úÖ' if HAS_DFN else '‚ö†Ô∏è'} DFN3 | {'‚úÖ' if HAS_MATCHERING else '‚ö†Ô∏è'} Matchering | {'‚úÖ' if HAS_CUML else '‚ÑπÔ∏è'} cuML\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "analysis-header",
            "metadata": {},
            "source": [
                "### 2. üß† Neural Analysis Engine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralMasterEngine:\n",
                "    def __init__(self, device='cuda', sr=24000, cache_file='spectral_master_cache.json'):\n",
                "        self.device, self.sr, self.cache_file = device, sr, cache_file\n",
                "        self.cache = json.load(open(cache_file)) if os.path.exists(cache_file) else {}\n",
                "        self.cqt = CQT1992v2(sr=sr, n_bins=84, bins_per_octave=12).to(device)\n",
                "        major = torch.tensor([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], device=device)\n",
                "        minor = torch.tensor([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major,i) for i in range(12)] + [torch.roll(minor,i) for i in range(12)]).t()\n",
                "        print('üß† Loading MERT...')\n",
                "        self.proc = Wav2Vec2FeatureExtractor.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True)\n",
                "        self.mert = AutoModel.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True).to(device).eval()\n",
                "\n",
                "    def save_cache(self): json.dump(self.cache, open(self.cache_file, 'w'))\n",
                "\n",
                "    def get_camelot(self, key, mode):\n",
                "        cm = {('B','major'):'01B',('F#','major'):'02B',('C#','major'):'03B',('G#','major'):'04B',\n",
                "              ('D#','major'):'05B',('A#','major'):'06B',('F','major'):'07B',('C','major'):'08B',\n",
                "              ('G','major'):'09B',('D','major'):'10B',('A','major'):'11B',('E','major'):'12B',\n",
                "              ('G#','minor'):'01A',('D#','minor'):'02A',('A#','minor'):'03A',('F','minor'):'04A',\n",
                "              ('C','minor'):'05A',('G','minor'):'06A',('D','minor'):'07A',('A','minor'):'08A',\n",
                "              ('E','minor'):'09A',('B','minor'):'10A',('F#','minor'):'11A',('C#','minor'):'12A'}\n",
                "        return cm.get((key, mode.lower()), '00X')\n",
                "\n",
                "    def process_batch(self, batch_data):\n",
                "        pc = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
                "        paths, audios, durs = [x[0] for x in batch_data], [x[1] for x in batch_data], [x[2] for x in batch_data]\n",
                "        t = torch.zeros(len(audios), self.sr*120, device=self.device)\n",
                "        for i,a in enumerate(audios): l=min(len(a),self.sr*120); t[i,:l]=torch.from_numpy(a[:l]).to(self.device)\n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt(t)\n",
                "            energy = spec.pow(2).mean(dim=(1,2)).cpu().numpy()\n",
                "            chroma = spec.view(len(audios),7,12,-1).sum(dim=(1,3))\n",
                "            chroma = chroma / (chroma.norm(dim=1,keepdim=True)+1e-6)\n",
                "            best = torch.argmax(torch.matmul(chroma, self.profiles), dim=1).cpu().numpy()\n",
                "            embs = []\n",
                "            for i in range(len(audios)):\n",
                "                mid = len(audios[i])//2; sl = int(self.sr*15)\n",
                "                s = audios[i][mid:mid+sl] if len(audios[i])>sl else audios[i]\n",
                "                iv = self.proc(s, sampling_rate=self.sr, return_tensors='pt').input_values.to(self.device)\n",
                "                embs.append(self.mert(iv).last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist())\n",
                "        results = []\n",
                "        for i in range(len(audios)):\n",
                "            r = {'key':pc[best[i]%12], 'mode':'major' if best[i]<12 else 'minor', 'energy':float(energy[i]),\n",
                "                 'duration':float(durs[i]), 'embedding':embs[i], 'path':paths[i]}\n",
                "            try: r['bpm']=float(librosa.beat.tempo(onset_envelope=librosa.onset.onset_strength(y=audios[i][:self.sr*60],sr=self.sr),sr=self.sr,aggregate=np.mean)[0])\n",
                "            except: r['bpm']=120.0\n",
                "            r['camelot'] = self.get_camelot(r['key'], r['mode'])\n",
                "            results.append(r)\n",
                "        return results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "restoration-header",
            "metadata": {},
            "source": [
                "### 3. üíé Ultimate Suno Master (7-Stage Restoration)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "restoration",
            "metadata": {},
            "outputs": [],
            "source": [
                "class UltimateSunoMaster:\n",
                "    def __init__(self, device='cuda', target_sr=48000, stages=None):\n",
                "        self.device, self.target_sr = device, target_sr\n",
                "        self.stages = stages or {'neural_clean':True,'spectral_shape':True,'phase_shape':True,'stereo_widen':True,'mono_bass':True,'transient_punch':True,'spectre_restore':True}\n",
                "        self.dfn_available = False\n",
                "        if self.stages.get('neural_clean') and HAS_DFN:\n",
                "            try: self._dfn_model, self._df_state, _ = init_df(); self.dfn_available = True; print('  ‚úÖ DFN3 loaded')\n",
                "            except Exception as e: print(f'  ‚ö†Ô∏è DFN3: {e}')\n",
                "\n",
                "    def _to_48k(self, wav, sr):\n",
                "        return T.Resample(sr, self.target_sr).to(self.device)(wav) if sr != self.target_sr else wav\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 1: Neural Clean ‚îÄ‚îÄ\n",
                "    def neural_clean(self, wav):\n",
                "        if not self.dfn_available: return wav\n",
                "        try: return df_enhance(self._dfn_model, self._df_state, wav, atten_lim_db=6)\n",
                "        except: return wav\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 2: Spectral Shaper (Stabilizer) ‚îÄ‚îÄ\n",
                "    def spectral_shape(self, wav, amount=60, speed=90, sensitivity=30, focus_low=200, focus_high=16000):\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        sens_db = 6.0 - (sensitivity/100.0*5.0); max_cut = (amount/100.0)*8.0; alpha = 0.05+(speed/100.0*0.45)\n",
                "        chs = []\n",
                "        for ch in range(wav.shape[0]):\n",
                "            stft = torch.stft(wav[ch], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "            mag, phase = stft.abs(), stft.angle()\n",
                "            env = torch.nn.functional.conv1d(mag.t().unsqueeze(1), torch.ones(1,1,31,device=self.device)/31, padding=15).squeeze(1).t()\n",
                "            excess = torch.clamp(20*torch.log10(mag+1e-8) - 20*torch.log10(env+1e-8) - sens_db, min=0)\n",
                "            gain = 10**(-torch.clamp(excess*0.8, max=max_cut)/20)\n",
                "            freqs = torch.linspace(0, sr/2, mag.shape[0]).to(self.device)\n",
                "            mask = ((freqs>=focus_low)&(freqs<=focus_high)).float().unsqueeze(1)\n",
                "            gain = gain*mask + (1.0-mask)\n",
                "            for t in range(1, gain.shape[1]): gain[:,t] = alpha*gain[:,t] + (1-alpha)*gain[:,t-1]\n",
                "            chs.append(torch.istft((mag*gain)*torch.exp(1j*phase), n_fft=n, hop_length=h, window=win, length=wav.shape[-1]))\n",
                "        return torch.stack(chs)\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 3: Phase Shaper (-1 linearize ‚Üê 0 ‚Üí +1 analogize) ‚îÄ‚îÄ\n",
                "    def phase_shape(self, wav, control=-0.3, stereo_link=True):\n",
                "        if abs(control) < 0.01: return wav\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        chs, ref_delta = [], None\n",
                "        for ch in range(wav.shape[0]):\n",
                "            stft = torch.stft(wav[ch], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "            mag, phase = stft.abs(), stft.angle()\n",
                "            if control < 0:\n",
                "                bi = torch.arange(phase.shape[0], dtype=torch.float32, device=self.device)\n",
                "                fi = torch.arange(phase.shape[1], dtype=torch.float32, device=self.device)\n",
                "                expected = phase[:,:1] + (2*np.pi*bi.unsqueeze(1)*h/n) * fi.unsqueeze(0)\n",
                "                delta = torch.atan2(torch.sin(phase-expected), torch.cos(phase-expected))\n",
                "                factor = 1.0 + control\n",
                "                if stereo_link and ch == 0: ref_delta = delta.clone()\n",
                "                if stereo_link and ch > 0 and ref_delta is not None:\n",
                "                    new_phase = expected + ref_delta*factor + (delta - ref_delta)\n",
                "                else:\n",
                "                    new_phase = expected + delta*factor\n",
                "            else:\n",
                "                freqs = torch.linspace(0, sr/2, phase.shape[0], device=self.device)\n",
                "                analog = 0.15*torch.exp(-((freqs-80)/60)**2) - 0.08*torch.exp(-((freqs-3000)/2000)**2) + 0.12*torch.sigmoid((freqs-8000)/2000)\n",
                "                new_phase = phase + analog.unsqueeze(1)*control\n",
                "            chs.append(torch.istft(mag*torch.exp(1j*new_phase), n_fft=n, hop_length=h, window=win, length=wav.shape[-1]))\n",
                "        return torch.stack(chs)\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 4: Stereo Wider (M/S + Synthetic Side) ‚îÄ‚îÄ\n",
                "    def stereo_widen(self, wav, width=0.3, generate_side=True):\n",
                "        if wav.shape[0] < 2: wav = wav.expand(2,-1).clone()\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        Ls = torch.stft(wav[0], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "        Rs = torch.stft(wav[1], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "        M, S = (Ls+Rs)/2, (Ls-Rs)/2\n",
                "        freqs = torch.linspace(0, sr/2, M.shape[0]).to(self.device)\n",
                "        # Generate synthetic side if track is nearly mono\n",
                "        ratio = (S.abs().pow(2).mean() / (M.abs().pow(2).mean()+1e-8)).item()\n",
                "        if generate_side and ratio < 0.05:\n",
                "            po = torch.linspace(0, 0.8, M.shape[0]).to(self.device) * torch.sigmoid((freqs-300)/200)\n",
                "            S = S + M.abs()*0.18*torch.exp(1j*(M.angle()+po.unsqueeze(1)))\n",
                "        # Freq-dependent width curve (bass narrow, presence wide, ultra-high rolloff)\n",
                "        wc = torch.ones_like(freqs)*width\n",
                "        wc *= torch.sigmoid((freqs-200)/100)\n",
                "        wc *= 1.0 + 0.5*torch.exp(-((freqs-5000)/3000)**2)\n",
                "        wc *= 1.0 - 0.3*torch.sigmoid((freqs-14000)/2000)\n",
                "        Sw = S*(1.0+wc.unsqueeze(1))\n",
                "        Lo = torch.istft(M+Sw, n_fft=n, hop_length=h, window=win, length=wav.shape[-1])\n",
                "        Ro = torch.istft(M-Sw, n_fft=n, hop_length=h, window=win, length=wav.shape[-1])\n",
                "        result = torch.stack([Lo, Ro])\n",
                "        pk = result.abs().max()\n",
                "        return result*(0.98/pk) if pk > 0.98 else result\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 5: Mono-Bass ‚îÄ‚îÄ\n",
                "    def mono_bass(self, wav, cutoff=150):\n",
                "        low = F.lowpass_biquad(F.lowpass_biquad(wav, self.target_sr, cutoff), self.target_sr, cutoff)\n",
                "        high = wav - low\n",
                "        if wav.shape[0] >= 2: low = low.mean(dim=0, keepdim=True).expand_as(low)\n",
                "        return low + high\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 6: Transient Punch ‚îÄ‚îÄ\n",
                "    def transient_punch(self, wav, boost_db=4.0):\n",
                "        sr = self.target_sr\n",
                "        mono = wav.mean(dim=0) if wav.shape[0]>=2 else wav.squeeze(0)\n",
                "        fl = int(sr*0.005); hp = fl//2\n",
                "        if fl < 2: return wav\n",
                "        p = torch.nn.functional.pad(mono, (fl//2, fl//2))\n",
                "        e = p.unfold(0, fl, hp).pow(2).mean(dim=-1).sqrt()\n",
                "        flux = torch.clamp(torch.diff(e, prepend=e[:1]), min=0)\n",
                "        if flux.max() < 1e-8: return wav\n",
                "        fn = flux/(flux.max()+1e-8); thr = fn.mean()+1.5*fn.std()\n",
                "        mask = torch.clamp((fn-thr)/(1.0-thr+1e-8), 0, 1)\n",
                "        gain = torch.nn.functional.interpolate(mask[None,None,:], size=wav.shape[-1], mode='linear', align_corners=False).squeeze()\n",
                "        rl = max(int(sr*0.025), 4)\n",
                "        k = torch.exp(-torch.arange(rl, device=self.device, dtype=torch.float32)/(rl/4))\n",
                "        k = (k/k.sum())[None,None,:]\n",
                "        gain = torch.nn.functional.conv1d(gain[None,None,:], k, padding=rl//2).squeeze()[:wav.shape[-1]]\n",
                "        r = wav*(1.0+gain.unsqueeze(0)*(10**(boost_db/20)-1.0))\n",
                "        pk = r.abs().max()\n",
                "        return r*(0.98/pk) if pk > 0.98 else r\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 7: Spectre Restore ‚îÄ‚îÄ\n",
                "    def spectre_restore(self, wav):\n",
                "        sr = self.target_sr\n",
                "        stft = torch.stft(wav[0], n_fft=4096, hop_length=1024, window=torch.hann_window(4096).to(self.device), return_complex=True)\n",
                "        mdb = 20*torch.log10(stft.abs().mean(dim=1)+1e-8)\n",
                "        freqs = torch.linspace(0, sr/2, mdb.shape[0]).to(self.device)\n",
                "        v = mdb > (mdb.max()-55)\n",
                "        co = freqs[v][-1].item() if v.any() else 16000.0\n",
                "        co = max(12000.0, min(co, 20000.0))\n",
                "        if co > 19500: return wav\n",
                "        e1 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, co*0.85)*1.8), sr, co*0.9)\n",
                "        e2 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, co)*3.0), sr, co)\n",
                "        y = wav + e1*0.07 + e2*0.12\n",
                "        pk = y.abs().max()\n",
                "        return y*(0.98/pk) if pk > 0.98 else y\n",
                "\n",
                "\n",
                "class MasteringEngine:\n",
                "    def __init__(self, ref=None):\n",
                "        self.ref, self.available = ref, False\n",
                "        if ref and os.path.exists(str(ref)) and HAS_MATCHERING:\n",
                "            self.available = True; print(f'  üéöÔ∏è Mastering ready | Ref: {os.path.basename(ref)}')\n",
                "        else: print('  ‚ÑπÔ∏è Mastering disabled' if not ref else f'  ‚ö†Ô∏è Ref not found: {ref}')\n",
                "    def master(self, inp, out):\n",
                "        if not self.available: shutil.copy2(inp,out) if inp!=out else None; return False\n",
                "        try: mg.process(target=inp, reference=self.ref, results=[mg.pcm16(out)]); return True\n",
                "        except Exception as e: print(f'  ‚ö†Ô∏è {e}'); shutil.copy2(inp,out) if inp!=out else None; return False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "logic-header",
            "metadata": {},
            "source": [
                "### 4. üåà Chromatic Flow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(c):\n",
                "    n, a = int(c[:2]), c[2]\n",
                "    return [f'{str(n).zfill(2)}{a}', f'{str((n%12)+1).zfill(2)}{a}', f'{str(((n-2)%12)+1).zfill(2)}{a}', f\"{str(n).zfill(2)}{'A' if a=='B' else 'B'}\"]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target):\n",
                "    if not tracks: return []\n",
                "    pool = list(tracks); cur = pool.pop(0); ordered = [cur]; dur = cur['duration']\n",
                "    while pool and dur < target:\n",
                "        ck = get_next_harmonic(cur['camelot'])\n",
                "        def sc(t):\n",
                "            h = 1.0 if t['camelot'] in ck else (0.8 if t['camelot']==cur['camelot'] else 0.0)\n",
                "            b = max(0, 1.0-(abs(t['bpm']-cur['bpm'])/40.0))\n",
                "            s = np.dot(cur['embedding'],t['embedding'])/(np.linalg.norm(cur['embedding'])*np.linalg.norm(t['embedding'])+1e-9)\n",
                "            return h*0.5+s*0.3+b*0.2\n",
                "        pool.sort(key=sc, reverse=True); nxt = pool.pop(0); ordered.append(nxt); dur += nxt['duration']; cur = nxt\n",
                "    return ordered\n",
                "\n",
                "def clean_name(n): return re.sub(r'[\\-\\_\\.]+?', ' ', re.sub(r'^[\\w\\-]+?-', '', os.path.basename(n).rsplit('.',1)[0])).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exec-header",
            "metadata": {},
            "source": [
                "### 5. üöÄ Execute Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exec",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "# ‚ïë  CONFIG ‚Äî SLAVIC SONGS v6.3                                  ‚ïë\n",
                "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "INPUT_DIR       = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "REFERENCE_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUTPUT_DIR      = '/kaggle/working/master_organized'\n",
                "TEMP_DIR        = '/kaggle/working/_temp_restore'\n",
                "BATCH_SIZE, SET_DUR, N_CLUSTERS = 16, 75*60, 3\n",
                "\n",
                "STAGES = {\n",
                "    'neural_clean':    True,   # 1. DFN3\n",
                "    'spectral_shape':  True,   # 2. Stabilizer\n",
                "    'phase_shape':     True,   # 3. Phase Shaper\n",
                "    'stereo_widen':    True,   # 4. Stereo Wider\n",
                "    'mono_bass':       True,   # 5. Sub mono\n",
                "    'transient_punch': True,   # 6. Punch\n",
                "    'spectre_restore': True,   # 7. HF Exciter\n",
                "    'matchering':      True,   # 9. Mastering Match\n",
                "}\n",
                "\n",
                "# ‚îÄ‚îÄ üéõÔ∏è STABILIZER ‚îÄ‚îÄ\n",
                "SHAPER = {'amount': 60, 'speed': 90, 'sensitivity': 30, 'focus_low': 200, 'focus_high': 16000}\n",
                "\n",
                "# ‚îÄ‚îÄ üåÄ PHASE SHAPER ‚îÄ‚îÄ\n",
                "PHASE_CONTROL = -0.3    # -1.0 (tight/linear) ‚Üê 0.0 (bypass) ‚Üí +1.0 (analog/warm)\n",
                "\n",
                "# ‚îÄ‚îÄ üîÄ STEREO WIDER ‚îÄ‚îÄ\n",
                "STEREO_WIDTH  = 0.3     # 0.0 (no change) to 1.0 (max width)\n",
                "\n",
                "# ‚îÄ‚îÄ Other ‚îÄ‚îÄ\n",
                "PUNCH_DB, BASS_HZ = 4.0, 150\n",
                "\n",
                "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
                "print('\\nüîß Initializing 9-Stage Pipeline...')\n",
                "analyzer  = SpectralMasterEngine(device=device, sr=24000)\n",
                "restorer  = UltimateSunoMaster(device=device, stages=STAGES)\n",
                "mastering = MasteringEngine(ref=REFERENCE_TRACK)\n",
                "\n",
                "# ‚îÄ‚îÄ Phase 1: Scan & Analyze ‚îÄ‚îÄ\n",
                "print('\\nüîç Scanning...')\n",
                "paths = sorted(set(sum([glob.glob(os.path.join(INPUT_DIR,'**',e), recursive=True) for e in ['*.mp3','*.wav','*.flac','*.m4a']], [])))\n",
                "print(f'   {len(paths)} tracks found')\n",
                "\n",
                "to_do = [p for p in paths if p not in analyzer.cache]\n",
                "if to_do:\n",
                "    for ci in range(0, len(to_do), BATCH_SIZE):\n",
                "        chunk = to_do[ci:ci+BATCH_SIZE]\n",
                "        bd = []\n",
                "        for p in chunk:\n",
                "            try: y,_=librosa.load(p, sr=24000); bd.append((p,y,len(y)/24000))\n",
                "            except: pass\n",
                "        if bd:\n",
                "            for r in analyzer.process_batch(bd): analyzer.cache[r['path']]=r\n",
                "            analyzer.save_cache(); gc.collect()\n",
                "\n",
                "# ‚îÄ‚îÄ Phase 2: Cluster & Sequence ‚îÄ‚îÄ\n",
                "library = [analyzer.cache[p] for p in paths if p in analyzer.cache]\n",
                "if not library: print('‚ùå No files')\n",
                "else:\n",
                "    X = normalize(np.array([t['embedding'] for t in library]))\n",
                "    labels = (cuKMeans(n_clusters=N_CLUSTERS) if HAS_CUML else skKMeans(n_clusters=N_CLUSTERS, n_init=10)).fit_predict(X)\n",
                "    clusters = {i: [library[j] for j,l in enumerate(labels) if l==i] for i in range(N_CLUSTERS)}\n",
                "    if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "    os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "\n",
                "    # ‚îÄ‚îÄ Phase 3: Restore, Sequence & Master ‚îÄ‚îÄ\n",
                "    print('\\nüåà Processing with v6.3 pipeline...')\n",
                "    total, failed = 0, 0\n",
                "    for ci, ct in clusters.items():\n",
                "        cn = f'Group_{chr(65+ci)}'; pool = sorted(ct, key=lambda x: x['energy']); si = 1\n",
                "        while pool:\n",
                "            oset = sequence_chromatic_set(pool, SET_DUR)\n",
                "            if not oset: break\n",
                "            pool = [t for t in pool if t['path'] not in {s['path'] for s in oset}]\n",
                "            sd = os.path.join(OUTPUT_DIR, cn, f'Set_{si}'); os.makedirs(sd, exist_ok=True)\n",
                "            for i, t in enumerate(tqdm(oset, desc=f'üíé {cn} Set {si}', leave=False)):\n",
                "                on = f\"{str(i+1).zfill(2)} - [{t['camelot']} - {int(t['bpm'])}BPM] {clean_name(t['path'])}.flac\"\n",
                "                fp, tp = os.path.join(sd, on), os.path.join(TEMP_DIR, f'tmp_{ci}_{si}_{i}.wav')\n",
                "                try:\n",
                "                    w, s = torchaudio.load(t['path']); w = restorer._to_48k(w.to(device), s)\n",
                "                    if STAGES.get('neural_clean'): w = restorer.neural_clean(w)\n",
                "                    if STAGES.get('spectral_shape'): w = restorer.spectral_shape(w, **SHAPER)\n",
                "                    if STAGES.get('phase_shape'): w = restorer.phase_shape(w, control=PHASE_CONTROL)\n",
                "                    if STAGES.get('stereo_widen'): w = restorer.stereo_widen(w, width=STEREO_WIDTH)\n",
                "                    if STAGES.get('mono_bass'): w = restorer.mono_bass(w, BASS_HZ)\n",
                "                    if STAGES.get('transient_punch'): w = restorer.transient_punch(w, PUNCH_DB)\n",
                "                    if STAGES.get('spectre_restore'): w = restorer.spectre_restore(w)\n",
                "                    torchaudio.save(tp, w.cpu(), 48000, encoding='PCM_S', bits_per_sample=16)\n",
                "                    if mastering.available: mastering.master(tp, fp); os.remove(tp)\n",
                "                    else: shutil.move(tp, fp)\n",
                "                except Exception as e:\n",
                "                    print(f'  ‚ö†Ô∏è {e}'); shutil.copy2(t['path'], fp); failed += 1\n",
                "                total += 1; gc.collect(); torch.cuda.empty_cache()\n",
                "            si += 1\n",
                "    shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
                "    print(f'\\n‚úÖ {total} tracks processed ({failed} failed)')\n",
                "    !zip -0 -rq SlavMaster_v6_3.zip master_organized\n",
                "    display(HTML(\"<h3>üöÄ <a href='SlavMaster_v6_3.zip' id='dl'>DOWNLOAD v6.3 MASTER</a></h3>\"))\n",
                "    display(HTML(\"<script>setTimeout(()=>document.getElementById('dl').click(),1000)</script>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}