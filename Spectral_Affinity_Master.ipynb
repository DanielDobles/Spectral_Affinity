{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "master-header",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity Master: Neural Chromatic Hybrid (v4.0)\n",
                "\n",
                "This system unifies **DSP-based Harmonic Mixing** with **Neural Semantic Affinity (MERT)** for the ultimate GPU-accelerated music organization experience.\n",
                "\n",
                "### üß¨ Professional Hybrid Logic:\n",
                "- üß† **Neural Brain (MERT):** Extracts deep sonic signatures to understand the 'vibe' and group affinity.\n",
                "- üî• **DSP Brain (nnAudio GPU):** Precision detection of Musical Key, Mode, Energy, and spectral intensity.\n",
                "- üåà **Chromatic Flow Engine:** Intelligent sequencing following the **Camelot Wheel** (e.g., 1B ‚Üí 2B or 1B ‚Üí 1A).\n",
                "- üèñÔ∏è **Island Clustering:** Groups tracks into semantic 'Islands' based on group affinity before sequencing.\n",
                "- üì¶ **Turbo-Batching:** Full CUDA saturation for lightning-fast analysis of large libraries."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-section",
            "metadata": {},
            "source": [
                "### 1. üõ†Ô∏è High-Performance Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc, pathlib\n",
                "import numpy as np\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, FileLink, display\n",
                "import torchaudio.transforms as T\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel, logging as hf_logging\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.cluster import AffinityPropagation, KMeans as skKMeans\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "hf_logging.set_verbosity_error()\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"üî• ACCELERATOR: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'}\")\n",
                "\n",
                "# üì¶ Install Missing GPU libs\n",
                "try:\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "except:\n",
                "    !pip install -q nnAudio transformers\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "\n",
                "try:\n",
                "    import cuml\n",
                "    from cuml.cluster import KMeans as cuKMeans\n",
                "    HAS_CUML = True\n",
                "except:\n",
                "    HAS_CUML = False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "engines-section",
            "metadata": {},
            "source": [
                "### 2. üß† The Unified Neural & DSP Core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "engines-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralMasterEngine:\n",
                "    def __init__(self, device='cuda', sr=22050, cache_file='spectral_master_cache.json'):\n",
                "        self.device = device\n",
                "        self.sr = sr\n",
                "        self.cache_file = cache_file\n",
                "        self.cache = self._load_cache()\n",
                "        \n",
                "        # 1. DSP Layers\n",
                "        self.cqt_layer = CQT1992v2(sr=self.sr, n_bins=84, bins_per_octave=12).to(self.device)\n",
                "        major = torch.tensor([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88], device=device)\n",
                "        minor = torch.tensor([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major, i) for i in range(12)] + \n",
                "                                    [torch.roll(minor, i) for i in range(12)]).t()\n",
                "        \n",
                "        # 2. Neural Layers (MERT)\n",
                "        print(\"üß† Loading MERT Neural Brain...\")\n",
                "        self.mert_model_id = \"m-a-p/MERT-v1-95M\"\n",
                "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(self.mert_model_id, trust_remote_code=True)\n",
                "        self.mert_model = AutoModel.from_pretrained(self.mert_model_id, trust_remote_code=True).to(self.device)\n",
                "        self.mert_model.eval()\n",
                "\n",
                "    def _load_cache(self):\n",
                "        if os.path.exists(self.cache_file):\n",
                "            with open(self.cache_file, 'r') as f: return json.load(f)\n",
                "        return {}\n",
                "\n",
                "    def save_cache(self):\n",
                "        with open(self.cache_file, 'w') as f: json.dump(self.cache, f)\n",
                "\n",
                "    def get_camelot(self, key, mode):\n",
                "        c_map = {\n",
                "            ('B', 'major'): '01B', ('F#', 'major'): '02B', ('C#', 'major'): '03B', ('G#', 'major'): '04B',\n",
                "            ('D#', 'major'): '05B', ('A#', 'major'): '06B', ('F', 'major'): '07B', ('C', 'major'): '08B',\n",
                "            ('G', 'major'): '09B', ('D', 'major'): '10B', ('A', 'major'): '11B', ('E', 'major'): '12B',\n",
                "            ('G#', 'minor'): '01A', ('D#', 'minor'): '02A', ('A#', 'minor'): '03A', ('F', 'minor'): '04A',\n",
                "            ('C', 'minor'): '05A', ('G', 'minor'): '06A', ('D', 'minor'): '07A', ('A', 'minor'): '08A',\n",
                "            ('E', 'minor'): '09A', ('B', 'minor'): '10A', ('F#', 'minor'): '11A', ('C#', 'minor'): '12A'\n",
                "        }\n",
                "        return c_map.get((key, mode.lower()), \"00X\")\n",
                "\n",
                "    def process_batch(self, batch_data):\n",
                "        paths = [x[0] for x in batch_data]\n",
                "        audios = [x[1] for x in batch_data]\n",
                "        durations = [x[2] for x in batch_data]\n",
                "        \n",
                "        max_len_dsp = self.sr * 120 # 2 mins for Key\n",
                "        \n",
                "        dsp_tensor = torch.zeros(len(audios), max_len_dsp, device=self.device)\n",
                "        for i, a in enumerate(audios):\n",
                "            l = min(len(a), max_len_dsp)\n",
                "            dsp_tensor[i, :l] = torch.from_numpy(a[:l]).to(self.device)\n",
                "\n",
                "        with torch.no_grad():\n",
                "            # --- A. DSP Logic ---\n",
                "            spec = self.cqt_layer(dsp_tensor)\n",
                "            energy = spec.pow(2).mean(dim=(1, 2)).cpu().numpy()\n",
                "            chroma = spec.view(len(audios), 7, 12, -1).sum(dim=(1, 3))\n",
                "            chroma = chroma / (chroma.norm(dim=1, keepdim=True) + 1e-6)\n",
                "            corrs = torch.matmul(chroma, self.profiles)\n",
                "            best_idx = torch.argmax(corrs, dim=1).cpu().numpy()\n",
                "            \n",
                "            # --- B. Neural Logic (MERT) ---\n",
                "            embeddings_list = []\n",
                "            pc = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
                "            \n",
                "            for i in range(len(audios)):\n",
                "                audio_slice = audios[i][len(audios[i])//4 : len(audios[i])//4 + 22050*15]\n",
                "                if len(audio_slice) < 22050*5: audio_slice = audios[i][:22050*15]\n",
                "                \n",
                "                input_values = self.processor(audio_slice, sampling_rate=22050, return_tensors=\"pt\").input_values.to(self.device)\n",
                "                out = self.mert_model(input_values)\n",
                "                emb = out.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
                "                embeddings_list.append(emb.tolist())\n",
                "                \n",
                "        batch_results = []\n",
                "        for i in range(len(audios)):\n",
                "            idx = best_idx[i]\n",
                "            res = {\n",
                "                'key': pc[idx % 12],\n",
                "                'mode': 'major' if idx < 12 else 'minor',\n",
                "                'energy': float(energy[i]),\n",
                "                'duration': float(durations[i]),\n",
                "                'embedding': embeddings_list[i],\n",
                "                'path': paths[i]\n",
                "            }\n",
                "            try:\n",
                "                onset = librosa.onset.onset_strength(y=audios[i][:22050*60], sr=22050)\n",
                "                res['bpm'] = float(librosa.beat.tempo(onset_envelope=onset, sr=22050, aggregate=np.mean)[0])\n",
                "            except: res['bpm'] = 120.0\n",
                "            res['camelot'] = self.get_camelot(res['key'], res['mode'])\n",
                "            batch_results.append(res)\n",
                "            \n",
                "        return batch_results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "logic-section",
            "metadata": {},
            "source": [
                "### 3. üåà Chromatic Mixer & Affinity Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "logic-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(current_cam):\n",
                "    \"\"\"\n",
                "    Calculates compatible Camelot keys for chromatic mixing.\n",
                "    Enables transitions like 1B -> 2B (next tone) or 1B -> 1A (parallel).\n",
                "    \"\"\"\n",
                "    num = int(current_cam[:2])\n",
                "    alpha = current_cam[2]\n",
                "    \n",
                "    neighbors = [\n",
                "        f\"{str(num).zfill(2)}{alpha}\",               # Constant (Stays in key)\n",
                "        f\"{str((num % 12) + 1).zfill(2)}{alpha}\",    # Chromatic (+1 step on wheel)\n",
                "        f\"{str(((num - 2) % 12) + 1).zfill(2)}{alpha}\", # Chromatic (-1 step on wheel)\n",
                "        f\"{str(num).zfill(2)}{'A' if alpha == 'B' else 'B'}\" # Parallel Mood Shift\n",
                "    ]\n",
                "    return neighbors\n",
                "\n",
                "def sequence_chromatic_set(tracks, target_duration):\n",
                "    \"\"\"\n",
                "    Advanced Greedy Sequencer:\n",
                "    Uses a hybrid scoring system to select the next track in the set.\n",
                "    Scores based on Harmonic Compatibility + Semantic Affinity + BPM Consistency.\n",
                "    \"\"\"\n",
                "    if not tracks: return []\n",
                "    \n",
                "    pool = list(tracks)\n",
                "    # Starting track (Seed)\n",
                "    current = pool.pop(0)\n",
                "    ordered_set = [current]\n",
                "    current_dur = current['duration']\n",
                "    \n",
                "    while pool and current_dur < target_duration:\n",
                "        compat_keys = get_next_harmonic(current['camelot'])\n",
                "        \n",
                "        def score(t):\n",
                "            # 1. Harmonic Score (Crucial for Chromatic Mixing)\n",
                "            # We give a slight edge to actually MOVING to a new compatible key for variety\n",
                "            if t['camelot'] == current['camelot']:\n",
                "                h_score = 0.8 # Good\n",
                "            elif t['camelot'] in compat_keys:\n",
                "                h_score = 1.0 # Best (Moves the wheel)\n",
                "            else:\n",
                "                h_score = 0.0 # Clash\n",
                "            \n",
                "            # 2. BPM Score (Ensures smooth tempo flow)\n",
                "            bpm_diff = abs(t['bpm'] - current['bpm'])\n",
                "            b_score = max(0, 1.0 - (bpm_diff / 40.0))\n",
                "            \n",
                "            # 3. Semantic Score (Group Affinity via MERT)\n",
                "            s_score = np.dot(current['embedding'], t['embedding']) / (np.linalg.norm(current['embedding']) * np.linalg.norm(t['embedding']) + 1e-9)\n",
                "            \n",
                "            # Final weighted score\n",
                "            return (h_score * 0.5) + (s_score * 0.3) + (b_score * 0.2)\n",
                "        \n",
                "        pool.sort(key=score, reverse=True)\n",
                "        next_t = pool.pop(0)\n",
                "        ordered_set.append(next_t)\n",
                "        current_dur += next_t['duration']\n",
                "        current = next_t\n",
                "        \n",
                "    return ordered_set\n",
                "\n",
                "def clean_name(n):\n",
                "    n = os.path.basename(n)\n",
                "    name = n.rsplit('.', 1)[0]\n",
                "    name = re.sub(r\"^[\\w\\-]+?-\", \"\", name)\n",
                "    name = re.sub(r\"[\\-\\_\\.]+?\", \" \", name).strip()\n",
                "    return f\"{name}.{n.rsplit('.', 1)[1]}\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "run-section",
            "metadata": {},
            "source": [
                "### 4. üöÄ Run Execution Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# CONFIG\n",
                "INPUT_DIR = \"/kaggle/input/datasets/danieldobles/ost-songs\"\n",
                "OUTPUT_DIR = \"/kaggle/working/master_sets\"\n",
                "BATCH_SIZE = 16\n",
                "SET_DUR = 75 * 60 # 75 mins per set\n",
                "N_CLUSTERS = 4    # Semantic Affinity groups\n",
                "\n",
                "master = SpectralMasterEngine(device=device)\n",
                "\n",
                "print(\"üîç Scanning Library...\")\n",
                "paths = []\n",
                "for ext in ['*.mp3', '*.wav', '*.flac', '*.m4a']:\n",
                "    paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\n",
                "paths = list(set(paths))\n",
                "\n",
                "to_analyze = [p for p in paths if p not in master.cache]\n",
                "print(f\"üì¶ Total: {len(paths)} | üß† Cached: {len(paths)-len(to_analyze)} | üöÄ New: {len(to_analyze)}\")\n",
                "\n",
                "if to_analyze:\n",
                "    chunks = [to_analyze[i:i+BATCH_SIZE] for i in range(0, len(to_analyze), BATCH_SIZE)]\n",
                "    with ThreadPoolExecutor(max_workers=2) as pool:\n",
                "        for chunk in tqdm(chunks, desc=\"üî• AI DSP Extraction\"):\n",
                "            def load(p):\n",
                "                try: y, _ = librosa.load(p, sr=22050); return (p, y, len(y)/22050)\n",
                "                except: return None\n",
                "            batch_data = [x for x in list(pool.map(load, chunk)) if x is not None]\n",
                "            if not batch_data: continue\n",
                "            results = master.process_batch(batch_data)\n",
                "            for r in results: master.cache[r['path']] = r\n",
                "            master.save_cache()\n",
                "            gc.collect()\n",
                "\n",
                "library = [master.cache[p] for p in paths if p in master.cache]\n",
                "\n",
                "# --- STEP A: Semantic Grouping (Affinity) ---\n",
                "print(\"üèñÔ∏è Clustering by Semantic Affinity...\")\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "if HAS_CUML:\n",
                "    p_labels = cuKMeans(n_clusters=N_CLUSTERS).fit_predict(X)\n",
                "else:\n",
                "    p_labels = skKMeans(n_clusters=N_CLUSTERS, n_init=10).fit_predict(X)\n",
                "\n",
                "clusters = {i: [] for i in range(N_CLUSTERS)}\n",
                "for i, l in enumerate(p_labels): clusters[l].append(library[i])\n",
                "\n",
                "# --- STEP B: Chromatic Sequencing within Clusters ---\n",
                "if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "\n",
                "print(\"üåà Sequencing Chromatic Sets...\")\n",
                "final_sets_count = 0\n",
                "for c_idx, cluster_tracks in clusters.items():\n",
                "    c_name = f\"Group_{chr(65+c_idx)}\"\n",
                "    cluster_tracks.sort(key=lambda x: x['energy'])\n",
                "    \n",
                "    temp_pool = list(cluster_tracks)\n",
                "    set_idx = 1\n",
                "    while temp_pool:\n",
                "        ordered_set = sequence_chromatic_set(temp_pool, SET_DUR)\n",
                "        if not ordered_set: break\n",
                "        \n",
                "        used_paths = {t['path'] for t in ordered_set}\n",
                "        temp_pool = [t for t in temp_pool if t['path'] not in used_paths]\n",
                "        \n",
                "        s_dir = os.path.join(OUTPUT_DIR, c_name, f\"Set_{set_idx}\")\n",
                "        os.makedirs(s_dir, exist_ok=True)\n",
                "        for i, t in enumerate(ordered_set):\n",
                "            meta = f\"[{t['camelot']} - {int(t['bpm'])}BPM]\"\n",
                "            filename = f\"{str(i+1).zfill(2)} - {meta} {clean_name(t['path'])}\"\n",
                "            shutil.copy2(t['path'], os.path.join(s_dir, filename))\n",
                "        \n",
                "        set_idx += 1\n",
                "        final_sets_count += 1\n",
                "\n",
                "print(f\"‚úÖ DONE! Generated {final_sets_count} chromatic sets in {N_CLUSTERS} affinity groups.\")\n",
                "zip_name = \"SpectralAffinity_MasterMix.zip\"\n",
                "!zip -0 -rq {zip_name} master_sets\n",
                "display(HTML(f\"<h3>üöÄ <a href='{zip_name}' id='dl'>DOWNLOAD MASTER MIXES</a></h3>\"))\n",
                "display(HTML(\"<script>setTimeout(() => document.getElementById('dl').click(), 1000);</script>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}