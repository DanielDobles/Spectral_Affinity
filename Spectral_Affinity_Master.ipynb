{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity Master v6.3\n",
                "### 9-Stage Ultimate Suno Master Pipeline\n",
                "\n",
                "| # | Stage | Tech | Effect |\n",
                "|---|-------|------|--------|\n",
                "| 1 | üßπ Neural Clean | DeepFilterNet 3 | AI artifact removal |\n",
                "| 2 | üéõÔ∏è Spectral Shaper | STFT Stabilizer | Resonance / harshness control |\n",
                "| 3 | üåÄ Phase Shaper | STFT Phase | Phase coherence (-1 tight ‚Üê 0 ‚Üí +1 analog) |\n",
                "| 4 | üîÄ Stereo Wider | M/S + Haas | Synthetic stereo for mono Suno tracks |\n",
                "| 5 | üîä Mono-Bass | Linkwitz-Riley | Sub-bass phase ‚Üí mono |\n",
                "| 6 | üí• Transient Punch | Envelope Mask | Restore attack dynamics |\n",
                "| 7 | ‚ú® Spectre Restore | Harmonic Exciter | 48kHz high-end recovery |\n",
                "| 8 | üèùÔ∏è Affinity Grouping | MERT + K-Means | Neural semantic clustering |\n",
                "| 9 | üéöÔ∏è Mastering Match | Matchering | Reference loudness & tone |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-header",
            "metadata": {},
            "source": [
                "### 1. üõ†Ô∏è Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc, sys\n",
                "import numpy as np\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, display, clear_output\n",
                "import torchaudio.transforms as T\n",
                "import torchaudio.functional as F\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.cluster import KMeans as skKMeans\n",
                "\n",
                "# ü§´ SHUT UP NOISE: Suppress CUDA/TF/Librosa warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "gpu_name = torch.cuda.get_device_name(0) if device=='cuda' else 'CPU'\n",
                "display(HTML(f\"\"\"\n",
                "<style>\n",
                "    .status-card {{ background: #1a1a1a; border-radius: 8px; padding: 15px; color: #00ffcc; font-family: 'Consolas', monospace; border-left: 5px solid #00ffcc; margin: 10px 0; }}\n",
                "</style>\n",
                "<div class='status-card'>üî• ENGINE READY: {gpu_name}</div>\n",
                "\"\"\"))\n",
                "\n",
                "try: from nnAudio.Spectrogram import CQT1992v2\n",
                "except: \n",
                "    !pip install -q nnAudio transformers deepfilternet matchering\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
                "\n",
                "HAS_CUML = False\n",
                "try: from cuml.cluster import KMeans as cuKMeans; HAS_CUML = True\n",
                "except: pass\n",
                "\n",
                "from ultimate_pipeline import UltimateSunoMaster, MasteringEngine, clean_name\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "analysis-header",
            "metadata": {},
            "source": [
                "### 2. üß† Neural Analysis Engine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralMasterEngine:\n",
                "    def __init__(self, device='cuda', sr=24000, cache_file='spectral_master_cache.json'):\n",
                "        self.device, self.sr, self.cache_file = device, sr, cache_file\n",
                "        self.cache = json.load(open(cache_file)) if os.path.exists(cache_file) else {}\n",
                "        self.cqt = CQT1992v2(sr=sr, n_bins=84, bins_per_octave=12, verbose=False).to(device)\n",
                "        major = torch.tensor([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], device=device)\n",
                "        minor = torch.tensor([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major,i) for i in range(12)] + [torch.roll(minor,i) for i in range(12)]).t()\n",
                "        self.proc = Wav2Vec2FeatureExtractor.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True)\n",
                "        self.mert = AutoModel.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True).to(device).eval()\n",
                "\n",
                "    def save_cache(self): json.dump(self.cache, open(self.cache_file, 'w'))\n",
                "\n",
                "    def get_camelot(self, key, mode):\n",
                "        cm = {('B','major'):'01B',('F#','major'):'02B',('C#','major'):'03B',('G#','major'):'04B',\n",
                "              ('D#','major'):'05B',('A#','major'):'06B',('F','major'):'07B',('C','major'):'08B',\n",
                "              ('G','major'):'09B',('D','major'):'10B',('A','major'):'11B',('E','major'):'12B',\n",
                "              ('G#','minor'):'01A',('D#','minor'):'02A',('A#','minor'):'03A',('F','minor'):'04A',\n",
                "              ('C','minor'):'05A',('G','minor'):'06A',('D','minor'):'07A',('A','minor'):'08A',\n",
                "              ('E','minor'):'09A',('B','minor'):'10A',('F#','minor'):'11A',('C#','minor'):'12A'}\n",
                "        return cm.get((key, mode.lower()), '00X')\n",
                "\n",
                "    def process_batch(self, paths_batch):\n",
                "        def load_one(p):\n",
                "            try:\n",
                "                w, s = torchaudio.load(p)\n",
                "                if s != self.sr: w = T.Resample(s, self.sr)(w)\n",
                "                w = w.mean(0)\n",
                "                if w.shape[0] > self.sr*120: w = w[:self.sr*120] # Max 2min for analysis\n",
                "                return w, len(w)/self.sr\n",
                "            except: return None\n",
                "        \n",
                "        # CPU Parallel Load\n",
                "        audios, durs, valid_p = [], [], []\n",
                "        with ThreadPoolExecutor() as pl: \n",
                "            res = list(pl.map(load_one, paths_batch))\n",
                "        for i, r in enumerate(res):\n",
                "            if r: audios.append(r[0]); durs.append(r[1]); valid_p.append(paths_batch[i])\n",
                "        \n",
                "        if not audios: return []\n",
                "        \n",
                "        # GPU Batch analysis\n",
                "        m_len = max([a.shape[0] for a in audios])\n",
                "        t = torch.zeros(len(audios), m_len, device=self.device)\n",
                "        for i, a in enumerate(audios): t[i, :a.shape[0]] = a.to(self.device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt(t)\n",
                "            energy = spec.pow(2).mean(dim=(1,2)).cpu().numpy()\n",
                "            chroma = spec.view(len(audios),7,12,-1).sum(dim=(1,3))\n",
                "            chroma = chroma / (chroma.norm(dim=1,keepdim=True)+1e-6)\n",
                "            best = torch.argmax(torch.matmul(chroma, self.profiles), dim=1).cpu().numpy()\n",
                "            embs = []\n",
                "            for i in range(len(audios)):\n",
                "                sl = int(self.sr*15); s = audios[i][:sl].cpu().numpy() # First 15s for MERT embs\n",
                "                iv = self.proc(s, sampling_rate=self.sr, return_tensors='pt').input_values.to(self.device)\n",
                "                embs.append(self.mert(iv).last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist())\n",
                "        \n",
                "        pc = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
                "        return [{'key':pc[best[i]%12], 'mode':'major' if best[i]<12 else 'minor', \n",
                "                 'energy':float(energy[i]), 'duration':float(durs[i]), \n",
                "                 'embedding':embs[i], 'path':valid_p[i], 'camelot': self.get_camelot(pc[best[i]%12], 'major' if best[i]<12 else 'minor'),\n",
                "                 'bpm': 120.0} for i in range(len(audios))]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "restoration-header",
            "metadata": {},
            "source": [
                "### 3. üíé Ultimate Suno Master (7-Stage Restoration)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "restoration",
            "metadata": {},
            "outputs": [],
            "source": [
                "class UltimateSunoMaster:\n",
                "    def __init__(self, device='cuda', target_sr=48000, stages=None):\n",
                "        self.device, self.target_sr = device, target_sr\n",
                "        self.stages = stages or {'neural_clean':True,'spectral_shape':True,'phase_shape':True,'stereo_widen':True,'mono_bass':True,'transient_punch':True,'spectre_restore':True}\n",
                "        self.dfn_available = False\n",
                "        if self.stages.get('neural_clean') and HAS_DFN:\n",
                "            try: self._dfn_model, self._df_state, _ = init_df(); self.dfn_available = True; print('  ‚úÖ DFN3 loaded')\n",
                "            except Exception as e: print(f'  ‚ö†Ô∏è DFN3: {e}')\n",
                "\n",
                "    def _to_48k(self, wav, sr):\n",
                "        return T.Resample(sr, self.target_sr).to(self.device)(wav) if sr != self.target_sr else wav\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 1: Neural Clean ‚îÄ‚îÄ\n",
                "    def neural_clean(self, wav):\n",
                "        if not self.dfn_available: return wav\n",
                "        try: return df_enhance(self._dfn_model, self._df_state, wav, atten_lim_db=6)\n",
                "        except: return wav\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 2: Spectral Shaper (Stabilizer) ‚îÄ‚îÄ\n",
                "    def spectral_shape(self, wav, amount=60, speed=90, sensitivity=30, focus_low=200, focus_high=16000):\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        sens_db = 6.0 - (sensitivity/100.0*5.0); max_cut = (amount/100.0)*8.0; alpha = 0.05+(speed/100.0*0.45)\n",
                "        chs = []\n",
                "        for ch in range(wav.shape[0]):\n",
                "            stft = torch.stft(wav[ch], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "            mag, phase = stft.abs(), stft.angle()\n",
                "            env = torch.nn.functional.conv1d(mag.t().unsqueeze(1), torch.ones(1,1,31,device=self.device)/31, padding=15).squeeze(1).t()\n",
                "            excess = torch.clamp(20*torch.log10(mag+1e-8) - 20*torch.log10(env+1e-8) - sens_db, min=0)\n",
                "            gain = 10**(-torch.clamp(excess*0.8, max=max_cut)/20)\n",
                "            freqs = torch.linspace(0, sr/2, mag.shape[0]).to(self.device)\n",
                "            mask = ((freqs>=focus_low)&(freqs<=focus_high)).float().unsqueeze(1)\n",
                "            gain = gain*mask + (1.0-mask)\n",
                "            for t in range(1, gain.shape[1]): gain[:,t] = alpha*gain[:,t] + (1-alpha)*gain[:,t-1]\n",
                "            chs.append(torch.istft((mag*gain)*torch.exp(1j*phase), n_fft=n, hop_length=h, window=win, length=wav.shape[-1]))\n",
                "        return torch.stack(chs)\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 3: Phase Shaper (-1 linearize ‚Üê 0 ‚Üí +1 analogize) ‚îÄ‚îÄ\n",
                "    def phase_shape(self, wav, control=-0.3, stereo_link=True):\n",
                "        if abs(control) < 0.01: return wav\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        chs, ref_delta = [], None\n",
                "        for ch in range(wav.shape[0]):\n",
                "            stft = torch.stft(wav[ch], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "            mag, phase = stft.abs(), stft.angle()\n",
                "            if control < 0:\n",
                "                bi = torch.arange(phase.shape[0], dtype=torch.float32, device=self.device)\n",
                "                fi = torch.arange(phase.shape[1], dtype=torch.float32, device=self.device)\n",
                "                expected = phase[:,:1] + (2*np.pi*bi.unsqueeze(1)*h/n) * fi.unsqueeze(0)\n",
                "                delta = torch.atan2(torch.sin(phase-expected), torch.cos(phase-expected))\n",
                "                factor = 1.0 + control\n",
                "                if stereo_link and ch == 0: ref_delta = delta.clone()\n",
                "                if stereo_link and ch > 0 and ref_delta is not None:\n",
                "                    new_phase = expected + ref_delta*factor + (delta - ref_delta)\n",
                "                else:\n",
                "                    new_phase = expected + delta*factor\n",
                "            else:\n",
                "                freqs = torch.linspace(0, sr/2, phase.shape[0], device=self.device)\n",
                "                analog = 0.15*torch.exp(-((freqs-80)/60)**2) - 0.08*torch.exp(-((freqs-3000)/2000)**2) + 0.12*torch.sigmoid((freqs-8000)/2000)\n",
                "                new_phase = phase + analog.unsqueeze(1)*control\n",
                "            chs.append(torch.istft(mag*torch.exp(1j*new_phase), n_fft=n, hop_length=h, window=win, length=wav.shape[-1]))\n",
                "        return torch.stack(chs)\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 4: Stereo Wider (M/S + Synthetic Side) ‚îÄ‚îÄ\n",
                "    def stereo_widen(self, wav, width=0.3, generate_side=True):\n",
                "        if wav.shape[0] < 2: wav = wav.expand(2,-1).clone()\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        Ls = torch.stft(wav[0], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "        Rs = torch.stft(wav[1], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "        M, S = (Ls+Rs)/2, (Ls-Rs)/2\n",
                "        freqs = torch.linspace(0, sr/2, M.shape[0]).to(self.device)\n",
                "        # Generate synthetic side if track is nearly mono\n",
                "        ratio = (S.abs().pow(2).mean() / (M.abs().pow(2).mean()+1e-8)).item()\n",
                "        if generate_side and ratio < 0.05:\n",
                "            po = torch.linspace(0, 0.8, M.shape[0]).to(self.device) * torch.sigmoid((freqs-300)/200)\n",
                "            S = S + M.abs()*0.18*torch.exp(1j*(M.angle()+po.unsqueeze(1)))\n",
                "        # Freq-dependent width curve (bass narrow, presence wide, ultra-high rolloff)\n",
                "        wc = torch.ones_like(freqs)*width\n",
                "        wc *= torch.sigmoid((freqs-200)/100)\n",
                "        wc *= 1.0 + 0.5*torch.exp(-((freqs-5000)/3000)**2)\n",
                "        wc *= 1.0 - 0.3*torch.sigmoid((freqs-14000)/2000)\n",
                "        Sw = S*(1.0+wc.unsqueeze(1))\n",
                "        Lo = torch.istft(M+Sw, n_fft=n, hop_length=h, window=win, length=wav.shape[-1])\n",
                "        Ro = torch.istft(M-Sw, n_fft=n, hop_length=h, window=win, length=wav.shape[-1])\n",
                "        result = torch.stack([Lo, Ro])\n",
                "        pk = result.abs().max()\n",
                "        return result*(0.98/pk) if pk > 0.98 else result\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 5: Mono-Bass ‚îÄ‚îÄ\n",
                "    def mono_bass(self, wav, cutoff=150):\n",
                "        low = F.lowpass_biquad(F.lowpass_biquad(wav, self.target_sr, cutoff), self.target_sr, cutoff)\n",
                "        high = wav - low\n",
                "        if wav.shape[0] >= 2: low = low.mean(dim=0, keepdim=True).expand_as(low)\n",
                "        return low + high\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 6: Transient Punch ‚îÄ‚îÄ\n",
                "    def transient_punch(self, wav, boost_db=4.0):\n",
                "        sr = self.target_sr\n",
                "        mono = wav.mean(dim=0) if wav.shape[0]>=2 else wav.squeeze(0)\n",
                "        fl = int(sr*0.005); hp = fl//2\n",
                "        if fl < 2: return wav\n",
                "        p = torch.nn.functional.pad(mono, (fl//2, fl//2))\n",
                "        e = p.unfold(0, fl, hp).pow(2).mean(dim=-1).sqrt()\n",
                "        flux = torch.clamp(torch.diff(e, prepend=e[:1]), min=0)\n",
                "        if flux.max() < 1e-8: return wav\n",
                "        fn = flux/(flux.max()+1e-8); thr = fn.mean()+1.5*fn.std()\n",
                "        mask = torch.clamp((fn-thr)/(1.0-thr+1e-8), 0, 1)\n",
                "        gain = torch.nn.functional.interpolate(mask[None,None,:], size=wav.shape[-1], mode='linear', align_corners=False).squeeze()\n",
                "        rl = max(int(sr*0.025), 4)\n",
                "        k = torch.exp(-torch.arange(rl, device=self.device, dtype=torch.float32)/(rl/4))\n",
                "        k = (k/k.sum())[None,None,:]\n",
                "        gain = torch.nn.functional.conv1d(gain[None,None,:], k, padding=rl//2).squeeze()[:wav.shape[-1]]\n",
                "        r = wav*(1.0+gain.unsqueeze(0)*(10**(boost_db/20)-1.0))\n",
                "        pk = r.abs().max()\n",
                "        return r*(0.98/pk) if pk > 0.98 else r\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 7: Spectre Restore ‚îÄ‚îÄ\n",
                "    def spectre_restore(self, wav):\n",
                "        sr = self.target_sr\n",
                "        stft = torch.stft(wav[0], n_fft=4096, hop_length=1024, window=torch.hann_window(4096).to(self.device), return_complex=True)\n",
                "        mdb = 20*torch.log10(stft.abs().mean(dim=1)+1e-8)\n",
                "        freqs = torch.linspace(0, sr/2, mdb.shape[0]).to(self.device)\n",
                "        v = mdb > (mdb.max()-55)\n",
                "        co = freqs[v][-1].item() if v.any() else 16000.0\n",
                "        co = max(12000.0, min(co, 20000.0))\n",
                "        if co > 19500: return wav\n",
                "        e1 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, co*0.85)*1.8), sr, co*0.9)\n",
                "        e2 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, co)*3.0), sr, co)\n",
                "        y = wav + e1*0.07 + e2*0.12\n",
                "        pk = y.abs().max()\n",
                "        return y*(0.98/pk) if pk > 0.98 else y\n",
                "\n",
                "\n",
                "class MasteringEngine:\n",
                "    def __init__(self, ref=None):\n",
                "        self.ref, self.available = ref, False\n",
                "        if ref and os.path.exists(str(ref)) and HAS_MATCHERING:\n",
                "            self.available = True; print(f'  üéöÔ∏è Mastering ready | Ref: {os.path.basename(ref)}')\n",
                "        else: print('  ‚ÑπÔ∏è Mastering disabled' if not ref else f'  ‚ö†Ô∏è Ref not found: {ref}')\n",
                "    def master(self, inp, out):\n",
                "        if not self.available: shutil.copy2(inp,out) if inp!=out else None; return False\n",
                "        try: mg.process(target=inp, reference=self.ref, results=[mg.pcm16(out)]); return True\n",
                "        except Exception as e: print(f'  ‚ö†Ô∏è {e}'); shutil.copy2(inp,out) if inp!=out else None; return False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "logic-header",
            "metadata": {},
            "source": [
                "### 4. üåà Chromatic Flow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(c):\n",
                "    n, a = int(c[:2]), c[2]\n",
                "    return [f'{str(n).zfill(2)}{a}', f'{str((n%12)+1).zfill(2)}{a}', f'{str(((n-2)%12)+1).zfill(2)}{a}', f\"{str(n).zfill(2)}{'A' if a=='B' else 'B'}\"]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target):\n",
                "    if not tracks: return []\n",
                "    pool = list(tracks); cur = pool.pop(0); ordered = [cur]; dur = cur['duration']\n",
                "    while pool and dur < target:\n",
                "        ck = get_next_harmonic(cur['camelot'])\n",
                "        def sc(t):\n",
                "            h = 1.0 if t['camelot'] in ck else (0.8 if t['camelot']==cur['camelot'] else 0.0)\n",
                "            b = max(0, 1.0-(abs(t['bpm']-cur['bpm'])/40.0))\n",
                "            s = np.dot(cur['embedding'],t['embedding'])/(np.linalg.norm(cur['embedding'])*np.linalg.norm(t['embedding'])+1e-9)\n",
                "            return h*0.5+s*0.3+b*0.2\n",
                "        pool.sort(key=sc, reverse=True); nxt = pool.pop(0); ordered.append(nxt); dur += nxt['duration']; cur = nxt\n",
                "    return ordered\n",
                "\n",
                "def clean_name(n): return re.sub(r'[\\-\\_\\.]+?', ' ', re.sub(r'^[\\w\\-]+?-', '', os.path.basename(n).rsplit('.',1)[0])).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exec-header",
            "metadata": {},
            "source": [
                "### 5. üöÄ Execute Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exec",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONFIG ===\n",
                "INPUT_DIR       = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "REFERENCE_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUTPUT_DIR      = '/kaggle/working/master_organized'\n",
                "TEMP_DIR        = '/kaggle/working/_temp_restore'\n",
                "BATCH_SIZE, SET_DUR, N_CLUSTERS = 16, 75*60, 3\n",
                "\n",
                "STAGES = {'neural_clean':True,'spectral_shape':True,'phase_shape':True,'stereo_widen':True,'mono_bass':True,'transient_punch':True,'spectre_restore':True,'matchering':True}\n",
                "SHAPER = {'amount': 60, 'speed': 90, 'sensitivity': 30}\n",
                "PHASE_CONTROL, STEREO_WIDTH = -0.3, 0.3\n",
                "\n",
                "print('\\nüîß Warming Up Pipeline...')\n",
                "analyzer = SpectralMasterEngine(device=device); restorer = UltimateSunoMaster(device=device, stages=STAGES); mastering = MasteringEngine(ref=REFERENCE_TRACK)\n",
                "\n",
                "paths = sorted(set(sum([glob.glob(os.path.join(INPUT_DIR,'**',e), recursive=True) for e in ['*.mp3','*.wav','*.flac','*.m4a']], [])))\n",
                "to_do = [p for p in paths if p not in analyzer.cache]\n",
                "if to_do:\n",
                "    print(f'üîç Analyzing {len(to_do)} new tracks...')\n",
                "    for i in range(0, len(to_do), BATCH_SIZE):\n",
                "        for r in analyzer.process_batch(to_do[i:i+BATCH_SIZE]): analyzer.cache[r['path']]=r\n",
                "        analyzer.save_cache()\n",
                "\n",
                "library = [analyzer.cache[p] for p in paths if p in analyzer.cache]\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "labels = (cuKMeans(n_clusters=N_CLUSTERS) if HAS_CUML else skKMeans(n_clusters=N_CLUSTERS, n_init=10)).fit_predict(X)\n",
                "clusters = {i: [library[j] for j,l in enumerate(labels) if l==i] for i in range(N_CLUSTERS)}\n",
                "\n",
                "if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "\n",
                "# ‚îÄ‚îÄ DASHBOARD LOGIC ‚îÄ‚îÄ\n",
                "dashboard_html = \"\"\"\n",
                "<style>\n",
                "    .dash {{ background: #000; color: #fff; padding: 20px; border-radius: 12px; font-family: 'Segoe UI', sans-serif; border: 1px solid #333; }}\n",
                "    .bar {{ height: 10px; background: #333; border-radius: 5px; margin: 10px 0; overflow: hidden; }}\n",
                "    .fill {{ height: 100%; background: linear-gradient(90deg, #00f2fe, #4facfe); width: 0%; transition: width 0.3s; }}\n",
                "    .stat {{ font-size: 13px; color: #aaa; margin: 5px 0; }}\n",
                "    .err-box {{ background: #300; border: 1px solid #f33; padding: 10px; margin-top: 15px; border-radius: 6px; display: none; }}\n",
                "    .err-item {{ font-size: 12px; border-bottom: 1px solid #500; padding: 4px 0; color: #ff9999; }}\n",
                "</style>\n",
                "<div class='dash' id='dash'>\n",
                "    <h2 style='margin:0; color:#4facfe'>üíé SPECTRAL AFFINITY DASHBOARD</h2>\n",
                "    <div class='stat' id='current-track'>Initializing engine...</div>\n",
                "    <div class='bar'><div class='fill' id='prog'></div></div>\n",
                "    <div style='display:flex; justify-content:space-between'>\n",
                "        <span class='stat' id='count'>0/0</span>\n",
                "        <span class='stat' id='perc'>0%</span>\n",
                "    </div>\n",
                "    <div class='err-box' id='err-box'>\n",
                "        <div style='color:#f33; font-weight:bold; margin-bottom:5px'>üõ∏ INCIDENT REPORT (Errors detected)</div>\n",
                "        <div id='err-list'></div>\n",
                "    </div>\n",
                "</div>\n",
                "\"\"\"\n",
                "display(HTML(dashboard_html))\n",
                "\n",
                "def update_ui(idx, total, name, errors):\n",
                "    p = int((idx/total)*100)\n",
                "    js = f\"\"\"\n",
                "    document.getElementById('prog').style.width = '{p}%';\n",
                "    document.getElementById('current-track').innerText = 'Processing: {name}';\n",
                "    document.getElementById('count').innerText = '{idx}/{total}';\n",
                "    document.getElementById('perc').innerText = '{p}%';\n",
                "    \"\"\"\n",
                "    if errors:\n",
                "        items = \"\".join([f\"<div class='err-item'>‚ö†Ô∏è Stage: {e['stage']} | File: {e['file']} | {e['msg']}</div>\" for e in errors[-5:]])\n",
                "        js += f\"document.getElementById('err-box').style.display = 'block';\"\n",
                "        js += f\"document.getElementById('err-list').innerHTML = `{items}`;\"\n",
                "    display(HTML(f\"<script>{js}</script>\"))\n",
                "\n",
                "# ‚îÄ‚îÄ PROCESSOR ‚îÄ‚îÄ\n",
                "master_pool = ThreadPoolExecutor(max_workers=1)\n",
                "futures, incident_logs = [], []\n",
                "total_tracks = sum(len(c) for c in clusters.values())\n",
                "processed_count = 0\n",
                "\n",
                "for ci, ct in clusters.items():\n",
                "    cn = f'Group_{chr(65+ci)}'; pool = sorted(ct, key=lambda x: x['energy']); si = 1\n",
                "    while pool:\n",
                "        oset = sequence_chromatic_set(pool, SET_DUR)\n",
                "        if not oset: break\n",
                "        pool = [t for t in pool if t['path'] not in {s['path'] for s in oset}]\n",
                "        sd = os.path.join(OUTPUT_DIR, cn, f'Set_{si}'); os.makedirs(sd, exist_ok=True)\n",
                "        for i, t in enumerate(oset):\n",
                "            on = f\"{str(i+1).zfill(2)} - [{t['camelot']}] {clean_name(t['path'])}.flac\"\n",
                "            fp, tp = os.path.join(sd, on), os.path.join(TEMP_DIR, f'tmp_{ci}_{si}_{i}.wav')\n",
                "            \n",
                "            res = restorer.process_track(t['path'], tp, shaper_params=SHAPER, phase_control=PHASE_CONTROL, stereo_width=STEREO_WIDTH)\n",
                "            if res['status'] == 'ok':\n",
                "                futures.append(master_pool.submit(lambda p1, p2: mastering.master(p1, p2) or os.remove(p1) if mastering.available else shutil.move(p1, p2), tp, fp))\n",
                "            else:\n",
                "                incident_logs.append({'file': clean_name(t['path']), 'stage': res['stage'], 'msg': res['msg']})\n",
                "                shutil.copy2(t['path'], fp)\n",
                "            \n",
                "            processed_count += 1\n",
                "            if processed_count % 2 == 0: update_ui(processed_count, total_tracks, clean_name(t['path']), incident_logs)\n",
                "            if processed_count % 10 == 0: gc.collect(); torch.cuda.empty_cache()\n",
                "        si += 1\n",
                "\n",
                "update_ui(total_tracks, total_tracks, \"Mastering Completed\", incident_logs)\n",
                "master_pool.shutdown(); shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
                "!zip -0 -rq SlavMaster_v6_3.zip master_organized\n",
                "display(HTML(\"<h3>üöÄ <a href='SlavMaster_v6_3.zip' id='dl'>DOWNLOAD v6.3 MASTER</a></h3>\"))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}