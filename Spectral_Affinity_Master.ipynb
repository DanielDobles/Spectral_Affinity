{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "master-header",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity Master: Ultimate Suno Master Pipeline (v6.0)\n",
                "\n",
                "**6-Stage Professional Restoration** specifically engineered for AI-generated audio (Suno, Udio, etc.)  \n",
                "combined with **Neural Semantic Affinity** for intelligent track organization.\n",
                "\n",
                "### üöÄ The Pipeline:\n",
                "| # | Stage | What It Does | Speed |\n",
                "|---|-------|-------------|-------|\n",
                "| 1 | üßπ **Neural Cleaning** (DeepFilterNet 3) | AI artifact & noise removal | ~2s/track |\n",
                "| 2 | üîä **Mono-Bass Phase Correction** | Solid low-end (< 150Hz ‚Üí mono) | instant |\n",
                "| 3 | üí• **Transient Re-synthesis (Punch)** | Restore dynamics & attack energy | instant |\n",
                "| 4 | ‚ú® **Spectre Restoration** | Multi-band harmonic exciter (48kHz) | ~1s/track |\n",
                "| 5 | üèùÔ∏è **Affinity Grouping** (MERT + K-Means) | Neural semantic clustering + Camelot | batch |\n",
                "| 6 | üéöÔ∏è **Mastering Match** (Matchering) | Reference-based loudness & tone | ~3s/track |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-section",
            "metadata": {},
            "source": [
                "### 1. üõ†Ô∏è Ultimate Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc, pathlib\n",
                "import numpy as np\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, FileLink, display\n",
                "import torchaudio.transforms as T\n",
                "import torchaudio.functional as F\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel, logging as hf_logging\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.cluster import KMeans as skKMeans\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "hf_logging.set_verbosity_error()\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"üî• ACCELERATOR: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'}\")\n",
                "\n",
                "# ‚îÄ‚îÄ Core DSP ‚îÄ‚îÄ\n",
                "try:\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "except:\n",
                "    !pip install -q nnAudio transformers\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "\n",
                "# ‚îÄ‚îÄ DeepFilterNet 3 ‚îÄ‚îÄ\n",
                "try:\n",
                "    from df.enhance import init_df, enhance as df_enhance\n",
                "    HAS_DFN = True\n",
                "except:\n",
                "    !pip install -q deepfilternet\n",
                "    try:\n",
                "        from df.enhance import init_df, enhance as df_enhance\n",
                "        HAS_DFN = True\n",
                "    except:\n",
                "        HAS_DFN = False\n",
                "print(f\"{'‚úÖ' if HAS_DFN else '‚ö†Ô∏è'} DeepFilterNet 3: {'ready' if HAS_DFN else 'unavailable (skipping neural clean)'}\")\n",
                "\n",
                "# ‚îÄ‚îÄ Matchering ‚îÄ‚îÄ\n",
                "try:\n",
                "    import matchering as mg\n",
                "    HAS_MATCHERING = True\n",
                "except:\n",
                "    !pip install -q matchering\n",
                "    try:\n",
                "        import matchering as mg\n",
                "        HAS_MATCHERING = True\n",
                "    except:\n",
                "        HAS_MATCHERING = False\n",
                "print(f\"{'‚úÖ' if HAS_MATCHERING else '‚ö†Ô∏è'} Matchering: {'ready' if HAS_MATCHERING else 'unavailable (skipping mastering match)'}\")\n",
                "\n",
                "# ‚îÄ‚îÄ cuML (optional GPU clustering) ‚îÄ‚îÄ\n",
                "try:\n",
                "    from cuml.cluster import KMeans as cuKMeans\n",
                "    HAS_CUML = True\n",
                "except:\n",
                "    HAS_CUML = False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "engines-section",
            "metadata": {},
            "source": [
                "### 2. üß† Neural Analysis Engine (MERT + DSP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "engines-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralMasterEngine:\n",
                "    def __init__(self, device='cuda', sr=24000, cache_file='spectral_master_cache.json'):\n",
                "        self.device = device\n",
                "        self.sr = sr\n",
                "        self.cache_file = cache_file\n",
                "        self.cache = self._load_cache()\n",
                "        \n",
                "        self.cqt_layer = CQT1992v2(sr=self.sr, n_bins=84, bins_per_octave=12).to(self.device)\n",
                "        major = torch.tensor([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88], device=device)\n",
                "        minor = torch.tensor([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major, i) for i in range(12)] + \n",
                "                                    [torch.roll(minor, i) for i in range(12)]).t()\n",
                "        \n",
                "        print(\"üß† Loading MERT Neural Brain...\")\n",
                "        self.mert_model_id = \"m-a-p/MERT-v1-95M\"\n",
                "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(self.mert_model_id, trust_remote_code=True)\n",
                "        self.mert_model = AutoModel.from_pretrained(self.mert_model_id, trust_remote_code=True).to(self.device)\n",
                "        self.mert_model.eval()\n",
                "\n",
                "    def _load_cache(self):\n",
                "        if os.path.exists(self.cache_file):\n",
                "            with open(self.cache_file, 'r') as f: return json.load(f)\n",
                "        return {}\n",
                "\n",
                "    def save_cache(self):\n",
                "        with open(self.cache_file, 'w') as f: json.dump(self.cache, f)\n",
                "\n",
                "    def get_camelot(self, key, mode):\n",
                "        c_map = {\n",
                "            ('B', 'major'): '01B', ('F#', 'major'): '02B', ('C#', 'major'): '03B', ('G#', 'major'): '04B',\n",
                "            ('D#', 'major'): '05B', ('A#', 'major'): '06B', ('F', 'major'): '07B', ('C', 'major'): '08B',\n",
                "            ('G', 'major'): '09B', ('D', 'major'): '10B', ('A', 'major'): '11B', ('E', 'major'): '12B',\n",
                "            ('G#', 'minor'): '01A', ('D#', 'minor'): '02A', ('A#', 'minor'): '03A', ('F', 'minor'): '04A',\n",
                "            ('C', 'minor'): '05A', ('G', 'minor'): '06A', ('D', 'minor'): '07A', ('A', 'minor'): '08A',\n",
                "            ('E', 'minor'): '09A', ('B', 'minor'): '10A', ('F#', 'minor'): '11A', ('C#', 'minor'): '12A'\n",
                "        }\n",
                "        return c_map.get((key, mode.lower()), \"00X\")\n",
                "\n",
                "    def process_batch(self, batch_data):\n",
                "        paths = [x[0] for x in batch_data]\n",
                "        audios = [x[1] for x in batch_data]\n",
                "        durations = [x[2] for x in batch_data]\n",
                "        dsp_tensor = torch.zeros(len(audios), self.sr * 120, device=self.device)\n",
                "        for i, a in enumerate(audios):\n",
                "            l = min(len(a), self.sr * 120)\n",
                "            dsp_tensor[i, :l] = torch.from_numpy(a[:l]).to(self.device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt_layer(dsp_tensor)\n",
                "            energy = spec.pow(2).mean(dim=(1, 2)).cpu().numpy()\n",
                "            chroma = spec.view(len(audios), 7, 12, -1).sum(dim=(1, 3))\n",
                "            chroma = chroma / (chroma.norm(dim=1, keepdim=True) + 1e-6)\n",
                "            corrs = torch.matmul(chroma, self.profiles)\n",
                "            best_idx = torch.argmax(corrs, dim=1).cpu().numpy()\n",
                "            \n",
                "            embeddings_list = []\n",
                "            pc = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
                "            for i in range(len(audios)):\n",
                "                mid = len(audios[i])//2\n",
                "                slice_len = int(self.sr * 15)\n",
                "                audio_slice = audios[i][mid : mid + slice_len] if len(audios[i]) > slice_len else audios[i]\n",
                "                input_values = self.processor(audio_slice, sampling_rate=self.sr, return_tensors=\"pt\").input_values.to(self.device)\n",
                "                emb = self.mert_model(input_values).last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
                "                embeddings_list.append(emb.tolist())\n",
                "                \n",
                "        results = []\n",
                "        for i in range(len(audios)):\n",
                "            res = {\n",
                "                'key': pc[best_idx[i] % 12], 'mode': 'major' if best_idx[i] < 12 else 'minor',\n",
                "                'energy': float(energy[i]), 'duration': float(durations[i]), \n",
                "                'embedding': embeddings_list[i], 'path': paths[i]\n",
                "            }\n",
                "            try:\n",
                "                onset = librosa.onset.onset_strength(y=audios[i][:self.sr*60], sr=self.sr)\n",
                "                res['bpm'] = float(librosa.beat.tempo(onset_envelope=onset, sr=self.sr, aggregate=np.mean)[0])\n",
                "            except: res['bpm'] = 120.0\n",
                "            res['camelot'] = self.get_camelot(res['key'], res['mode'])\n",
                "            results.append(res)\n",
                "        return results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "restoration-section",
            "metadata": {},
            "source": [
                "### 3. üíé Ultimate Suno Master: 6-Stage Restoration Pipeline\n",
                "\n",
                "| Stage | Technology | Purpose |\n",
                "|-------|-----------|----------|\n",
                "| üßπ Neural Clean | DeepFilterNet 3 (AI) | Remove compression artifacts, digital fizz |\n",
                "| üîä Mono-Bass | Linkwitz-Riley Crossover | Phase-coherent solid low-end |\n",
                "| üí• Transient Punch | Envelope Follower + Gain Mask | Restore dynamics Suno crushes |\n",
                "| ‚ú® Spectre Restore | Multi-band Harmonic Exciter | Recover lost high frequencies |\n",
                "| üéöÔ∏è Mastering Match | Matchering (DSP) | Match loudness & tone to reference |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "restoration-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class UltimateSunoMaster:\n",
                "    \"\"\"4-Stage GPU-accelerated restoration for AI-generated audio.\"\"\"\n",
                "\n",
                "    def __init__(self, device='cuda', target_sr=48000, stages=None):\n",
                "        self.device = device\n",
                "        self.target_sr = target_sr\n",
                "        self.stages = stages or {'neural_clean': True, 'mono_bass': True, 'transient_punch': True, 'spectre_restore': True}\n",
                "        self.dfn_available = False\n",
                "        if self.stages.get('neural_clean') and HAS_DFN:\n",
                "            try:\n",
                "                self._dfn_model, self._df_state, _ = init_df()\n",
                "                self.dfn_available = True\n",
                "                print('  ‚úÖ DeepFilterNet 3 model loaded')\n",
                "            except Exception as e:\n",
                "                print(f'  ‚ö†Ô∏è DFN3 init failed: {e}')\n",
                "\n",
                "    def _to_48k(self, wav, sr):\n",
                "        if sr != self.target_sr:\n",
                "            return T.Resample(sr, self.target_sr).to(self.device)(wav)\n",
                "        return wav\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 1: Neural Cleaning (DeepFilterNet 3) ‚îÄ‚îÄ\n",
                "    def neural_clean(self, wav):\n",
                "        if not self.dfn_available: return wav\n",
                "        try:\n",
                "            return df_enhance(self._dfn_model, self._df_state, wav, atten_lim_db=6)\n",
                "        except: return wav\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 2: Mono-Bass Phase Correction ‚îÄ‚îÄ\n",
                "    def mono_bass(self, wav, cutoff=150):\n",
                "        sr = self.target_sr\n",
                "        low = F.lowpass_biquad(wav, sr, cutoff)\n",
                "        low = F.lowpass_biquad(low, sr, cutoff)  # Linkwitz-Riley\n",
                "        high = wav - low\n",
                "        if wav.shape[0] >= 2:\n",
                "            low = low.mean(dim=0, keepdim=True).expand_as(low)\n",
                "        return low + high\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 3: Transient Re-synthesis (Punch) ‚îÄ‚îÄ\n",
                "    def transient_punch(self, wav, boost_db=4.0, release_ms=25):\n",
                "        sr = self.target_sr\n",
                "        mono = wav.mean(dim=0) if wav.shape[0] >= 2 else wav.squeeze(0)\n",
                "        frame_len = int(sr * 0.005)  # 5ms frames\n",
                "        hop = frame_len // 2\n",
                "        if frame_len < 2: return wav\n",
                "\n",
                "        padded = torch.nn.functional.pad(mono, (frame_len//2, frame_len//2))\n",
                "        energy = padded.unfold(0, frame_len, hop).pow(2).mean(dim=-1).sqrt()\n",
                "\n",
                "        # Positive spectral flux = onset detection\n",
                "        flux = torch.clamp(torch.diff(energy, prepend=energy[:1]), min=0)\n",
                "        if flux.max() < 1e-8: return wav\n",
                "        flux_n = flux / (flux.max() + 1e-8)\n",
                "        thr = flux_n.mean() + 1.5 * flux_n.std()\n",
                "        mask = torch.clamp((flux_n - thr) / (1.0 - thr + 1e-8), 0, 1)\n",
                "\n",
                "        # Upsample to sample resolution\n",
                "        gain = torch.nn.functional.interpolate(\n",
                "            mask[None, None, :], size=wav.shape[-1], mode='linear', align_corners=False\n",
                "        ).squeeze()\n",
                "\n",
                "        # Release smoothing kernel\n",
                "        rel = max(int(sr * release_ms / 1000), 4)\n",
                "        k = torch.exp(-torch.arange(rel, device=self.device, dtype=torch.float32) / (rel/4))\n",
                "        k = (k / k.sum())[None, None, :]\n",
                "        gain = torch.nn.functional.conv1d(gain[None, None, :], k, padding=rel//2).squeeze()[:wav.shape[-1]]\n",
                "\n",
                "        # Apply transient boost\n",
                "        boost = 10 ** (boost_db / 20)\n",
                "        result = wav * (1.0 + gain.unsqueeze(0) * (boost - 1.0))\n",
                "        peak = result.abs().max()\n",
                "        return result * (0.98 / peak) if peak > 0.98 else result\n",
                "\n",
                "    # ‚îÄ‚îÄ Stage 4: Spectre High-End Restoration (Multi-Band Exciter) ‚îÄ‚îÄ\n",
                "    def spectre_restore(self, wav):\n",
                "        sr = self.target_sr\n",
                "        stft = torch.stft(wav[0], n_fft=4096, hop_length=1024,\n",
                "                          window=torch.hann_window(4096).to(self.device), return_complex=True)\n",
                "        mag_db = 20 * torch.log10(torch.abs(stft).mean(dim=1) + 1e-8)\n",
                "        freqs = torch.linspace(0, sr/2, mag_db.shape[0]).to(self.device)\n",
                "        mask = mag_db > (mag_db.max() - 55)\n",
                "        cutoff = freqs[mask][-1].item() if mask.any() else 16000.0\n",
                "        cutoff = max(12000.0, min(cutoff, 22000.0))\n",
                "        if cutoff > 20000: return wav\n",
                "\n",
                "        # Band 1: Presence exciter\n",
                "        exc1 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, cutoff*0.85) * 1.8), sr, cutoff*0.9)\n",
                "        # Band 2: Air exciter\n",
                "        exc2 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, cutoff) * 3.0), sr, cutoff)\n",
                "\n",
                "        y = wav + (exc1 * 0.08) + (exc2 * 0.15)\n",
                "        peak = y.abs().max()\n",
                "        return y * (0.98 / peak) if peak > 0.98 else y\n",
                "\n",
                "    # ‚îÄ‚îÄ Full Pipeline ‚îÄ‚îÄ\n",
                "    def process_track(self, input_path, output_path, verbose=False):\n",
                "        try:\n",
                "            wav, sr = torchaudio.load(input_path)\n",
                "            wav = self._to_48k(wav.to(self.device), sr)\n",
                "            if self.stages.get('neural_clean'):  wav = self.neural_clean(wav)\n",
                "            if self.stages.get('mono_bass'):     wav = self.mono_bass(wav)\n",
                "            if self.stages.get('transient_punch'): wav = self.transient_punch(wav)\n",
                "            if self.stages.get('spectre_restore'): wav = self.spectre_restore(wav)\n",
                "            torchaudio.save(output_path, wav.cpu(), self.target_sr, encoding='PCM_S', bits_per_sample=16)\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f'  ‚ö†Ô∏è FAILED {os.path.basename(input_path)}: {e}')\n",
                "            return False\n",
                "\n",
                "\n",
                "class MasteringEngine:\n",
                "    \"\"\"Stage 6: Reference-based mastering via Matchering.\"\"\"\n",
                "\n",
                "    def __init__(self, reference_path=None):\n",
                "        self.ref = reference_path\n",
                "        self.available = HAS_MATCHERING and reference_path and os.path.exists(str(reference_path))\n",
                "        if self.available:\n",
                "            print(f'  üéöÔ∏è Mastering Engine ready | Ref: {os.path.basename(reference_path)}')\n",
                "        elif reference_path:\n",
                "            print(f'  ‚ö†Ô∏è Reference not found: {reference_path}')\n",
                "        else:\n",
                "            print('  ‚ÑπÔ∏è  Mastering Match disabled (set REFERENCE_TRACK to enable)')\n",
                "\n",
                "    def master(self, input_path, output_path):\n",
                "        if not self.available:\n",
                "            if input_path != output_path: shutil.copy2(input_path, output_path)\n",
                "            return False\n",
                "        try:\n",
                "            mg.process(target=input_path, reference=self.ref, results=[mg.pcm16(output_path)])\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f'  ‚ö†Ô∏è Mastering error: {e}')\n",
                "            if input_path != output_path: shutil.copy2(input_path, output_path)\n",
                "            return False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "logic-section",
            "metadata": {},
            "source": [
                "### 4. üåà Chromatic Flow & Affinity Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "logic-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(current_cam):\n",
                "    num, alpha = int(current_cam[:2]), current_cam[2]\n",
                "    return [\n",
                "        f\"{str(num).zfill(2)}{alpha}\",\n",
                "        f\"{str((num % 12) + 1).zfill(2)}{alpha}\",\n",
                "        f\"{str(((num - 2) % 12) + 1).zfill(2)}{alpha}\",\n",
                "        f\"{str(num).zfill(2)}{'A' if alpha == 'B' else 'B'}\"\n",
                "    ]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target_duration):\n",
                "    if not tracks: return []\n",
                "    pool = list(tracks)\n",
                "    current = pool.pop(0)\n",
                "    ordered_set = [current]\n",
                "    current_dur = current['duration']\n",
                "    \n",
                "    while pool and current_dur < target_duration:\n",
                "        compat_keys = get_next_harmonic(current['camelot'])\n",
                "        def score(t):\n",
                "            h_score = 1.0 if t['camelot'] in compat_keys else (0.8 if t['camelot'] == current['camelot'] else 0.0)\n",
                "            bpm_diff = abs(t['bpm'] - current['bpm'])\n",
                "            b_score = max(0, 1.0 - (bpm_diff / 40.0))\n",
                "            s_score = np.dot(current['embedding'], t['embedding']) / (np.linalg.norm(current['embedding']) * np.linalg.norm(t['embedding']) + 1e-9)\n",
                "            return (h_score * 0.5) + (s_score * 0.3) + (b_score * 0.2)\n",
                "        \n",
                "        pool.sort(key=score, reverse=True)\n",
                "        next_t = pool.pop(0)\n",
                "        ordered_set.append(next_t)\n",
                "        current_dur += next_t['duration']\n",
                "        current = next_t\n",
                "    return ordered_set\n",
                "\n",
                "def clean_name(n):\n",
                "    n = os.path.basename(n).rsplit('.', 1)[0]\n",
                "    n = re.sub(r\"^[\\w\\-]+?-\", \"\", n)\n",
                "    return re.sub(r\"[\\-\\_\\.]+?\", \" \", n).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "run-section",
            "metadata": {},
            "source": [
                "### 5. üöÄ Execution Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "# ‚ïë  CONFIG                                                      ‚ïë\n",
                "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "INPUT_DIR       = \"/kaggle/input/datasets/danieldobles/slavic-set\"\n",
                "OUTPUT_DIR      = \"/kaggle/working/master_organized\"\n",
                "TEMP_DIR        = \"/kaggle/working/_temp_restore\"\n",
                "BATCH_SIZE      = 16\n",
                "SET_DUR         = 75 * 60   # 75 min sets\n",
                "N_CLUSTERS      = 3\n",
                "\n",
                "# ‚îÄ‚îÄ Restoration Config ‚îÄ‚îÄ\n",
                "REFERENCE_TRACK = \"\"   # Path to a commercial reference for mastering match\n",
                "STAGES = {\n",
                "    'neural_clean':    True,   # Stage 1: DeepFilterNet 3\n",
                "    'mono_bass':       True,   # Stage 2: Sub-bass to mono (< 150Hz)\n",
                "    'transient_punch': True,   # Stage 3: Restore attack dynamics\n",
                "    'spectre_restore': True,   # Stage 4: High-end harmonic exciter\n",
                "    'matchering':      True,   # Stage 6: Reference-based mastering\n",
                "}\n",
                "PUNCH_BOOST_DB  = 4.0   # Transient boost (2-6 dB recommended)\n",
                "BASS_CUTOFF_HZ  = 150   # Mono-bass crossover frequency\n",
                "\n",
                "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "# ‚ïë  INIT ENGINES                                                ‚ïë\n",
                "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "print('\\nüîß Initializing engines...')\n",
                "analyzer  = SpectralMasterEngine(device=device, sr=24000)\n",
                "restorer  = UltimateSunoMaster(device=device, stages=STAGES)\n",
                "mastering = MasteringEngine(reference_path=REFERENCE_TRACK) if STAGES.get('matchering') else None\n",
                "\n",
                "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "# ‚ïë  PHASE 1: SCAN & ANALYZE                                     ‚ïë\n",
                "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "print('\\nüîç Scanning Library...')\n",
                "paths = []\n",
                "for ext in ['*.mp3', '*.wav', '*.flac', '*.m4a']:\n",
                "    paths.extend(glob.glob(os.path.join(INPUT_DIR, '**', ext), recursive=True))\n",
                "paths = sorted(set(paths))\n",
                "print(f'   Found {len(paths)} tracks')\n",
                "\n",
                "to_analyze = [p for p in paths if p not in analyzer.cache]\n",
                "if to_analyze:\n",
                "    chunks = [to_analyze[i:i+BATCH_SIZE] for i in range(0, len(to_analyze), BATCH_SIZE)]\n",
                "    with ThreadPoolExecutor(max_workers=2) as pool:\n",
                "        for chunk in tqdm(chunks, desc='üî• AI Analysis'):\n",
                "            def load(p):\n",
                "                try: y, _ = librosa.load(p, sr=analyzer.sr); return (p, y, len(y)/analyzer.sr)\n",
                "                except: return None\n",
                "            batch_data = [x for x in list(pool.map(load, chunk)) if x is not None]\n",
                "            results = analyzer.process_batch(batch_data)\n",
                "            for r in results: analyzer.cache[r['path']] = r\n",
                "            analyzer.save_cache(); gc.collect()\n",
                "\n",
                "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "# ‚ïë  PHASE 2: CLUSTER & SEQUENCE                                 ‚ïë\n",
                "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "library = [analyzer.cache[p] for p in paths if p in analyzer.cache]\n",
                "if not library:\n",
                "    print('‚ùå ERROR: No audio files processed.')\n",
                "else:\n",
                "    X = normalize(np.array([t['embedding'] for t in library]))\n",
                "    KM = cuKMeans(n_clusters=N_CLUSTERS) if HAS_CUML else skKMeans(n_clusters=N_CLUSTERS, n_init=10)\n",
                "    p_labels = KM.fit_predict(X)\n",
                "\n",
                "    clusters = {i: [] for i in range(N_CLUSTERS)}\n",
                "    for i, l in enumerate(p_labels): clusters[l].append(library[i])\n",
                "\n",
                "    if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "    os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "\n",
                "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "    # ‚ïë  PHASE 3: RESTORE, SEQUENCE & MASTER                     ‚ïë\n",
                "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "    print('\\nüåà Processing Sets...')\n",
                "    total_sets, total_tracks, failed = 0, 0, 0\n",
                "\n",
                "    for c_idx, cluster_tracks in clusters.items():\n",
                "        c_name = f'Group_{chr(65+c_idx)}'\n",
                "        temp_pool = sorted(cluster_tracks, key=lambda x: x['energy'])\n",
                "        set_idx = 1\n",
                "\n",
                "        while temp_pool:\n",
                "            ordered_set = sequence_chromatic_set(temp_pool, SET_DUR)\n",
                "            if not ordered_set: break\n",
                "            temp_pool = [t for t in temp_pool if t['path'] not in {s['path'] for s in ordered_set}]\n",
                "\n",
                "            s_dir = os.path.join(OUTPUT_DIR, c_name, f'Set_{set_idx}')\n",
                "            os.makedirs(s_dir, exist_ok=True)\n",
                "\n",
                "            for i, t in enumerate(tqdm(ordered_set, desc=f'üíé {c_name} Set {set_idx}', leave=False)):\n",
                "                meta = f\"[{t['camelot']} - {int(t['bpm'])}BPM]\"\n",
                "                out_name = f\"{str(i+1).zfill(2)} - {meta} {clean_name(t['path'])}.flac\"\n",
                "                final_path = os.path.join(s_dir, out_name)\n",
                "                temp_path  = os.path.join(TEMP_DIR, f'temp_{c_idx}_{set_idx}_{i}.wav')\n",
                "\n",
                "                # Stages 1-4: Restoration\n",
                "                ok = restorer.process_track(t['path'], temp_path)\n",
                "\n",
                "                if ok and mastering and mastering.available:\n",
                "                    # Stage 6: Mastering Match\n",
                "                    mastering.master(temp_path, final_path)\n",
                "                    os.remove(temp_path)\n",
                "                elif ok:\n",
                "                    shutil.move(temp_path, final_path)\n",
                "                else:\n",
                "                    shutil.copy2(t['path'], final_path)\n",
                "                    failed += 1\n",
                "\n",
                "                total_tracks += 1\n",
                "                gc.collect(); torch.cuda.empty_cache()\n",
                "\n",
                "            set_idx += 1; total_sets += 1\n",
                "\n",
                "    # Cleanup temp\n",
                "    if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)\n",
                "\n",
                "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
                "    # ‚ïë  DONE                                                    ‚ïë\n",
                "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
                "    stages_used = [k for k, v in STAGES.items() if v]\n",
                "    print(f'\\n‚úÖ SUCCESS! {total_tracks} tracks processed ({failed} failed) ‚Üí {total_sets} sets')\n",
                "    print(f'   Stages applied: {\" ‚Üí \".join(stages_used)}')\n",
                "    zip_name = 'SpectralAffinity_UltimateMaster.zip'\n",
                "    !zip -0 -rq {zip_name} master_organized\n",
                "    display(HTML(f\"<h3>üöÄ <a href='{zip_name}' id='dl'>DOWNLOAD ULTIMATE MASTER MIXES</a></h3>\"))\n",
                "    display(HTML(\"<script>setTimeout(() => document.getElementById('dl').click(), 1000);</script>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}