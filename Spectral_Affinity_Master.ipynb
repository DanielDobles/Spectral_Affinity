{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# \ud83c\udf0c Spectral Affinity Master v6.5\n",
                "### 9-Stage Ultimate SunoMaster Pipeline (Pure Audio Mode)\n",
                "\n",
                "| # | Stage | Tech | Effect |\n",
                "|---|-------|------|--------|\n",
                "| 1 | \ud83e\uddf9 Clean | Bypass | Deactivated (Neural Clean OFF) |\n",
                "| 2 | \ud83c\udf9b\ufe0f Spectral Shaper | STFT Stabilizer | Resonance / harshness control |\n",
                "| 3 | \ud83c\udf00 DC Block | Arithmetic | Simple DC Offset removal (Phase Safe) |\n",
                "| 4 | \ud83d\udd00 Stereo Wider | Safe M/S | Width without phase issues |\n",
                "| 5 | \ud83d\udd0a Mono-Bass | Linkwitz-Riley | Sub-bass phase \u2192 mono |\n",
                "| 6 | \ud83d\udca5 Transient Punch | Envelope Mask | Restore attack dynamics |\n",
                "| 7 | \u2728 Spectre Restore | Harmonic Exciter | 48kHz high-end recovery |\n",
                "| 8 | \ud83c\udfdd\ufe0f Affinity Grouping | MERT + K-Means | Neural semantic clustering |\n",
                "| 9 | \ud83c\udf9a\ufe0f Mastering Match | Matchering | Reference loudness & tone |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-header",
            "metadata": {},
            "source": [
                "### 1. \ud83d\udee0\ufe0f Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc, sys\n",
                "import numpy as np\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, display, clear_output\n",
                "import torchaudio.transforms as T\n",
                "import torchaudio.functional as F\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.cluster import KMeans as skKMeans\n",
                "\n",
                "# \ud83e\udd2b SHUT UP NOISE: Suppress CUDA/TF/Librosa warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "gpu_name = torch.cuda.get_device_name(0) if device=='cuda' else 'CPU'\n",
                "display(HTML(f\"\"\"\n",
                "<style>\n",
                "    .status-card {{ background: #1a1a1a; border-radius: 8px; padding: 15px; color: #00ffcc; font-family: 'Consolas', monospace; border-left: 5px solid #00ffcc; margin: 10px 0; }}\n",
                "</style>\n",
                "<div class='status-card'>\ud83d\udd25 ENGINE READY: {gpu_name}</div>\n",
                "\"\"\"))\n",
                "\n",
                "try: from nnAudio.Spectrogram import CQT1992v2\n",
                "except: \n",
                "    !pip install -q nnAudio transformers deepfilternet matchering\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
                "\n",
                "HAS_CUML = False\n",
                "try: from cuml.cluster import KMeans as cuKMeans; HAS_CUML = True\n",
                "except: pass\n",
                "\n",
                "from ultimate_pipeline import UltimateSunoMaster, MasteringEngine, clean_name\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "analysis-header",
            "metadata": {},
            "source": [
                "### 2. \ud83e\udde0 Neural Analysis Engine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralMasterEngine:\n",
                "    def __init__(self, device='cuda', sr=24000, cache_file='spectral_master_cache.json'):\n",
                "        self.device, self.sr, self.cache_file = device, sr, cache_file\n",
                "        self.cache = json.load(open(cache_file)) if os.path.exists(cache_file) else {}\n",
                "        self.cqt = CQT1992v2(sr=sr, n_bins=84, bins_per_octave=12, verbose=False).to(device)\n",
                "        major = torch.tensor([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], device=device)\n",
                "        minor = torch.tensor([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major,i) for i in range(12)] + [torch.roll(minor,i) for i in range(12)]).t()\n",
                "        self.proc = Wav2Vec2FeatureExtractor.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True)\n",
                "        self.mert = AutoModel.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True).to(device).eval()\n",
                "\n",
                "    def save_cache(self): json.dump(self.cache, open(self.cache_file, 'w'))\n",
                "\n",
                "    def get_camelot(self, key, mode):\n",
                "        cm = {('B','major'):'01B',('F#','major'):'02B',('C#','major'):'03B',('G#','major'):'04B',\n",
                "              ('D#','major'):'05B',('A#','major'):'06B',('F','major'):'07B',('C','major'):'08B',\n",
                "              ('G','major'):'09B',('D','major'):'10B',('A','major'):'11B',('E','major'):'12B',\n",
                "              ('G#','minor'):'01A',('D#','minor'):'02A',('A#','minor'):'03A',('F','minor'):'04A',\n",
                "              ('C','minor'):'05A',('G','minor'):'06A',('D','minor'):'07A',('A','minor'):'08A',\n",
                "              ('E','minor'):'09A',('B','minor'):'10A',('F#','minor'):'11A',('C#','minor'):'12A'}\n",
                "        return cm.get((key, mode.lower()), '00X')\n",
                "\n",
                "    def process_batch(self, paths_batch):\n",
                "        def load_one(p):\n",
                "            try:\n",
                "                w, s = torchaudio.load(p)\n",
                "                if s != self.sr: w = T.Resample(s, self.sr)(w)\n",
                "                w = w.mean(0)\n",
                "                if w.shape[0] > self.sr*120: w = w[:self.sr*120] # Max 2min for analysis\n",
                "                return w, len(w)/self.sr\n",
                "            except: return None\n",
                "        \n",
                "        # CPU Parallel Load\n",
                "        audios, durs, valid_p = [], [], []\n",
                "        with ThreadPoolExecutor() as pl: \n",
                "            res = list(pl.map(load_one, paths_batch))\n",
                "        for i, r in enumerate(res):\n",
                "            if r: audios.append(r[0]); durs.append(r[1]); valid_p.append(paths_batch[i])\n",
                "        \n",
                "        if not audios: return []\n",
                "        \n",
                "        # GPU Batch analysis\n",
                "        m_len = max([a.shape[0] for a in audios])\n",
                "        t = torch.zeros(len(audios), m_len, device=self.device)\n",
                "        for i, a in enumerate(audios): t[i, :a.shape[0]] = a.to(self.device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt(t)\n",
                "            energy = spec.pow(2).mean(dim=(1,2)).cpu().numpy()\n",
                "            chroma = spec.view(len(audios),7,12,-1).sum(dim=(1,3))\n",
                "            chroma = chroma / (chroma.norm(dim=1,keepdim=True)+1e-6)\n",
                "            best = torch.argmax(torch.matmul(chroma, self.profiles), dim=1).cpu().numpy()\n",
                "            embs = []\n",
                "            for i in range(len(audios)):\n",
                "                sl = int(self.sr*15); s = audios[i][:sl].cpu().numpy() # First 15s for MERT embs\n",
                "                iv = self.proc(s, sampling_rate=self.sr, return_tensors='pt').input_values.to(self.device)\n",
                "                embs.append(self.mert(iv).last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist())\n",
                "        \n",
                "        pc = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
                "        return [{'key':pc[best[i]%12], 'mode':'major' if best[i]<12 else 'minor', \n",
                "                 'energy':float(energy[i]), 'duration':float(durs[i]), \n",
                "                 'embedding':embs[i], 'path':valid_p[i], 'camelot': self.get_camelot(pc[best[i]%12], 'major' if best[i]<12 else 'minor'),\n",
                "                 'bpm': 120.0} for i in range(len(audios))]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "restoration-header",
            "metadata": {},
            "source": [
                "### 3. \ud83d\udc8e Ultimate Suno Master (7-Stage Restoration)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "restoration",
            "metadata": {},
            "outputs": [],
            "source": [
                "class UltimateSunoMaster:\n",
                "    def __init__(self, device='cuda', target_sr=48000, stages=None):\n",
                "        self.device, self.target_sr = device, target_sr\n",
                "        self.stages = stages or {'neural_clean':True,'spectral_shape':True,'phase_shape':True,'stereo_widen':True,'mono_bass':True,'transient_punch':True,'spectre_restore':True}\n",
                "\n",
                "    def _to_48k(self, wav, sr):\n",
                "        try:\n",
                "            return T.Resample(sr, self.target_sr).to(self.device)(wav) if sr != self.target_sr else wav\n",
                "        except: return wav\n",
                "\n",
                "    # \u2500\u2500 Stage 1: Neural Clean (DEACTIVATED PER USER REQUEST) \u2500\u2500\n",
                "    def neural_clean(self, wav):\n",
                "        return wav\n",
                "\n",
                "    # \u2500\u2500 Stage 2: Spectral Shaper (Stabilizer + Anti-Ringing) \u2500\u2500\n",
                "    def spectral_shape(self, wav, amount=60, speed=90, sensitivity=30, focus_low=200, focus_high=16000):\n",
                "        if not self.stages.get('spectral_shape'): return wav\n",
                "        sr, n, h = self.target_sr, 4096, 1024\n",
                "        win = torch.hann_window(n).to(self.device)\n",
                "        sens_db = 6.0 - (sensitivity/100.0*5.0); max_cut = (amount/100.0)*8.0; alpha = 0.05+(speed/100.0*0.45)\n",
                "        chs = []\n",
                "        for ch in range(wav.shape[0]):\n",
                "            stft = torch.stft(wav[ch], n_fft=n, hop_length=h, window=win, return_complex=True)\n",
                "            mag, phase = stft.abs(), stft.angle()\n",
                "            # Dynamic De-Resonator (Spectral Envelope)\n",
                "            env = torch.nn.functional.conv1d(mag.t().unsqueeze(1), torch.ones(1,1,31,device=self.device)/31, padding=15).squeeze(1).t()\n",
                "            excess = torch.clamp(20*torch.log10(mag+1e-8) - 20*torch.log10(env+1e-8) - sens_db, min=0)\n",
                "            gain = 10**(-torch.clamp(excess*0.8, max=max_cut)/20)\n",
                "            \n",
                "            # Anti-Ringing for AI (Specific focus on 3k-8k range)\n",
                "            freqs = torch.linspace(0, sr/2, mag.shape[0]).to(self.device).unsqueeze(1)\n",
                "            ringing_mask = ((freqs >= 3000) & (freqs <= 8000)).float()\n",
                "            gain = gain * (1.0 - (ringing_mask * 0.15 * (amount/100.0))) # Subtle extra cut for AI metallic sounds\n",
                "            \n",
                "            mask = ((freqs>=focus_low)&(freqs<=focus_high)).float()\n",
                "            gain = gain*mask + (1.0-mask)\n",
                "            for t in range(1, gain.shape[1]): gain[:,t] = alpha*gain[:,t] + (1-alpha)*gain[:,t-1]\n",
                "            chs.append(torch.istft((mag*gain)*torch.exp(1j*phase), n_fft=n, hop_length=h, window=win, length=wav.shape[-1]))\n",
                "        return torch.stack(chs)\n",
                "\n",
                "    # \u2500\u2500 Stage 3: Phase & DC Shaper (Phase Safe DC Block + Sub-HPF) \u2500\u2500\n",
                "    def phase_shape(self, wav, control=0.0):\n",
                "        if not self.stages.get('phase_shape'): return wav\n",
                "        # Remove DC Offset\n",
                "        wav = wav - wav.mean(dim=-1, keepdim=True)\n",
                "        # Steep 30Hz High Pass Filter to clean sub-bass rumble detected in dataset analysis\n",
                "        wav = F.highpass_biquad(wav, self.target_sr, 30.0, Q=0.707)\n",
                "        return wav\n",
                "\n",
                "    # \u2500\u2500 Stage 4: Stereo Wider (Phase-Aware Safe M/S) \u2500\u2500\n",
                "    def stereo_widen(self, wav, width=0.2):\n",
                "        if not self.stages.get('stereo_widen') or wav.shape[0] < 2: return wav\n",
                "        # Calculate Correlation to avoid phase collapse (Problem found in Min Corr tracks)\n",
                "        l, r = wav[0], wav[1]\n",
                "        prod = (l * r).sum()\n",
                "        norms = (l.pow(2).sum().sqrt() * r.pow(2).sum().sqrt()) + 1e-8\n",
                "        corr = prod / norms\n",
                "        \n",
                "        # Adaptive Width: If correlation is low (<0.4), narrow the stereo field instead of widening\n",
                "        # Width control: 0.2 is default. If corr is negative, we force narrowing.\n",
                "        actual_width = width if corr > 0.4 else width * (corr - 0.2)\n",
                "        \n",
                "        m = (wav[0] + wav[1]) / 2\n",
                "        s = (wav[0] - wav[1]) / 2\n",
                "        s = s * (1.0 + actual_width)\n",
                "        return torch.stack([m + s, m - s])\n",
                "\n",
                "    # \u2500\u2500 Stage 5: Mono-Bass (Sanitized Linkwitz-Riley) \u2500\u2500\n",
                "    def mono_bass(self, wav, cutoff=150):\n",
                "        if not self.stages.get('mono_bass'): return wav\n",
                "        low = F.lowpass_biquad(F.lowpass_biquad(wav, self.target_sr, cutoff), self.target_sr, cutoff)\n",
                "        high = wav - low\n",
                "        if wav.shape[0] >= 2: \n",
                "            low_mono = low.mean(dim=0, keepdim=True).expand_as(low)\n",
                "            return low_mono + high\n",
                "        return wav\n",
                "\n",
                "    # \u2500\u2500 Stage 6: Transient Punch \u2500\u2500\n",
                "    def transient_punch(self, wav, boost_db=4.0):\n",
                "        if not self.stages.get('transient_punch'): return wav\n",
                "        sr = self.target_sr\n",
                "        mono = wav.mean(dim=0) if wav.shape[0]>=2 else wav.squeeze(0)\n",
                "        fl = int(sr*0.005); hp = fl//2\n",
                "        if fl < 2: return wav\n",
                "        p = torch.nn.functional.pad(mono, (fl//2, fl//2))\n",
                "        e = p.unfold(0, fl, hp).pow(2).mean(dim=-1).sqrt()\n",
                "        flux = torch.clamp(torch.diff(e, prepend=e[:1]), min=0)\n",
                "        if flux.max() < 1e-8: return wav\n",
                "        fn = flux/(flux.max()+1e-8); thr = fn.mean()+1.5*fn.std()\n",
                "        mask = torch.clamp((fn-thr)/(1.0-thr+1e-8), 0, 1)\n",
                "        gain = torch.nn.functional.interpolate(mask[None,None,:], size=wav.shape[-1], mode='linear', align_corners=False).squeeze()\n",
                "        rl = max(int(sr*0.025), 4)\n",
                "        k = torch.exp(-torch.arange(rl, device=self.device, dtype=torch.float32)/(rl/4))\n",
                "        k = (k/k.sum())[None,None,:]\n",
                "        gain = torch.nn.functional.conv1d(gain[None,None,:], k, padding=rl//2).squeeze()[:wav.shape[-1]]\n",
                "        r = wav*(1.0+gain.unsqueeze(0)*(10**(boost_db/20)-1.0))\n",
                "        pk = r.abs().max()\n",
                "        return r*(0.98/pk) if pk > 0.98 else r\n",
                "\n",
                "    # \u2500\u2500 Stage 7: Spectre Restore \u2500\u2500\n",
                "    def spectre_restore(self, wav):\n",
                "        if not self.stages.get('spectre_restore'): return wav\n",
                "        sr = self.target_sr\n",
                "        stft = torch.stft(wav[0], n_fft=4096, hop_length=1024, window=torch.hann_window(4096).to(self.device), return_complex=True)\n",
                "        mdb = 20*torch.log10(stft.abs().mean(dim=1)+1e-8)\n",
                "        freqs = torch.linspace(0, sr/2, mdb.shape[0]).to(self.device)\n",
                "        v = mdb > (mdb.max()-55)\n",
                "        co = freqs[v][-1].item() if v.any() else 16000.0\n",
                "        co = max(12000.0, min(co, 20000.0))\n",
                "        if co > 19500: return wav\n",
                "        e1 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, co*0.85)*1.8), sr, co*0.9)\n",
                "        e2 = F.highpass_biquad(torch.tanh(F.highpass_biquad(wav, sr, co)*3.0), sr, co)\n",
                "        y = wav + e1*0.07 + e2*0.12\n",
                "        pk = y.abs().max()\n",
                "        return y*(0.98/pk) if pk > 0.98 else y\n",
                "\n",
                "    def process_track(self, input_path, output_path, shaper_params=None, phase_control=0.0, stereo_width=0.2):\n",
                "        if not os.path.exists(input_path): return {'status':'error', 'msg':'File not found', 'stage':'init'}\n",
                "        try:\n",
                "            wav, sr = torchaudio.load(input_path)\n",
                "            wav = self._to_48k(wav.to(self.device), sr)\n",
                "            if self.stages.get('neural_clean'): wav = self.neural_clean(wav)\n",
                "            if self.stages.get('spectral_shape'): wav = self.spectral_shape(wav, **(shaper_params or {}))\n",
                "            if self.stages.get('phase_shape'): wav = self.phase_shape(wav, control=phase_control)\n",
                "            if self.stages.get('stereo_widen'): wav = self.stereo_widen(wav, width=stereo_width)\n",
                "            if self.stages.get('mono_bass'): wav = self.mono_bass(wav)\n",
                "            if self.stages.get('transient_punch'): wav = self.transient_punch(wav)\n",
                "            if self.stages.get('spectre_restore'): wav = self.spectre_restore(wav)\n",
                "            # Peak Normalization before saving for consistency\n",
                "            pk = wav.abs().max()\n",
                "            if pk > 0: wav = wav * (0.95 / pk)\n",
                "            torchaudio.save(output_path, wav.cpu(), self.target_sr, encoding='PCM_S', bits_per_sample=16)\n",
                "            return {'status':'ok', 'stage':'Complete'}\n",
                "        except Exception as e:\n",
                "            import traceback\n",
                "            return {'status':'error', 'msg':str(e), 'stage':'processing'}\n",
                "\n",
                "class MasteringEngine:\n",
                "    def __init__(self, ref=None):\n",
                "        self.ref, self.available = ref, False\n",
                "        HAS_MATCHERING = False\n",
                "        try: import matchering as mg; HAS_MATCHERING = True\n",
                "        except: pass\n",
                "        if ref and os.path.exists(str(ref)) and HAS_MATCHERING:\n",
                "            self.available = True; print(f'  \ud83c\udf9a\ufe0f Mastering ready | Ref: {os.path.basename(ref)}')\n",
                "        else: print('  \u2139\ufe0f Mastering disabled' if not ref else f'  \u26a0\ufe0f Ref not found: {ref}')\n",
                "    def master(self, inp, out):\n",
                "        if not self.available: shutil.move(inp,out) if inp!=out else None; return False\n",
                "        try: \n",
                "            import matchering as mg\n",
                "            mg.process(target=inp, reference=self.ref, results=[mg.pcm16(out)])\n",
                "            return True\n",
                "        except Exception as e: \n",
                "            print(f'  \u26a0\ufe0f {e}')\n",
                "            shutil.move(inp,out) if inp!=out else None; return False\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "logic-header",
            "metadata": {},
            "source": [
                "### 4. \ud83c\udf08 Chromatic Flow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(c):\n",
                "    n, a = int(c[:2]), c[2]\n",
                "    return [f'{str(n).zfill(2)}{a}', f'{str((n%12)+1).zfill(2)}{a}', f'{str(((n-2)%12)+1).zfill(2)}{a}', f\"{str(n).zfill(2)}{'A' if a=='B' else 'B'}\"]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target):\n",
                "    if not tracks: return []\n",
                "    pool = list(tracks); cur = pool.pop(0); ordered = [cur]; dur = cur['duration']\n",
                "    while pool and dur < target:\n",
                "        ck = get_next_harmonic(cur['camelot'])\n",
                "        def sc(t):\n",
                "            h = 1.0 if t['camelot'] in ck else (0.8 if t['camelot']==cur['camelot'] else 0.0)\n",
                "            b = max(0, 1.0-(abs(t['bpm']-cur['bpm'])/40.0))\n",
                "            s = np.dot(cur['embedding'],t['embedding'])/(np.linalg.norm(cur['embedding'])*np.linalg.norm(t['embedding'])+1e-9)\n",
                "            return h*0.5+s*0.3+b*0.2\n",
                "        pool.sort(key=sc, reverse=True); nxt = pool.pop(0); ordered.append(nxt); dur += nxt['duration']; cur = nxt\n",
                "    return ordered\n",
                "\n",
                "def clean_name(n): return re.sub(r'[\\-\\_\\.]+?', ' ', re.sub(r'^[\\w\\-]+?-', '', os.path.basename(n).rsplit('.',1)[0])).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exec-header",
            "metadata": {},
            "source": [
                "### 5. \ud83d\ude80 Execute Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exec",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONFIG ===\n",
                "INPUT_DIR       = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "REFERENCE_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUTPUT_DIR      = '/kaggle/working/master_organized'\n",
                "TEMP_DIR        = '/kaggle/working/_temp_restore'\n",
                "BATCH_SIZE, SET_DUR, N_CLUSTERS = 16, 75*60, 3\n",
                "\n",
                "STAGES = {'neural_clean':True,'spectral_shape':True,'phase_shape':True,'stereo_widen':True,'mono_bass':True,'transient_punch':True,'spectre_restore':True,'matchering':True}\n",
                "SHAPER = {'amount': 60, 'speed': 90, 'sensitivity': 30}\n",
                "PHASE_CONTROL, STEREO_WIDTH = 0.0, 0.2\n",
                "\n",
                "print('\\n\ud83d\udd27 Warming Up Pipeline...')\n",
                "analyzer = SpectralMasterEngine(device=device); restorer = UltimateSunoMaster(device=device, stages=STAGES); mastering = MasteringEngine(ref=REFERENCE_TRACK)\n",
                "\n",
                "paths = sorted(set(sum([glob.glob(os.path.join(INPUT_DIR,'**',e), recursive=True) for e in ['*.mp3','*.wav','*.flac','*.m4a']], [])))\n",
                "to_do = [p for p in paths if p not in analyzer.cache]\n",
                "if to_do:\n",
                "    print(f'\ud83d\udd0d Analyzing {len(to_do)} new tracks...')\n",
                "    for i in range(0, len(to_do), BATCH_SIZE):\n",
                "        for r in analyzer.process_batch(to_do[i:i+BATCH_SIZE]): analyzer.cache[r['path']]=r\n",
                "        analyzer.save_cache()\n",
                "\n",
                "library = [analyzer.cache[p] for p in paths if p in analyzer.cache]\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "labels = (cuKMeans(n_clusters=N_CLUSTERS) if HAS_CUML else skKMeans(n_clusters=N_CLUSTERS, n_init=10)).fit_predict(X)\n",
                "clusters = {i: [library[j] for j,l in enumerate(labels) if l==i] for i in range(N_CLUSTERS)}\n",
                "\n",
                "if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "\n",
                "# \u2500\u2500 DASHBOARD LOGIC \u2500\u2500\n",
                "dashboard_html = \"\"\"\n",
                "<style>\n",
                "    .dash {{ background: #000; color: #fff; padding: 20px; border-radius: 12px; font-family: 'Segoe UI', sans-serif; border: 1px solid #333; }}\n",
                "    .bar {{ height: 10px; background: #333; border-radius: 5px; margin: 10px 0; overflow: hidden; }}\n",
                "    .fill {{ height: 100%; background: linear-gradient(90deg, #00f2fe, #4facfe); width: 0%; transition: width 0.3s; }}\n",
                "    .stat {{ font-size: 13px; color: #aaa; margin: 5px 0; }}\n",
                "    .err-box {{ background: #300; border: 1px solid #f33; padding: 10px; margin-top: 15px; border-radius: 6px; display: none; }}\n",
                "    .err-item {{ font-size: 12px; border-bottom: 1px solid #500; padding: 4px 0; color: #ff9999; }}\n",
                "</style>\n",
                "<div class='dash' id='dash'>\n",
                "    <h2 style='margin:0; color:#4facfe'>\ud83d\udc8e SPECTRAL AFFINITY DASHBOARD</h2>\n",
                "    <div class='stat' id='current-track'>Initializing engine...</div>\n",
                "    <div class='bar'><div class='fill' id='prog'></div></div>\n",
                "    <div style='display:flex; justify-content:space-between'>\n",
                "        <span class='stat' id='count'>0/0</span>\n",
                "        <span class='stat' id='perc'>0%</span>\n",
                "    </div>\n",
                "    <div class='err-box' id='err-box'>\n",
                "        <div style='color:#f33; font-weight:bold; margin-bottom:5px'>\ud83d\udef8 INCIDENT REPORT (Errors detected)</div>\n",
                "        <div id='err-list'></div>\n",
                "    </div>\n",
                "</div>\n",
                "\"\"\"\n",
                "display(HTML(dashboard_html))\n",
                "\n",
                "def update_ui(idx, total, name, errors):\n",
                "    p = int((idx/total)*100)\n",
                "    js = f\"\"\"\n",
                "    document.getElementById('prog').style.width = '{p}%';\n",
                "    document.getElementById('current-track').innerText = 'Processing: {name}';\n",
                "    document.getElementById('count').innerText = '{idx}/{total}';\n",
                "    document.getElementById('perc').innerText = '{p}%';\n",
                "    \"\"\"\n",
                "    if errors:\n",
                "        items = \"\".join([f\"<div class='err-item'>\u26a0\ufe0f Stage: {e['stage']} | File: {e['file']} | {e['msg']}</div>\" for e in errors[-5:]])\n",
                "        js += f\"document.getElementById('err-box').style.display = 'block';\"\n",
                "        js += f\"document.getElementById('err-list').innerHTML = `{items}`;\"\n",
                "    display(HTML(f\"<script>{js}</script>\"))\n",
                "\n",
                "# \u2500\u2500 PROCESSOR \u2500\u2500\n",
                "master_pool = ThreadPoolExecutor(max_workers=1)\n",
                "futures, incident_logs = [], []\n",
                "total_tracks = sum(len(c) for c in clusters.values())\n",
                "processed_count = 0\n",
                "\n",
                "for ci, ct in clusters.items():\n",
                "    cn = f'Group_{chr(65+ci)}'; pool = sorted(ct, key=lambda x: x['energy']); si = 1\n",
                "    while pool:\n",
                "        oset = sequence_chromatic_set(pool, SET_DUR)\n",
                "        if not oset: break\n",
                "        pool = [t for t in pool if t['path'] not in {s['path'] for s in oset}]\n",
                "        sd = os.path.join(OUTPUT_DIR, cn, f'Set_{si}'); os.makedirs(sd, exist_ok=True)\n",
                "        for i, t in enumerate(oset):\n",
                "            on = f\"{str(i+1).zfill(2)} - [{t['camelot']}] {clean_name(t['path'])}.flac\"\n",
                "            fp, tp = os.path.join(sd, on), os.path.join(TEMP_DIR, f'tmp_{ci}_{si}_{i}.wav')\n",
                "            \n",
                "            res = restorer.process_track(t['path'], tp, shaper_params=SHAPER, phase_control=PHASE_CONTROL, stereo_width=STEREO_WIDTH)\n",
                "            if res['status'] == 'ok':\n",
                "                futures.append(master_pool.submit(lambda p1, p2: mastering.master(p1, p2) or os.remove(p1) if mastering.available else shutil.move(p1, p2), tp, fp))\n",
                "            else:\n",
                "                incident_logs.append({'file': clean_name(t['path']), 'stage': res['stage'], 'msg': res['msg']})\n",
                "                shutil.copy2(t['path'], fp)\n",
                "            \n",
                "            processed_count += 1\n",
                "            if processed_count % 2 == 0: update_ui(processed_count, total_tracks, clean_name(t['path']), incident_logs)\n",
                "            if processed_count % 10 == 0: gc.collect(); torch.cuda.empty_cache()\n",
                "        si += 1\n",
                "\n",
                "update_ui(total_tracks, total_tracks, \"Mastering Completed\", incident_logs)\n",
                "master_pool.shutdown(); shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
                "!zip -0 -rq SlavMaster_v6_3.zip master_organized\n",
                "display(HTML(\"<h3>\ud83d\ude80 <a href='SlavMaster_v6_3.zip' id='dl'>DOWNLOAD v6.3 MASTER</a></h3>\"))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}