{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "master-header",
            "metadata": {},
            "source": [
                "# üåå Spectral Affinity Master: Neural Chromatic Hybrid (v5.0)\n",
                "\n",
                "This system unifies **DSP-based Harmonic Mixing**, **Neural Semantic Affinity (MERT)**, and **Professional Spectral Restoration**.\n",
                "\n",
                "### üß¨ Professional Hybrid & Restoration Features:\n",
                "- üß† **Neural Brain (MERT):** Extracts deep sonic signatures to understand the 'vibe' and group affinity.\n",
                "- üî• **DSP Brain (nnAudio GPU):** Precision detection of Musical Key, Mode, Energy, and spectral intensity.\n",
                "- üåà **Chromatic Flow Engine:** Intelligent sequencing following the **Camelot Wheel** (e.g., 1B ‚Üí 2B or 1B ‚Üí 1A).\n",
                "- üèñÔ∏è **Island Clustering:** Groups tracks into semantic 'Islands' based on group affinity before sequencing.\n",
                "- üíé **Spectre Restoration:** AI-driven harmonic synthesis to restore MP3 high-end losses (Upsampling to 48kHz + Saturation + FLAC export).\n",
                "- üì¶ **Turbo-Batching:** Full CUDA saturation for lightning-fast analysis of large libraries."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-section",
            "metadata": {},
            "source": [
                "### 1. üõ†Ô∏è High-Performance Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc, pathlib\n",
                "import numpy as np\n",
                "from tqdm.auto import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from IPython.display import HTML, FileLink, display\n",
                "import torchaudio.transforms as T\n",
                "import torchaudio.functional as F\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel, logging as hf_logging\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.cluster import AffinityPropagation, KMeans as skKMeans\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "hf_logging.set_verbosity_error()\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"üî• ACCELERATOR: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'}\")\n",
                "\n",
                "try:\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "except:\n",
                "    !pip install -q nnAudio transformers\n",
                "    from nnAudio.Spectrogram import CQT1992v2\n",
                "\n",
                "try:\n",
                "    import cuml\n",
                "    from cuml.cluster import KMeans as cuKMeans\n",
                "    HAS_CUML = True\n",
                "except:\n",
                "    HAS_CUML = False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "engines-section",
            "metadata": {},
            "source": [
                "### 2. üß† The Unified Neural & DSP Core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "engines-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralMasterEngine:\n",
                "    def __init__(self, device='cuda', sr=22050, cache_file='spectral_master_cache.json'):\n",
                "        self.device = device\n",
                "        self.sr = sr\n",
                "        self.cache_file = cache_file\n",
                "        self.cache = self._load_cache()\n",
                "        \n",
                "        # 1. DSP Layers\n",
                "        self.cqt_layer = CQT1992v2(sr=self.sr, n_bins=84, bins_per_octave=12).to(self.device)\n",
                "        major = torch.tensor([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88], device=device)\n",
                "        minor = torch.tensor([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17], device=device)\n",
                "        self.profiles = torch.stack([torch.roll(major, i) for i in range(12)] + \n",
                "                                    [torch.roll(minor, i) for i in range(12)]).t()\n",
                "        \n",
                "        # 2. Neural Layers (MERT)\n",
                "        print(\"üß† Loading MERT Neural Brain...\")\n",
                "        self.mert_model_id = \"m-a-p/MERT-v1-95M\"\n",
                "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(self.mert_model_id, trust_remote_code=True)\n",
                "        self.mert_model = AutoModel.from_pretrained(self.mert_model_id, trust_remote_code=True).to(self.device)\n",
                "        self.mert_model.eval()\n",
                "\n",
                "    def _load_cache(self):\n",
                "        if os.path.exists(self.cache_file):\n",
                "            with open(self.cache_file, 'r') as f: return json.load(f)\n",
                "        return {}\n",
                "\n",
                "    def save_cache(self):\n",
                "        with open(self.cache_file, 'w') as f: json.dump(self.cache, f)\n",
                "\n",
                "    def get_camelot(self, key, mode):\n",
                "        c_map = {\n",
                "            ('B', 'major'): '01B', ('F#', 'major'): '02B', ('C#', 'major'): '03B', ('G#', 'major'): '04B',\n",
                "            ('D#', 'major'): '05B', ('A#', 'major'): '06B', ('F', 'major'): '07B', ('C', 'major'): '08B',\n",
                "            ('G', 'major'): '09B', ('D', 'major'): '10B', ('A', 'major'): '11B', ('E', 'major'): '12B',\n",
                "            ('G#', 'minor'): '01A', ('D#', 'minor'): '02A', ('A#', 'minor'): '03A', ('F', 'minor'): '04A',\n",
                "            ('C', 'minor'): '05A', ('G', 'minor'): '06A', ('D', 'minor'): '07A', ('A', 'minor'): '08A',\n",
                "            ('E', 'minor'): '09A', ('B', 'minor'): '10A', ('F#', 'minor'): '11A', ('C#', 'minor'): '12A'\n",
                "        }\n",
                "        return c_map.get((key, mode.lower()), \"00X\")\n",
                "\n",
                "    def process_batch(self, batch_data):\n",
                "        paths = [x[0] for x in batch_data]\n",
                "        audios = [x[1] for x in batch_data]\n",
                "        durations = [x[2] for x in batch_data]\n",
                "        dsp_tensor = torch.zeros(len(audios), self.sr * 120, device=self.device)\n",
                "        for i, a in enumerate(audios):\n",
                "            l = min(len(a), self.sr * 120)\n",
                "            dsp_tensor[i, :l] = torch.from_numpy(a[:l]).to(self.device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            spec = self.cqt_layer(dsp_tensor)\n",
                "            energy = spec.pow(2).mean(dim=(1, 2)).cpu().numpy()\n",
                "            chroma = spec.view(len(audios), 7, 12, -1).sum(dim=(1, 3))\n",
                "            chroma = chroma / (chroma.norm(dim=1, keepdim=True) + 1e-6)\n",
                "            corrs = torch.matmul(chroma, self.profiles)\n",
                "            best_idx = torch.argmax(corrs, dim=1).cpu().numpy()\n",
                "            \n",
                "            embeddings_list = []\n",
                "            pc = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
                "            for i in range(len(audios)):\n",
                "                mid = len(audios[i])//2\n",
                "                audio_slice = audios[i][mid : mid + 22050*15] if len(audios[i]) > 22050*15 else audios[i]\n",
                "                input_values = self.processor(audio_slice, sampling_rate=22050, return_tensors=\"pt\").input_values.to(self.device)\n",
                "                emb = self.mert_model(input_values).last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
                "                embeddings_list.append(emb.tolist())\n",
                "                \n",
                "        results = []\n",
                "        for i in range(len(audios)):\n",
                "            res = {\n",
                "                'key': pc[best_idx[i] % 12], 'mode': 'major' if best_idx[i] < 12 else 'minor',\n",
                "                'energy': float(energy[i]), 'duration': float(durations[i]), \n",
                "                'embedding': embeddings_list[i], 'path': paths[i]\n",
                "            }\n",
                "            try:\n",
                "                onset = librosa.onset.onset_strength(y=audios[i][:22050*60], sr=22050)\n",
                "                res['bpm'] = float(librosa.beat.tempo(onset_envelope=onset, sr=22050, aggregate=np.mean)[0])\n",
                "            except: res['bpm'] = 120.0\n",
                "            res['camelot'] = self.get_camelot(res['key'], res['mode'])\n",
                "            results.append(res)\n",
                "        return results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "restoration-section",
            "metadata": {},
            "source": [
                "### 3. üíé Spectre Restoration Unit (High-End Reconstruction)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "restoration-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectreRestorer:\n",
                "    \"\"\"\n",
                "    DSP Restoration Unit: \n",
                "    Upsampling -> Spectral Gap Detection -> Harmonics Synthesis -> FLAC Export.\n",
                "    \"\"\"\n",
                "    def __init__(self, target_sr=48000, device='cuda'):\n",
                "        self.target_sr = target_sr\n",
                "        self.device = device\n",
                "\n",
                "    def detect_cutoff(self, waveform, sr):\n",
                "        # Perform STFT to find the MP3 frequency shelf\n",
                "        stft = torch.stft(waveform, n_fft=2048, hop_length=512, window=torch.hann_window(2048).to(self.device), return_complex=True)\n",
                "        mag = torch.abs(stft).mean(dim=-1).mean(dim=0)\n",
                "        mag_db = 20 * torch.log10(mag + 1e-8)\n",
                "        max_db = torch.max(mag_db)\n",
                "        freqs = torch.linspace(0, sr/2, len(mag_db))\n",
                "        \n",
                "        # Find where energy drops below -55dB relative to peak\n",
                "        threshold = max_db - 55\n",
                "        mask = mag_db > threshold\n",
                "        if not mask.any(): return 16000.0\n",
                "        cutoff = freqs[mask][-1].item()\n",
                "        return max(12000.0, min(cutoff, 20000.0))\n",
                "\n",
                "    def restore(self, input_path, output_path):\n",
                "        try:\n",
                "            waveform, sr = torchaudio.load(input_path)\n",
                "            waveform = waveform.to(self.device)\n",
                "            \n",
                "            # 1. Upsampling to 48kHz\n",
                "            if sr != self.target_sr:\n",
                "                resampler = T.Resample(sr, self.target_sr).to(self.device)\n",
                "                waveform = resampler(waveform)\n",
                "            \n",
                "            # 2. Analyze Magnitude for Cutoff\n",
                "            cutoff = self.detect_cutoff(waveform[0], self.target_sr)\n",
                "            \n",
                "            # 3. High-Pass Isolation\n",
                "            # We extract the 'air' band just below the cutoff to generate harmonics\n",
                "            y_high = F.highpass_biquad(waveform, self.target_sr, cutoff * 0.85)\n",
                "            \n",
                "            # 4. Non-linear Harmonic Synthesis (Saturation)\n",
                "            # Creating new harmonics using a tanh curve for pleasant 'Spectre' style excitement\n",
                "            gain = 2.5 \n",
                "            y_excited = torch.tanh(y_high * gain) \n",
                "            \n",
                "            # Apply a steep HPF to the excited signal so it only fills the GAP\n",
                "            y_excited = F.highpass_biquad(y_excited, self.target_sr, cutoff)\n",
                "            \n",
                "            # 5. Parallel Mix (12% Wet for subtle air restoration)\n",
                "            wet_level = 0.12\n",
                "            y_final = waveform + (y_excited * wet_level)\n",
                "            \n",
                "            # Normalize to avoid clipping\n",
                "            y_final = y_final / (torch.max(torch.abs(y_final)) + 1e-6)\n",
                "            \n",
                "            # 6. Export as FLAC Level 5\n",
                "            torchaudio.save(output_path, y_final.cpu(), self.target_sr, encoding=\"PCM_S\", bits_per_sample=16)\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ö†Ô∏è Restoration failed for {input_path}: {e}\")\n",
                "            return False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "logic-section",
            "metadata": {},
            "source": [
                "### 4. üåà Chromatic Mixer & Affinity Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "logic-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_next_harmonic(current_cam):\n",
                "    num, alpha = int(current_cam[:2]), current_cam[2]\n",
                "    return [\n",
                "        f\"{str(num).zfill(2)}{alpha}\",               # Same\n",
                "        f\"{str((num % 12) + 1).zfill(2)}{alpha}\",    # +1 Chromatic\n",
                "        f\"{str(((num - 2) % 12) + 1).zfill(2)}{alpha}\", # -1 Chromatic\n",
                "        f\"{str(num).zfill(2)}{'A' if alpha == 'B' else 'B'}\" # Parallel\n",
                "    ]\n",
                "\n",
                "def sequence_chromatic_set(tracks, target_duration):\n",
                "    if not tracks: return []\n",
                "    pool = list(tracks)\n",
                "    current = pool.pop(0)\n",
                "    ordered_set = [current]\n",
                "    current_dur = current['duration']\n",
                "    \n",
                "    while pool and current_dur < target_duration:\n",
                "        compat_keys = get_next_harmonic(current['camelot'])\n",
                "        def score(t):\n",
                "            h_score = 1.0 if t['camelot'] in compat_keys else (0.8 if t['camelot'] == current['camelot'] else 0.0)\n",
                "            bpm_diff = abs(t['bpm'] - current['bpm'])\n",
                "            b_score = max(0, 1.0 - (bpm_diff / 40.0))\n",
                "            s_score = np.dot(current['embedding'], t['embedding']) / (np.linalg.norm(current['embedding']) * np.linalg.norm(t['embedding']) + 1e-9)\n",
                "            return (h_score * 0.5) + (s_score * 0.3) + (b_score * 0.2)\n",
                "        \n",
                "        pool.sort(key=score, reverse=True)\n",
                "        next_t = pool.pop(0)\n",
                "        ordered_set.append(next_t)\n",
                "        current_dur += next_t['duration']\n",
                "        current = next_t\n",
                "    return ordered_set\n",
                "\n",
                "def clean_name(n):\n",
                "    n = os.path.basename(n).rsplit('.', 1)[0]\n",
                "    n = re.sub(r\"^[\\w\\-]+?-\", \"\", n)\n",
                "    return re.sub(r\"[\\-\\_\\.]+?\", \" \", n).strip()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "run-section",
            "metadata": {},
            "source": [
                "### 4. üöÄ Execution Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# CONFIG\n",
                "INPUT_DIR = \"/kaggle/input/datasets/danieldobles/slavic-set\"\n",
                "OUTPUT_DIR = \"/kaggle/working/master_organized\"\n",
                "BATCH_SIZE = 16\n",
                "SET_DUR = 75 * 60 \n",
                "N_CLUSTERS = 3\n",
                "ENABLE_RESTORATION = True # Set to False to just copy files without Spectre Enhancements\n",
                "\n",
                "master = SpectralMasterEngine(device=device)\n",
                "restorer = SpectreRestorer(device=device)\n",
                "\n",
                "print(\"üîç Scanning Library...\")\n",
                "paths = []\n",
                "for ext in ['*.mp3', '*.wav', '*.flac', '*.m4a']:\n",
                "    paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\n",
                "paths = list(set(paths))\n",
                "\n",
                "to_analyze = [p for p in paths if p not in master.cache]\n",
                "if to_analyze:\n",
                "    chunks = [to_analyze[i:i+BATCH_SIZE] for i in range(0, len(to_analyze), BATCH_SIZE)]\n",
                "    with ThreadPoolExecutor(max_workers=2) as pool:\n",
                "        for chunk in tqdm(chunks, desc=\"üî• AI Analysis\"):\n",
                "            def load(p):\n",
                "                try: y, _ = librosa.load(p, sr=22050); return (p, y, len(y)/22050)\n",
                "                except: return None\n",
                "            batch_data = [x for x in list(pool.map(load, chunk)) if x is not None]\n",
                "            results = master.process_batch(batch_data)\n",
                "            for r in results: master.cache[r['path']] = r\n",
                "            master.save_cache(); gc.collect()\n",
                "\n",
                "library = [master.cache[p] for p in paths if p in master.cache]\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "p_labels = (cuKMeans(n_clusters=N_CLUSTERS) if HAS_CUML else skKMeans(n_clusters=N_CLUSTERS, n_init=10)).fit_predict(X)\n",
                "\n",
                "clusters = {i: [] for i in range(N_CLUSTERS)}\n",
                "for i, l in enumerate(p_labels): clusters[l].append(library[i])\n",
                "\n",
                "if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
                "print(\"üåà Sequencing & Processing Sets...\")\n",
                "total_sets = 0\n",
                "for c_idx, cluster_tracks in clusters.items():\n",
                "    c_name = f\"Group_{chr(65+c_idx)}\"\n",
                "    temp_pool = sorted(cluster_tracks, key=lambda x: x['energy'])\n",
                "    set_idx = 1\n",
                "    while temp_pool:\n",
                "        ordered_set = sequence_chromatic_set(temp_pool, SET_DUR)\n",
                "        if not ordered_set: break\n",
                "        temp_pool = [t for t in temp_pool if t['path'] not in {s['path'] for s in ordered_set}]\n",
                "        \n",
                "        s_dir = os.path.join(OUTPUT_DIR, c_name, f\"Set_{set_idx}\")\n",
                "        os.makedirs(s_dir, exist_ok=True)\n",
                "        \n",
                "        for i, t in enumerate(tqdm(ordered_set, desc=f\"üíé {c_name} Set {set_idx}\", leave=False)):\n",
                "            meta = f\"[{t['camelot']} - {int(t['bpm'])}BPM]\"\n",
                "            ext = \"flac\" if ENABLE_RESTORATION else t['path'].rsplit('.', 1)[1]\n",
                "            out_name = f\"{str(i+1).zfill(2)} - {meta} {clean_name(t['path'])}.{ext}\"\n",
                "            out_path = os.path.join(s_dir, out_name)\n",
                "            \n",
                "            if ENABLE_RESTORATION:\n",
                "                restorer.restore(t['path'], out_path)\n",
                "            else:\n",
                "                shutil.copy2(t['path'], out_path)\n",
                "        \n",
                "        set_idx += 1; total_sets += 1\n",
                "\n",
                "print(f\"‚úÖ SUCCESS! Generated {total_sets} high-fidelity sets.\")\n",
                "zip_name = \"SpectralAffinity_Restored_MasterMix.zip\"\n",
                "!zip -0 -rq {zip_name} master_organized\n",
                "display(HTML(f\"<h3>üöÄ <a href='{zip_name}' id='dl'>DOWNLOAD SPECTRE MASTER MIXES</a></h3>\"))\n",
                "display(HTML(\"<script>setTimeout(() => document.getElementById('dl').click(), 1000);</script>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}