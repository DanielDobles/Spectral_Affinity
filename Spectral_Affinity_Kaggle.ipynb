{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽµ Spectral Affinity: Automated Audio Grouping\n",
                "\n",
                "This notebook automates the grouping of audio files based on their mathematical features (tempo, timbre, and brightness) using **Librosa** and **Scikit-learn**.\n",
                "\n",
                "## How it works:\n",
                "1. **Extraction**: It loads the center 30 seconds of each song.\n",
                "2. **Fingerprinting**: It extracts MFCCs, Spectral Centroid, and Tempo.\n",
                "3. **Clustering**: It uses KMeans to group similar songs.\n",
                "4. **Organization**: it copies the files into organized folders.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install librosa scikit-learn numpy soundfile joblib"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import glob\n",
                "import time\n",
                "import shutil\n",
                "import pathlib\n",
                "import librosa\n",
                "import numpy as np\n",
                "from joblib import Parallel, delayed\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.cluster import KMeans"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Core Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_filename(filename):\n",
                "    \"\"\"\n",
                "    Cleans audio filenames by removing common prefixes and UUID suffixes.\n",
                "    \"\"\"\n",
                "    if '.' not in filename: return filename\n",
                "    name_body, ext = filename.rsplit('.', 1)\n",
                "    \n",
                "    prefixes = [r\"^Slavic-\", r\"^Theme_OST-\", r\"^My_Workspace-\", r\"^audio-\"]\n",
                "    for prefix in prefixes:\n",
                "        name_body = re.sub(prefix, \"\", name_body, flags=re.IGNORECASE)\n",
                "        \n",
                "    uuid_pattern = r\"-[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$\"\n",
                "    name_body = re.sub(uuid_pattern, \"\", name_body)\n",
                "    name_body = name_body.replace(\"_\", \" \")\n",
                "    name_body = re.sub(r\"\\s+\", \" \", name_body).strip()\n",
                "    \n",
                "    return f\"{name_body}.{ext}\"\n",
                "\n",
                "def extract_features(file_path, duration=30):\n",
                "    \"\"\"\n",
                "    Optimized feature extraction (loads only 30s center).\n",
                "    \"\"\"\n",
                "    try:\n",
                "        total_duration = librosa.get_duration(path=file_path)\n",
                "        start_time = max(0, (total_duration - duration) // 2)\n",
                "        y, sr = librosa.load(file_path, sr=22050, duration=duration, offset=start_time)\n",
                "        \n",
                "        if len(y) == 0: return None\n",
                "\n",
                "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
                "        features = np.hstack([\n",
                "            np.mean(mfcc, axis=1), np.var(mfcc, axis=1),\n",
                "            np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
                "            np.var(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
                "            librosa.beat.beat_track(y=y, sr=sr)[0]\n",
                "        ])\n",
                "        return features\n",
                "    except Exception as e:\n",
                "        return None\n",
                "\n",
                "def organize_files(file_paths, labels, output_dir, mode='copy', rename=False):\n",
                "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
                "    for i, file_path in enumerate(file_paths):\n",
                "        label = labels[i]\n",
                "        cluster_dir = os.path.join(output_dir, f\"Cluster_{label}\")\n",
                "        pathlib.Path(cluster_dir).mkdir(exist_ok=True)\n",
                "        \n",
                "        filename = os.path.basename(file_path)\n",
                "        if rename: filename = clean_filename(filename)\n",
                "            \n",
                "        dest_path = os.path.join(cluster_dir, filename)\n",
                "        if mode == 'copy': shutil.copy2(file_path, dest_path)\n",
                "        else: shutil.move(file_path, dest_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Configuration and Execution\n",
                "\n",
                "Adjust the paths below. In Kaggle, datasets are usually in `../input/dataset-name`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "INPUT_DIR = \"/kaggle/input/datasets/danieldobles/ost-songs\" # Path updated to your dataset\n",
                "OUTPUT_DIR = \"./organized_music\"\n",
                "N_CLUSTERS = 5\n",
                "CLEAN_NAMES = True\n",
                "# ---------------------\n",
                "\n",
                "audio_extensions = ['*.mp3', '*.wav', '*.flac', '*.ogg', '*.m4a']\n",
                "file_paths = []\n",
                "for ext in audio_extensions:\n",
                "    file_paths.extend(glob.glob(os.path.join(INPUT_DIR, ext)))\n",
                "    file_paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\n",
                "\n",
                "file_paths = list(set(file_paths)) # Remove duplicates\n",
                "\n",
                "if not file_paths:\n",
                "    print(f\"No audio files found in {INPUT_DIR}!\")\n",
                "else:\n",
                "    print(f\"Found {len(file_paths)} files. Starting extraction...\")\n",
                "    \n",
                "    # Parallel Extraction\n",
                "    results = Parallel(n_jobs=-1)(delayed(extract_features)(p) for p in file_paths)\n",
                "    \n",
                "    valid_features = [r for r in results if r is not None]\n",
                "    valid_paths = [p for r, p in zip(results, file_paths) if r is not None]\n",
                "    \n",
                "    if valid_features:\n",
                "        # Clustering\n",
                "        scaler = StandardScaler()\n",
                "        scaled = scaler.fit_transform(np.array(valid_features))\n",
                "        labels = KMeans(n_clusters=N_CLUSTERS, random_state=42).fit_predict(scaled)\n",
                "        \n",
                "        # Organization\n",
                "        organize_files(valid_paths, labels, OUTPUT_DIR, mode='copy', rename=CLEAN_NAMES)\n",
                "        print(f\"Done! Organized into {N_CLUSTERS} clusters in {OUTPUT_DIR}\")\n",
                "    else:\n",
                "        print(\"Failed to extract features from any file.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Download Results (ZIP)\n",
                "\n",
                "Kaggle doesn't allow easy folder downloads. Run this cell to compress your results into a single ZIP file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists(OUTPUT_DIR):\n",
                "    shutil.make_archive('organized_results', 'zip', OUTPUT_DIR)\n",
                "    print(\"Success! 'organized_results.zip' is ready for download in the output folder.\")\n",
                "else:\n",
                "    print(\"Organized directory not found. Please run the previous cell first.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}