{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽµ Spectral Affinity: Full GPU Optimization (Hearing + Brain)\n",
                "\n",
                "This version is specialized for **Kaggle GPU T4**. It moves both the Feature Extraction (Hearing) and the Clustering (Brain) to the GPU, and uses high-speed shell commands for Zipping.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Verification of GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "!pip install soundfile torchaudio"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import glob\n",
                "import shutil\n",
                "import pathlib\n",
                "import numpy as np\n",
                "import soundfile as sf\n",
                "import torch\n",
                "import torchaudio\n",
                "import torchaudio.transforms as T\n",
                "from joblib import Parallel, delayed\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "try:\n",
                "    import cuml\n",
                "    from cuml.cluster import KMeans as cuKMeans\n",
                "    HAS_CUML = True\n",
                "except ImportError:\n",
                "    from sklearn.cluster import KMeans as skKMeans\n",
                "    HAS_CUML = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. High-Speed Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_filename(filename):\n",
                "    if '.' not in filename: return filename\n",
                "    name_body, ext = filename.rsplit('.', 1)\n",
                "    prefixes = [r\"^Slavic-\", r\"^Theme_OST-\", r\"^My_Workspace-\", r\"^audio-\"]\n",
                "    for prefix in prefixes: name_body = re.sub(prefix, \"\", name_body, flags=re.IGNORECASE)\n",
                "    uuid_pattern = r\"[\\(\\.\\-_\\s]?[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}[\\)]?$\"\n",
                "    name_body = re.sub(uuid_pattern, \"\", name_body)\n",
                "    name_body = name_body.replace(\"_\", \" \").strip(\" -(_)\")\n",
                "    name_body = re.sub(r\"\\s+\", \" \", name_body).strip()\n",
                "    return f\"{name_body if name_body else 'Unnamed'}.{ext}\"\n",
                "\n",
                "def get_fast_features(file_path, duration=30):\n",
                "    try:\n",
                "        info = sf.info(file_path)\n",
                "        sr, total_frames = info.samplerate, info.frames\n",
                "        desired_f = duration * sr\n",
                "        start_f = max(0, (total_frames - desired_f) // 2)\n",
                "        \n",
                "        y, _ = sf.read(file_path, frames=desired_f, start=start_f, dtype='float32')\n",
                "        if len(y.shape) > 1: y = y.mean(axis=1)\n",
                "        \n",
                "        waveform = torch.from_numpy(y).to(device).unsqueeze(0)\n",
                "        mfcc_transform = T.MFCC(sample_rate=sr, n_mfcc=13, \n",
                "                                melkwargs={\"n_fft\": 2048, \"hop_length\": 512, \"n_mels\": 64}).to(device)\n",
                "        mfcc = mfcc_transform(waveform).squeeze(0).cpu().numpy()\n",
                "        \n",
                "        import librosa\n",
                "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
                "        \n",
                "        return np.hstack([\n",
                "            np.mean(mfcc, axis=1), np.var(mfcc, axis=1), \n",
                "            float(tempo if isinstance(tempo, (float, int)) else tempo[0])\n",
                "        ])\n",
                "    except Exception: return None\n",
                "\n",
                "def organize_files(file_paths, labels, output_dir, mode='copy', rename=False):\n",
                "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
                "    cluster_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
                "    \n",
                "    for i, file_path in enumerate(file_paths):\n",
                "        label = labels[i]\n",
                "        c_letter = cluster_letters[label % len(cluster_letters)]\n",
                "        cluster_dir = os.path.join(output_dir, f\"Cluster_{c_letter}\")\n",
                "        pathlib.Path(cluster_dir).mkdir(exist_ok=True)\n",
                "        filename = os.path.basename(file_path)\n",
                "        if rename: filename = clean_filename(filename)\n",
                "        filename = f\"[{c_letter}] {filename}\"\n",
                "        \n",
                "        name_pure, ext = filename.rsplit('.', 1) if '.' in filename else (filename, '')\n",
                "        dest_path = os.path.join(cluster_dir, filename)\n",
                "        counter = 1\n",
                "        while os.path.exists(dest_path):\n",
                "            new_filename = f\"{name_pure} ({counter}).{ext}\" if ext else f\"{name_pure} ({counter})\"\n",
                "            dest_path = os.path.join(cluster_dir, new_filename)\n",
                "            counter += 1\n",
                "        shutil.copy2(file_path, dest_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Configuration and Execution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "INPUT_DIR = \"/kaggle/input/datasets/danieldobles/ost-songs\"\n",
                "OUTPUT_DIR = \"/kaggle/working/organized_music\"\n",
                "N_CLUSTERS = 5\n",
                "CLEAN_NAMES = True\n",
                "# ---------------------\n",
                "\n",
                "audio_extensions = ['*.mp3', '*.wav', '*.flac', '*.ogg', '*.m4a']\n",
                "file_paths = []\n",
                "for ext in audio_extensions:\n",
                "    file_paths.extend(glob.glob(os.path.join(INPUT_DIR, ext)))\n",
                "    file_paths.extend(glob.glob(os.path.join(INPUT_DIR, \"**\", ext), recursive=True))\n",
                "file_paths = list(set(file_paths))\n",
                "\n",
                "if not file_paths:\n",
                "    print(f\"No audio files found in {INPUT_DIR}!\")\n",
                "else:\n",
                "    print(f\"Found {len(file_paths)} files. Starting GPU Extraction...\")\n",
                "    results = Parallel(n_jobs=4)(delayed(get_fast_features)(p) for p in file_paths)\n",
                "    valid_features = [r for r in results if r is not None]\n",
                "    valid_paths = [p for r, p in zip(results, file_paths) if r is not None]\n",
                "    \n",
                "    if valid_features:\n",
                "        scaler = StandardScaler()\n",
                "        X = scaler.fit_transform(np.array(valid_features).astype('float32'))\n",
                "        if HAS_CUML:\n",
                "            labels = cuKMeans(n_clusters=N_CLUSTERS).fit_predict(X)\n",
                "        else:\n",
                "            labels = skKMeans(n_clusters=N_CLUSTERS, n_init=10).fit_predict(X)\n",
                "        \n",
                "        organize_files(valid_paths, labels, OUTPUT_DIR, mode='copy', rename=CLEAN_NAMES)\n",
                "        print(f\"Done! Created {N_CLUSTERS} clusters and organized results.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Download Results\n",
                "\n",
                "Kaggle restricts large automatic downloads. Follow these steps:\n",
                "1. Run the cell below to create the ZIP.\n",
                "2. Use the **Link** that appears to try a direct download.\n",
                "3. If the link fails (common for 7GB+ files), go to the **Data (Output)** sidebar on the right and click the download icon next to `organized_results.zip`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from IPython.display import FileLink\n",
                "\n",
                "if os.path.exists(OUTPUT_DIR):\n",
                "    print(\"Step 1: Creating ZIP archive (this may take a minute for 7GB+)...\")\n",
                "    !zip -0 -rq /kaggle/working/organized_results.zip organized_music\n",
                "    \n",
                "    print(\"\\nStep 2: Generation complete!\")\n",
                "    display(FileLink('organized_results.zip'))\n",
                "    \n",
                "    print(\"\\nNOTE: If the link above does not work, use the 'Output' sidebar on the right to download manually.\")\n",
                "else:\n",
                "    print(\"No organized data found. Run the extraction cell first.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (RAPIDS)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}