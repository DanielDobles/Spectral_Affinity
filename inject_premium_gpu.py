
import json
import os

NOTEBOOK_PATH = r"c:\Users\armon\DEV_main\Spectral_Affinity\Spectral_Affinity_Master.ipynb"

# ‚îÄ‚îÄ 1. SETUP IMPROVED (Suppress Noise) ‚îÄ‚îÄ
NEW_SETUP = [
    "import os, warnings, json, torch, torchaudio, librosa, glob, shutil, re, gc, sys\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.display import HTML, display, clear_output\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans as skKMeans\n",
    "\n",
    "# ü§´ SHUT UP NOISE: Suppress CUDA/TF/Librosa warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpu_name = torch.cuda.get_device_name(0) if device=='cuda' else 'CPU'\n",
    "display(HTML(f\"\"\"\n",
    "<style>\n",
    "    .status-card {{ background: #1a1a1a; border-radius: 8px; padding: 15px; color: #00ffcc; font-family: 'Consolas', monospace; border-left: 5px solid #00ffcc; margin: 10px 0; }}\n",
    "</style>\n",
    "<div class='status-card'>üî• ENGINE READY: {gpu_name}</div>\n",
    "\"\"\"))\n",
    "\n",
    "try: from nnAudio.Spectrogram import CQT1992v2\n",
    "except: \n",
    "    !pip install -q nnAudio transformers deepfilternet matchering\n",
    "    from nnAudio.Spectrogram import CQT1992v2\n",
    "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
    "\n",
    "HAS_CUML = False\n",
    "try: from cuml.cluster import KMeans as cuKMeans; HAS_CUML = True\n",
    "except: pass\n",
    "\n",
    "from ultimate_pipeline import UltimateSunoMaster, MasteringEngine, clean_name\n"
]

# ‚îÄ‚îÄ 2. ANALYSIS LOADERS (Optimized) ‚îÄ‚îÄ
NEW_ANALYSIS = [
    "class SpectralMasterEngine:\n",
    "    def __init__(self, device='cuda', sr=24000, cache_file='spectral_master_cache.json'):\n",
    "        self.device, self.sr, self.cache_file = device, sr, cache_file\n",
    "        self.cache = json.load(open(cache_file)) if os.path.exists(cache_file) else {}\n",
    "        self.cqt = CQT1992v2(sr=sr, n_bins=84, bins_per_octave=12, verbose=False).to(device)\n",
    "        major = torch.tensor([6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88], device=device)\n",
    "        minor = torch.tensor([6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17], device=device)\n",
    "        self.profiles = torch.stack([torch.roll(major,i) for i in range(12)] + [torch.roll(minor,i) for i in range(12)]).t()\n",
    "        self.proc = Wav2Vec2FeatureExtractor.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True)\n",
    "        self.mert = AutoModel.from_pretrained('m-a-p/MERT-v1-95M', trust_remote_code=True).to(device).eval()\n",
    "\n",
    "    def save_cache(self): json.dump(self.cache, open(self.cache_file, 'w'))\n",
    "\n",
    "    def get_camelot(self, key, mode):\n",
    "        cm = {('B','major'):'01B',('F#','major'):'02B',('C#','major'):'03B',('G#','major'):'04B',\n",
    "              ('D#','major'):'05B',('A#','major'):'06B',('F','major'):'07B',('C','major'):'08B',\n",
    "              ('G','major'):'09B',('D','major'):'10B',('A','major'):'11B',('E','major'):'12B',\n",
    "              ('G#','minor'):'01A',('D#','minor'):'02A',('A#','minor'):'03A',('F','minor'):'04A',\n",
    "              ('C','minor'):'05A',('G','minor'):'06A',('D','minor'):'07A',('A','minor'):'08A',\n",
    "              ('E','minor'):'09A',('B','minor'):'10A',('F#','minor'):'11A',('C#','minor'):'12A'}\n",
    "        return cm.get((key, mode.lower()), '00X')\n",
    "\n",
    "    def process_batch(self, paths_batch):\n",
    "        def load_one(p):\n",
    "            try:\n",
    "                w, s = torchaudio.load(p)\n",
    "                if s != self.sr: w = T.Resample(s, self.sr)(w)\n",
    "                w = w.mean(0)\n",
    "                if w.shape[0] > self.sr*120: w = w[:self.sr*120] # Max 2min for analysis\n",
    "                return w, len(w)/self.sr\n",
    "            except: return None\n",
    "        \n",
    "        # CPU Parallel Load\n",
    "        audios, durs, valid_p = [], [], []\n",
    "        with ThreadPoolExecutor() as pl: \n",
    "            res = list(pl.map(load_one, paths_batch))\n",
    "        for i, r in enumerate(res):\n",
    "            if r: audios.append(r[0]); durs.append(r[1]); valid_p.append(paths_batch[i])\n",
    "        \n",
    "        if not audios: return []\n",
    "        \n",
    "        # GPU Batch analysis\n",
    "        m_len = max([a.shape[0] for a in audios])\n",
    "        t = torch.zeros(len(audios), m_len, device=self.device)\n",
    "        for i, a in enumerate(audios): t[i, :a.shape[0]] = a.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            spec = self.cqt(t)\n",
    "            energy = spec.pow(2).mean(dim=(1,2)).cpu().numpy()\n",
    "            chroma = spec.view(len(audios),7,12,-1).sum(dim=(1,3))\n",
    "            chroma = chroma / (chroma.norm(dim=1,keepdim=True)+1e-6)\n",
    "            best = torch.argmax(torch.matmul(chroma, self.profiles), dim=1).cpu().numpy()\n",
    "            embs = []\n",
    "            for i in range(len(audios)):\n",
    "                sl = int(self.sr*15); s = audios[i][:sl].cpu().numpy() # First 15s for MERT embs\n",
    "                iv = self.proc(s, sampling_rate=self.sr, return_tensors='pt').input_values.to(self.device)\n",
    "                embs.append(self.mert(iv).last_hidden_state.mean(dim=1).squeeze().cpu().numpy().tolist())\n",
    "        \n",
    "        pc = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "        return [{'key':pc[best[i]%12], 'mode':'major' if best[i]<12 else 'minor', \n",
    "                 'energy':float(energy[i]), 'duration':float(durs[i]), \n",
    "                 'embedding':embs[i], 'path':valid_p[i], 'camelot': self.get_camelot(pc[best[i]%12], 'major' if best[i]<12 else 'minor'),\n",
    "                 'bpm': 120.0} for i in range(len(audios))]\n"
]

# ‚îÄ‚îÄ 3. EXECUTION + DASHBOARD UI ‚îÄ‚îÄ
NEW_EXEC = [
    "# === CONFIG ===\n",
    "INPUT_DIR       = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
    "REFERENCE_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
    "OUTPUT_DIR      = '/kaggle/working/master_organized'\n",
    "TEMP_DIR        = '/kaggle/working/_temp_restore'\n",
    "BATCH_SIZE, SET_DUR, N_CLUSTERS = 16, 75*60, 3\n",
    "\n",
    "STAGES = {'neural_clean':True,'spectral_shape':True,'phase_shape':True,'stereo_widen':True,'mono_bass':True,'transient_punch':True,'spectre_restore':True,'matchering':True}\n",
    "SHAPER = {'amount': 60, 'speed': 90, 'sensitivity': 30}\n",
    "PHASE_CONTROL, STEREO_WIDTH = -0.3, 0.3\n",
    "\n",
    "print('\\nüîß Warming Up Pipeline...')\n",
    "analyzer = SpectralMasterEngine(device=device); restorer = UltimateSunoMaster(device=device, stages=STAGES); mastering = MasteringEngine(ref=REFERENCE_TRACK)\n",
    "\n",
    "paths = sorted(set(sum([glob.glob(os.path.join(INPUT_DIR,'**',e), recursive=True) for e in ['*.mp3','*.wav','*.flac','*.m4a']], [])))\n",
    "to_do = [p for p in paths if p not in analyzer.cache]\n",
    "if to_do:\n",
    "    print(f'üîç Analyzing {len(to_do)} new tracks...')\n",
    "    for i in range(0, len(to_do), BATCH_SIZE):\n",
    "        for r in analyzer.process_batch(to_do[i:i+BATCH_SIZE]): analyzer.cache[r['path']]=r\n",
    "        analyzer.save_cache()\n",
    "\n",
    "library = [analyzer.cache[p] for p in paths if p in analyzer.cache]\n",
    "X = normalize(np.array([t['embedding'] for t in library]))\n",
    "labels = (cuKMeans(n_clusters=N_CLUSTERS) if HAS_CUML else skKMeans(n_clusters=N_CLUSTERS, n_init=10)).fit_predict(X)\n",
    "clusters = {i: [library[j] for j,l in enumerate(labels) if l==i] for i in range(N_CLUSTERS)}\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR): shutil.rmtree(OUTPUT_DIR)\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ DASHBOARD LOGIC ‚îÄ‚îÄ\n",
    "dashboard_html = \"\"\"\n",
    "<style>\n",
    "    .dash {{ background: #000; color: #fff; padding: 20px; border-radius: 12px; font-family: 'Segoe UI', sans-serif; border: 1px solid #333; }}\n",
    "    .bar {{ height: 10px; background: #333; border-radius: 5px; margin: 10px 0; overflow: hidden; }}\n",
    "    .fill {{ height: 100%; background: linear-gradient(90deg, #00f2fe, #4facfe); width: 0%; transition: width 0.3s; }}\n",
    "    .stat {{ font-size: 13px; color: #aaa; margin: 5px 0; }}\n",
    "    .err-box {{ background: #300; border: 1px solid #f33; padding: 10px; margin-top: 15px; border-radius: 6px; display: none; }}\n",
    "    .err-item {{ font-size: 12px; border-bottom: 1px solid #500; padding: 4px 0; color: #ff9999; }}\n",
    "</style>\n",
    "<div class='dash' id='dash'>\n",
    "    <h2 style='margin:0; color:#4facfe'>üíé SPECTRAL AFFINITY DASHBOARD</h2>\n",
    "    <div class='stat' id='current-track'>Initializing engine...</div>\n",
    "    <div class='bar'><div class='fill' id='prog'></div></div>\n",
    "    <div style='display:flex; justify-content:space-between'>\n",
    "        <span class='stat' id='count'>0/0</span>\n",
    "        <span class='stat' id='perc'>0%</span>\n",
    "    </div>\n",
    "    <div class='err-box' id='err-box'>\n",
    "        <div style='color:#f33; font-weight:bold; margin-bottom:5px'>üõ∏ INCIDENT REPORT (Errors detected)</div>\n",
    "        <div id='err-list'></div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(dashboard_html))\n",
    "\n",
    "def update_ui(idx, total, name, errors):\n",
    "    p = int((idx/total)*100)\n",
    "    js = f\"\"\"\n",
    "    document.getElementById('prog').style.width = '{p}%';\n",
    "    document.getElementById('current-track').innerText = 'Processing: {name}';\n",
    "    document.getElementById('count').innerText = '{idx}/{total}';\n",
    "    document.getElementById('perc').innerText = '{p}%';\n",
    "    \"\"\"\n",
    "    if errors:\n",
    "        items = \"\".join([f\"<div class='err-item'>‚ö†Ô∏è Stage: {e['stage']} | File: {e['file']} | {e['msg']}</div>\" for e in errors[-5:]])\n",
    "        js += f\"document.getElementById('err-box').style.display = 'block';\"\n",
    "        js += f\"document.getElementById('err-list').innerHTML = `{items}`;\"\n",
    "    display(HTML(f\"<script>{js}</script>\"))\n",
    "\n",
    "# ‚îÄ‚îÄ PROCESSOR ‚îÄ‚îÄ\n",
    "master_pool = ThreadPoolExecutor(max_workers=1)\n",
    "futures, incident_logs = [], []\n",
    "total_tracks = sum(len(c) for c in clusters.values())\n",
    "processed_count = 0\n",
    "\n",
    "for ci, ct in clusters.items():\n",
    "    cn = f'Group_{chr(65+ci)}'; pool = sorted(ct, key=lambda x: x['energy']); si = 1\n",
    "    while pool:\n",
    "        oset = sequence_chromatic_set(pool, SET_DUR)\n",
    "        if not oset: break\n",
    "        pool = [t for t in pool if t['path'] not in {s['path'] for s in oset}]\n",
    "        sd = os.path.join(OUTPUT_DIR, cn, f'Set_{si}'); os.makedirs(sd, exist_ok=True)\n",
    "        for i, t in enumerate(oset):\n",
    "            on = f\"{str(i+1).zfill(2)} - [{t['camelot']}] {clean_name(t['path'])}.flac\"\n",
    "            fp, tp = os.path.join(sd, on), os.path.join(TEMP_DIR, f'tmp_{ci}_{si}_{i}.wav')\n",
    "            \n",
    "            res = restorer.process_track(t['path'], tp, shaper_params=SHAPER, phase_control=PHASE_CONTROL, stereo_width=STEREO_WIDTH)\n",
    "            if res['status'] == 'ok':\n",
    "                futures.append(master_pool.submit(lambda p1, p2: mastering.master(p1, p2) or os.remove(p1) if mastering.available else shutil.move(p1, p2), tp, fp))\n",
    "            else:\n",
    "                incident_logs.append({'file': clean_name(t['path']), 'stage': res['stage'], 'msg': res['msg']})\n",
    "                shutil.copy2(t['path'], fp)\n",
    "            \n",
    "            processed_count += 1\n",
    "            if processed_count % 2 == 0: update_ui(processed_count, total_tracks, clean_name(t['path']), incident_logs)\n",
    "            if processed_count % 10 == 0: gc.collect(); torch.cuda.empty_cache()\n",
    "        si += 1\n",
    "\n",
    "update_ui(total_tracks, total_tracks, \"Mastering Completed\", incident_logs)\n",
    "master_pool.shutdown(); shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "!zip -0 -rq SlavMaster_v6_3.zip master_organized\n",
    "display(HTML(\"<h3>üöÄ <a href='SlavMaster_v6_3.zip' id='dl'>DOWNLOAD v6.3 MASTER</a></h3>\"))\n"
]

def main():
    with open(NOTEBOOK_PATH, 'r', encoding='utf-8') as f:
        nb = json.load(f)
    for cell in nb['cells']:
        if cell.get('id') == 'setup':
            cell['source'] = NEW_SETUP
        elif cell.get('id') == 'analysis':
            cell['source'] = NEW_ANALYSIS
        elif cell.get('id') == 'exec':
            cell['source'] = NEW_EXEC
    with open(NOTEBOOK_PATH, 'w', encoding='utf-8') as f:
        json.dump(nb, f, indent=4, ensure_ascii=False)
    print("Notebook optimized with Premium UI and GPU Pipeline!")

if __name__ == "__main__":
    main()
