{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéµ Music Information Retrieval (MIR) Ultimate Analyzer [nnAudio GPU EDITION]\n",
                "### *Powered by nnAudio, PyTorch (CUDA) & Librosa*\n",
                "\n",
                "Este cuaderno ha sido dise√±ado para la m√°xima velocidad de procesamiento utilizando **GPU** a trav√©s de la librer√≠a **nnAudio**. A diferencia de Librosa, que es CPU-bound, nnAudio utiliza PyTorch para realizar transformadas de Fourier (STFT, CQT, Mel) directamente en la tarjeta de video, permitiendo el an√°lisis masivo de datasets en una fracci√≥n del tiempo.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q nnAudio librosa torch pandas matplotlib tqdm\n",
                "\n",
                "import os\n",
                "import librosa\n",
                "import librosa.display\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import shutil\n",
                "import pandas as pd\n",
                "from nnAudio import features\n",
                "from IPython.display import Audio, display, FileLink\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# Configuraci√≥n de Dispositivo\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"üî• Motor de GPU: {device.upper()}\")\n",
                "if device == \"cuda\":\n",
                "    print(f\"Placa: {torch.cuda.get_device_name(0)}\")\n",
                "\n",
                "# Configuraci√≥n Est√©tica Premium\n",
                "plt.style.use('dark_background')\n",
                "plt.rcParams.update({'font.size': 12, 'figure.figsize': (15, 6), 'lines.linewidth': 1.5})\n",
                "\n",
                "OUTPUT_DIR = 'mir_nnaudio_results'\n",
                "PLOTS_DIR = os.path.join(OUTPUT_DIR, 'plots')\n",
                "os.makedirs(PLOTS_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìÇ 1. Preparaci√≥n del Dataset y Exclusi√≥n\n",
                "Configuramos el acceso a los archivos de Kaggle e ignoramos el archivo de referencia."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATASET_PATH = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "IGNORE_FILE = 'REF.flac'\n",
                "\n",
                "if not os.path.exists(DATASET_PATH):\n",
                "    print(f\"‚ö†Ô∏è Path Kaggle no detectado. Cambiando a local: Slavic Data_Set\")\n",
                "    DATASET_PATH = 'Slavic Data_Set'\n",
                "\n",
                "all_files = [f for f in os.listdir(DATASET_PATH) if f.endswith(('.mp3', '.wav', '.flac')) and f != IGNORE_FILE]\n",
                "print(f\"üìö Total de pistas a procesar v√≠a GPU: {len(all_files)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚ö° 2. Inicializaci√≥n de Capas nnAudio (GPU Kernels)\n",
                "Creamos las capas de procesamiento que vivir√°n en la GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definimos capas de nnAudio fuera del bucle para m√°ximo rendimiento\n",
                "sr_default = 44100 # Se ajustar√° din√°micamente si es necesario\n",
                "\n",
                "spec_layer = features.STFT(n_fft=2048, hop_length=512).to(device)\n",
                "mel_layer = features.MelSpectrogram(sr=sr_default, n_fft=2048, n_mels=128).to(device)\n",
                "cqt_layer = features.CQT2010v2(sr=sr_default, hop_length=512, fmin=32.7, n_bins=84).to(device)\n",
                "\n",
                "print(\"‚úÖ Kernels de nnAudio inicializados en GPU.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß¨ 3. El Algoritmo de Alto Rendimiento\n",
                "Esta funci√≥n coordina la carga de audio (CPU) y el an√°lisis espectral masivo (GPU)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_with_nnaudio(file_path, save_plots=True):\n",
                "    filename = os.path.basename(file_path)\n",
                "    \n",
                "    # Carga r√°pida (Librosa sigue siendo necesario para decodificar MP3/FLAC)\n",
                "    y, sr = librosa.load(file_path, sr=None, mono=True)\n",
                "    y_torch = torch.from_numpy(y).float().to(device).unsqueeze(0)\n",
                "    \n",
                "    # --- ANALISIS GPU CON nnAudio ---\n",
                "    with torch.no_grad():\n",
                "        # Espectrograma de Mel\n",
                "        melspec = mel_layer(y_torch)\n",
                "        melspec_db = librosa.power_to_db(melspec.cpu().squeeze().numpy(), ref=np.max)\n",
                "        \n",
                "        # Transformada Constant-Q (Mucho m√°s r√°pida en GPU)\n",
                "        cqt_spec = cqt_layer(y_torch)\n",
                "        cqt_db = librosa.amplitude_to_db(torch.abs(cqt_spec).cpu().squeeze().numpy(), ref=np.max)\n",
                "    \n",
                "    # --- ANALISIS COMPLEMENTARIO (M√©tricas de Tonalidad/Ritmo) ---\n",
                "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
                "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
                "    chroma_mean = np.mean(chroma, axis=1)\n",
                "    \n",
                "    # Key Estimation\n",
                "    major_p = [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]\n",
                "    minor_p = [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]\n",
                "    notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
                "    major_corr = [np.corrcoef(chroma_mean, np.roll(major_p, i))[0, 1] for i in range(12)]\n",
                "    minor_corr = [np.corrcoef(chroma_mean, np.roll(minor_p, i))[0, 1] for i in range(12)]\n",
                "    key = f\"{notes[np.argmax(major_corr)]} Major\" if max(major_corr) > max(minor_corr) else f\"{notes[np.argmax(minor_corr)]} Minor\"\n",
                "\n",
                "    # --- GUARDADO DE RESULTADOS ---\n",
                "    if save_plots:\n",
                "        fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
                "        img1 = librosa.display.specshow(melspec_db, ax=ax[0], x_axis='time', y_axis='mel', sr=sr, cmap='magma')\n",
                "        ax[0].set(title=f'Mel Spectrogram (nnAudio): {filename}')\n",
                "        plt.colorbar(img1, ax=ax[0])\n",
                "        \n",
                "        img2 = librosa.display.specshow(cqt_db, ax=ax[1], x_axis='time', y_axis='cqt_note', sr=sr, cmap='inferno')\n",
                "        ax[1].set(title=f'CQT Spectrogram (nnAudio): {filename}')\n",
                "        plt.colorbar(img2, ax=ax[1])\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.savefig(os.path.join(PLOTS_DIR, f\"{filename}_analysis.png\"))\n",
                "        plt.close()\n",
                "\n",
                "    return {\n",
                "        \"filename\": filename,\n",
                "        \"tempo_bpm\": tempo,\n",
                "        \"key\": key,\n",
                "        \"duration_sec\": len(y)/sr,\n",
                "        \"rms_mean\": np.mean(librosa.feature.rms(y=y))\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ 4. Lanzamiento del An√°lisis Masivo\n",
                "Ejecutamos el motor sobre todo el dataset. El uso de nnAudio en la GPU ver√° una mejora significativa en archivos grandes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "print(\"üöÄ Motor nnAudio Iniciado...\")\n",
                "\n",
                "for f in tqdm(all_files, desc=\"Procesando Dataset\"):\n",
                "    path = os.path.join(DATASET_PATH, f)\n",
                "    try:\n",
                "        res = process_with_nnaudio(path)\n",
                "        results.append(res)\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error en {f}: {e}\")\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "df.to_csv(os.path.join(OUTPUT_DIR, 'mir_gpu_report.csv'), index=False)\n",
                "print(f\"‚úÖ An√°lisis completado. Reporte generado en {OUTPUT_DIR}/mir_gpu_report.csv\")\n",
                "display(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ 5. Empaquetado de Resultados y Descarga Autom√°tica"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ZIP_NAME = 'MIR_nnAudio_GPU_Results.zip'\n",
                "\n",
                "print(\"üì¶ Creando archivo ZIP final...\")\n",
                "if os.path.exists(ZIP_NAME):\n",
                "    os.remove(ZIP_NAME)\n",
                "\n",
                "shutil.make_archive('MIR_nnAudio_GPU_Results', 'zip', OUTPUT_DIR)\n",
                "\n",
                "print(f\"\\nüéâ TODO LISTO: {ZIP_NAME}\")\n",
                "display(FileLink(ZIP_NAME, result_html_prefix=\"üîó DESCARGA TU AN√ÅLISIS AQU√ç: \"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}