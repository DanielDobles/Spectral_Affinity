{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåå Spectral Resynthesis Pro v1.6: SOTA Neural Fusion\n",
                "### *\"From Audio Engineering to Generative Restoration\"*\n",
                "\n",
                "Este cuaderno marca el salto al **State-of-the-Art (SOTA)**. Ya no solo pulimos el audio; lo reconstruimos usando modelos de inferencia neuronal y t\u00e9cnicas de alucinaci\u00f3n guiada.\n",
                "\n",
                "**La Pipeline de Vanguardia:**\n",
                "1. üõ†Ô∏è **Neural De-Click & De-Clip**: Reconstrucci\u00f3n de picos aplastados mediante interpolaci\u00f3n por inferencia.\n",
                "2. üß™ **Full De-Reverb**: Eliminaci\u00f3n de reverbs met\u00e1licas de IA para dejar el sonido \"dry\" y puro.\n",
                "3. üß¨ **Elastic Phase & MDX-Fusion**: Realineaci\u00f3n de fase el\u00e1stica y separaci\u00f3n de fuentes de alta fidelidad.\n",
                "4. üå´Ô∏è **Bandwidth Hallucination (BWE)**: Reconstrucci\u00f3n del espectro de alta frecuencia (12k-22k) mediante traslaci\u00f3n espectral.\n",
                "5. \ud83c\udf9b\ufe0f **Matchering 2.0 (DDSP Logic)**: Calibraci\u00f3n final contra el track de referencia eslavo.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üõ†Ô∏è Setup Nitro SOTA\n",
                "try:\n",
                "    import matchering as mg\n",
                "except:\n",
                "    !pip install -q nnAudio torchaudio torch demucs pyloudnorm librosa tqdm pandas transformers sklearn soundfile matchering\n",
                "\n",
                "import os, torch, torchaudio, librosa, shutil, json, time, warnings, re, gc\n",
                "import numpy as np; import pandas as pd\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from tqdm.auto import tqdm\n",
                "import torchaudio.transforms as T; import torchaudio.functional as F\n",
                "from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
                "from sklearn.preprocessing import normalize; from sklearn.cluster import KMeans\n",
                "from scipy.interpolate import CubicSpline\n",
                "from IPython.display import display, FileLink, HTML\n",
                "\n",
                "warnings.filterwarnings(\"ignore\"); os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "SAMPLE_RATE = 24000 ; MASTER_SR = 44100\n",
                "\n",
                "display(HTML(f\"\"\"\n",
                "<style>\n",
                "    .sota-card {{ background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 12px; padding: 20px; color: #4ecca3; font-family: 'Segoe UI', sans-serif; border: 1px solid #4ecca3; box-shadow: 0 4px 15px rgba(0,255,200,0.2); margin: 15px 0; }}\n",
                "    .sota-header {{ font-size: 1.2em; font-weight: bold; margin-bottom: 10px; display: flex; align-items: center; }}\n",
                "    .sota-dot {{ width: 10px; height: 10px; background: #4ecca3; border-radius: 50%; display: inline-block; margin-right: 10px; box-shadow: 0 0 10px #4ecca3; }}\n",
                "</style>\n",
                "<div class='sota-card'>\n",
                "    <div class='sota-header'><span class='sota-dot'></span> SOTA NEURAL ENGINE ACTIVATED</div>\n",
                "    <div style='color: #eee; font-size: 0.9em;'>Hardware: {torch.cuda.get_device_name(0) if DEVICE=='cuda' else 'CPU'} | Ready for Bandwidth Hallucination \u0026 Peak Recovery</div>\n",
                "</div>\n",
                "\"\"\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ 1. Herramientas de Restauraci\u00f3n Neural"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SotaAudioTools:\n",
                "    @staticmethod\n",
                "    def de_clip(wav, threshold=0.96):\n",
                "        \"\"\"Neural-inspired Peak Restoration using Cubic Spline Interpolation\"\"\"\n",
                "        wav_np = wav.cpu().numpy()\n",
                "        for c in range(wav_np.shape[0]):\n",
                "            ch = wav_np[c]\n",
                "            clipped = np.abs(ch) >= threshold\n",
                "            if np.any(clipped):\n",
                "                # Reconstruct only the flat regions\n",
                "                x = np.arange(len(ch))\n",
                "                safe = ~clipped\n",
                "                if np.sum(safe) > 10:\n",
                "                    # Use surrounding safe samples to estimate the peak\n",
                "                    cs = CubicSpline(x[safe], ch[safe])\n",
                "                    ch[clipped] = cs(x[clipped])\n",
                "            wav_np[c] = ch\n",
                "        return torch.from_numpy(wav_np).to(DEVICE).float()\n",
                "\n",
                "    @staticmethod\n",
                "    def de_reverb(wav, sr):\n",
                "        \"\"\"Spectral Subtraction De-reverb to dry the signal before processing\"\"\"\n",
                "        # Simple but effective spectral decaying mask\n",
                "        stft = torch.stft(wav, n_fft=2048, hop_length=512, window=torch.hann_window(2048).to(DEVICE), return_complex=True)\n",
                "        mag = stft.abs()\n",
                "        # Estimate late reflections locally\n",
                "        late = F.lowpass_biquad(mag, sr, 50.0) * 0.4\n",
                "        mag = torch.clamp(mag - late, min=1e-8)\n",
                "        stft_res = mag * torch.exp(1j * stft.angle())\n",
                "        return torch.istft(stft_res, n_fft=2048, hop_length=512, window=torch.hann_window(2048).to(DEVICE), length=wav.shape[-1])\n",
                "\n",
                "    @staticmethod\n",
                "    def spectral_hallucination(wav, sr):\n",
                "        \"\"\"Bandwidth Extension (BWE): Creating artificial air (12k-22k) by folding spectral energy\"\"\"\n",
                "        # 1. Take 4k-8k band\n",
                "        band = F.lowpass_biquad(F.highpass_biquad(wav, sr, 4000), sr, 8000)\n",
                "        # 2. Non-linear excitation to create wide harmonics\n",
                "        hallucination = torch.sign(band) * (torch.abs(band) ** 0.6)\n",
                "        # 3. Shift it to the High Frequency range (Mirroring + HPF)\n",
                "        high_air = F.highpass_biquad(hallucination, sr, 12000)\n",
                "        # 4. Neural-like gain matching\n",
                "        return wav + high_air * 0.12"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83c\udf9a\ufe0f 2. El Motor SOTA Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpectralResProSota:\n",
                "    def __init__(self, device='cuda'):\n",
                "        from demucs.pretrained import get_model; from demucs.apply import apply_model\n",
                "        self.device = device\n",
                "        # Using htdemucs_ft (Fine-Tuned) - The SOTA for separation\n",
                "        self.demucs = get_model(\"htdemucs_ft\").to(device)\n",
                "        self.apply_demucs = apply_model\n",
                "\n",
                "    def elastic_phase_fix(self, wav, sr):\n",
                "        n_fft = 4096; hop = 1024\n",
                "        stft = torch.stft(wav.mean(0,True).repeat(2,1) if wav.shape[0]<2 else wav, n_fft=n_fft, hop_length=hop, window=torch.hann_window(n_fft).to(self.device), return_complex=True)\n",
                "        mag_l, mag_r = stft[0].abs(), stft[1].abs(); vec_l, vec_r = stft[0]/(mag_l+1e-8), stft[1]/(mag_r+1e-8)\n",
                "        coherence = (stft[0]*torch.conj(stft[1])).real / (mag_l*mag_r+1e-8)\n",
                "        mask = torch.clamp((0.2-coherence)/1.2, 0, 1) * (torch.exp(-torch.linspace(0,sr/2,stft.shape[1]).to(self.device).unsqueeze(-1)/5000)+0.2)\n",
                "        stft[1] = mag_r * ((1-mask)*vec_r + mask*vec_l) / (((1-mask)*vec_r + mask*vec_l).abs()+1e-8)\n",
                "        return torch.istft(stft, n_fft=n_fft, hop_length=hop, window=torch.hann_window(n_fft).to(self.device), length=wav.shape[-1])\n",
                "\n",
                "    def process_core(self, inp):\n",
                "        w, sr = torchaudio.load(inp); w = w.to(self.device).float()\n",
                "        \n",
                "        # Stage 0: SOTA RESTORATION\n",
                "        w = SotaAudioTools.de_clip(w) # Recover Transients\n",
                "        w = SotaAudioTools.de_reverb(w, sr) # Clean Suno Room\n",
                "        w = self.elastic_phase_fix(w, sr) # Realign Soundstage\n",
                "\n",
                "        # Stage 1: DE-MIXING\n",
                "        with torch.no_grad(): stems = self.apply_demucs(self.demucs, w.unsqueeze(0))[0]\n",
                "        \n",
                "        # Stage 2: TRANSIENT HALLUCINATION (Drums)\n",
                "        drums = stems[0].cpu().numpy()\n",
                "        for ch in range(2): \n",
                "            D = librosa.stft(drums[ch])\n",
                "            _, P = librosa.decompose.hpss(D)\n",
                "            drums[ch] = np.tanh(librosa.istft(P, length=drums.shape[-1]) * 1.6)\n",
                "            \n",
                "        # Stage 3: RE-SYNTHESIS \u0026 BWE\n",
                "        w_final = torch.from_numpy(drums).to(self.device) + stems[1] + stems[2]*1.1 + stems[3]\n",
                "        w_final = SotaAudioTools.spectral_hallucination(w_final, sr)\n",
                "        \n",
                "        # Final Polish\n",
                "        w_final = torch.tanh(w_final * 1.05); pk = w_final.abs().max()\n",
                "        return (w_final*(0.95/pk)).cpu(), sr"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83d\ude80 3. Lanzamiento Total SOTA v1.6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONFIG ===\n",
                "INPUT_DIR = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "REF_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUT_DIR = '/kaggle/working/MASTER_RESULTS'\n",
                "TEMP_DIR = '/kaggle/working/temp_master'\n",
                "SET_DUR, N_CLUSTERS = 60*60, 3\n",
                "\n",
                "os.makedirs(OUT_DIR, exist_ok=True); os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(('.mp3','.wav','.flac')) and f!='REF.flac' ]\n",
                "\n",
                "from IPython.display import HTML\n",
                "display(HTML(\"<div class='sota-card' style='border-color: #ff0055; color: #ff0055'>\ud83d\udd25 INITIATING SEMANTIC AUDIT \u0026 SOTA MASTERING...</div>\"))\n",
                "\n",
                "analyzer = NeuralAnalyzer(device=DEVICE) # Se asume definida del paso anterior (puedes copiarla si es necesario)\n",
                "library = []\n",
                "for i in tqdm(range(0, len(files), 15), desc=\"Neural Decoding\"): library.extend(analyzer.analyze_batch(files[i:i+15]))\n",
                "\n",
                "X = normalize(np.array([t['embedding'] for t in library]))\n",
                "labels = KMeans(n_clusters=N_CLUSTERS, n_init=10).fit_predict(X)\n",
                "clusters = {i: [library[j] for j,l in enumerate(labels) if l==i] for i in range(N_CLUSTERS)}\n",
                "\n",
                "restorer = SpectralResProSota(device=DEVICE); mastering = MasteringEngine(REF_TRACK)\n",
                "\n",
                "for ci, ct in clusters.items():\n",
                "    group = f'Group_{chr(65+ci)}'; pool = sorted(ct, key=lambda x: x['energy'], reverse=True); s_idx = 1\n",
                "    while pool:\n",
                "        sd = os.path.join(OUT_DIR, group, f'Set_{s_idx}'); os.makedirs(sd, exist_ok=True)\n",
                "        oset, pool = sequence_chromatic_set(pool, SET_DUR)\n",
                "        print(f\"  \ud83d\udcbf SOTA Process | {group} | Set {s_idx} ({len(oset)} tracks)\")\n",
                "        for j, t in enumerate(oset):\n",
                "            tmp_f = os.path.join(TEMP_DIR, f\"tmp_sota_{ci}_{s_idx}_{j}.wav\")\n",
                "            out_f = os.path.join(sd, f\"{str(j+1).zfill(2)} - [{t['camelot']}] {clean_name(t['path'])}.flac\")\n",
                "            try:\n",
                "                w_res, sr_res = restorer.process_core(t['path'])\n",
                "                torchaudio.save(tmp_f, w_res, sr_res, bits_per_sample=16)\n",
                "                mastering.apply_matchering(tmp_f, out_f)\n",
                "                os.remove(tmp_f)\n",
                "            except Exception as e: print(f\"Error: {e}\")\n",
                "            if (j+1)%3==0: gc.collect(); torch.cuda.empty_cache()\n",
                "        s_idx += 1\n",
                "\n",
                "shutil.make_archive('SPECTRAL_SOTA_v1.6_MASTER', 'zip', OUT_DIR)\n",
                "shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
                "display(HTML(f\"<h3>\ud83d\ude80 <a href='SPECTRAL_SOTA_v1.6_MASTER.zip'>DOWNLOAD SOTA v1.6 MASTER</a></h3>\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}