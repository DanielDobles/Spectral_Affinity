{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåå Spectral Resynthesis Pro v1.8: Pure Reverb Edition\n",
                "### *\"Neural Reconstruction keeping original room acoustics\"*\n",
                "\n",
                "Esta versi\u00f3n mantiene la potencia SOTA de reconstrucci\u00f3n neuronal pero **elimina el De-Reverb**, preservando la espacialidad y el car\u00e1cter original de las generaciones de Suno. \n",
                "\n",
                "**La Pipeline SOTA Refinada:**\n",
                "1. \ud83e\uddec **htdemucs_ft**: Separaci\u00f3n de fuentes de alta pureza conservando la espacialidad original.\n",
                "2. \ud83d\uddef\ufe0f **VoiceFixer (Vocals Stage)**: Reconstrucci\u00f3n generativa de voces con Vocoder Neuronal y BWE para recuperar el brillo y detalle.\n",
    "3. üß¨ **Elastic Phase Rotator**: Correcci\u00f3n de fase quir\u00furgica para asegurar un centro s\u00f3lido y compatibilidad mono.\n",
                "4. \ud83c\udf9b\ufe0f **Matchering 2.0**: Calibraci\u00f3n final de tono y volumen contra tu pista de referencia eslava.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üõ†Ô∏è Setup\n",
                "try:\n",
                "    from voicefixer import VoiceFixer\n",
                "except:\n",
                "    !pip install -q nnAudio torchaudio torch demucs pyloudnorm librosa tqdm pandas transformers sklearn soundfile matchering voicefixer\n",
                "\n",
                "import os, torch, torchaudio, librosa, shutil, json, time, warnings, gc\n",
                "import numpy as np; import pandas as pd\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from tqdm.auto import tqdm\n",
                "import torchaudio.transforms as T; import torchaudio.functional as F\n",
                "from voicefixer import VoiceFixer\n",
                "from IPython.display import display, FileLink, HTML\n",
                "\n",
                "warnings.filterwarnings(\"ignore\"); os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "MASTER_SR = 44100\n",
                "\n",
                "display(HTML(\"\"\"\n",
                "<style>\n",
                "    .sota-v8 {{ background: #000d1a; border: 2px solid #00f2fe; border-radius: 15px; padding: 25px; color: #fff; font-family: 'Consolas', monospace; box-shadow: 0 0 25px #00f2fe44; }}\n",
                "    .sota-text {{ color: #00f2fe; font-weight: bold; font-size: 1.3em; letter-spacing: 1px; }}\n",
                "</style>\n",
                "<div class='sota-v8'>\n",
                "    <div class='sota-text'>\ud83c\udf0a NEURAL MASTER v1.8: NATURAL REVERB FLOW</div>\n",
                "    <p style='color: #eee; margin-top:10px;'>Models: VoiceFixer TSTNN, HTDemucs-FT | De-Reverb: DISABLED</p>\n",
                "</div>\n",
                "\"\"\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83e\udde0 1. Motor SOTA (Sin Fase de Limpieza de Sala)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SotaNeuralProcessor:\n",
                "    def __init__(self, device='cuda'):\n",
                "        self.device = device\n",
                "        # VoiceFixer: Reconstrucci\u00f3n de voces (usaremos modo para mantener reverb si es posible)\n",
                "        self.vfixer = VoiceFixer()\n",
                "        # Demucs Fine-Tuned (HTDemucs-FT)\n",
                "        from demucs.pretrained import get_model; from demucs.apply import apply_model\n",
                "        self.demucs = get_model(\"htdemucs_ft\").to(device)\n",
                "        self.apply_demucs = apply_model\n",
                "\n",
                "    def neural_vocal_fix(self, wav, sr, tmp_name=\"vocal_tmp.wav\"):\n",
                "        \"\"\"VoiceFixer para reconstruir el brillo. Usamos el modo que menos afecta a la reverb.\"\"\"\n",
                "        torchaudio.save(tmp_name, wav.cpu(), sr)\n",
                "        out_tmp = tmp_name.replace(\".wav\", \"_fix.wav\")\n",
                "        # Mode 1: Solo Denoise + BWE (Mantiene m\u00e1s la reverb original que el Mode 0)\n",
                "        self.vfixer.restore(tmp_name, out_tmp, mode=1, cuda=(self.device=='cuda'))\n",
                "        fixed_wav, _ = torchaudio.load(out_tmp)\n",
                "        if os.path.exists(tmp_name): os.remove(tmp_name)\n",
                "        if os.path.exists(out_tmp): os.remove(out_tmp)\n",
                "        return fixed_wav.to(self.device)\n",
                "\n",
                "    def elastic_phase_fix(self, wav, sr):\n",
                "        n_fft = 4096; hop = 1024\n",
                "        stft = torch.stft(wav.mean(0,True).repeat(2,1) if wav.shape[0]<2 else wav, n_fft=n_fft, hop_length=hop, window=torch.hann_window(n_fft).to(self.device), return_complex=True)\n",
                "        mag_l, mag_r = stft[0].abs(), stft[1].abs(); vec_l, vec_r = stft[0]/(mag_l+1e-8), stft[1]/(mag_r+1e-8)\n",
                "        coherence = (stft[0]*torch.conj(stft[1])).real / (mag_l*mag_r+1e-8)\n",
                "        mask = torch.clamp((0.2-coherence)/1.2, 0, 1) * (torch.exp(-torch.linspace(0,sr/2,stft.shape[1]).to(self.device).unsqueeze(-1)/5000)+0.2)\n",
                "        stft[1] = mag_r * ((1-mask)*vec_r + mask*vec_l) / (((1-mask)*vec_r + mask*vec_l).abs()+1e-8)\n",
                "        return torch.istft(stft, n_fft=n_fft, hop_length=hop, window=torch.hann_window(n_fft).to(self.device), length=wav.shape[-1])\n",
                "\n",
                "    def process_full_sota(self, input_path):\n",
                "        # 1. Load Original (Saltamos DeepFilterNet para NO quitar reverb)\n",
                "        w, sr = torchaudio.load(input_path)\n",
                "        w = w.to(self.device).float()\n",
                "        if w.shape[0] > 2: w = w[:2] # Ensure Stereo/Mono\n",
                "        \n",
                "        # 2. Separate (HTDemucs-FT) - Mantiene la espacialidad original\n",
                "        with torch.no_grad(): stems = self.apply_demucs(self.demucs, w.unsqueeze(0))[0]\n",
                "        \n",
                "        # 3. Vocals Reconstruction\n",
                "        vocal_fixed = self.neural_vocal_fix(stems[3], MASTER_SR)\n",
                "        \n",
                "        # 4. Drums Transient Shaping (HPSS)\n",
                "        drums = stems[0].cpu().numpy()\n",
                "        for ch in range(2): \n",
                "            D = librosa.stft(drums[ch])\n",
                "            _, P = librosa.decompose.hpss(D)\n",
                "            drums[ch] = np.tanh(librosa.istft(P, length=drums.shape[-1]) * 1.6)\n",
                "        \n",
                "        # 5. Hybrid Mixdown\n",
                "        w_mix = torch.from_numpy(drums).to(self.device) + stems[1] + stems[2]*1.1 + vocal_fixed\n",
                "        \n",
                "        # 6. Final Phase Surgery\n",
                "        w_final = self.elastic_phase_fix(w_mix, MASTER_SR)\n",
                "        \n",
                "        pk = w_final.abs().max()\n",
                "        return (w_final*(0.95/pk)).cpu(), MASTER_SR"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83d\ude80 2. Main Execution (Kaggle Edition)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Config e Inicio de Pipeline\n",
                "INPUT_DIR = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "REF_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUT_DIR = '/kaggle/working/MASTER_RESULTS_V8'\n",
                "os.makedirs(OUT_DIR, exist_ok=True)\n",
                "\n",
                "files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(('.mp3','.wav','.flac')) and f!='REF.flac' ]\n",
                "\n",
                "print(\"\ud83e\udde0 Analyzing Semantic Affinity...\")\n",
                "analyzer = NeuralAnalyzer(device=DEVICE)\n",
                "library = []\n",
                "for i in tqdm(range(0, len(files), 16)): library.extend(analyzer.analyze_batch(files[i:i+16]))\n",
                "\n",
                "sets = sequence_sets(pd.DataFrame(library), 60)\n",
                "\n",
                "processor = SotaNeuralProcessor(device=DEVICE)\n",
                "mastering = MasteringEngine(REF_TRACK)\n",
                "\n",
                "for i, h_set in enumerate(sets):\n",
                "    sd = os.path.join(OUT_DIR, f'Set_{i+1}'); os.makedirs(sd, exist_ok=True)\n",
                "    print(f\"  \ud83d\udd2a SOTA Flow | Set {i+1}\")\n",
                "    for j, t in enumerate(h_set):\n",
                "        tmp_f = f\"temp_sota_{j}.wav\"\n",
                "        out_f = os.path.join(sd, f\"{str(j+1).zfill(2)} - [{t['camelot']}] {clean_name(t['path'])}.flac\")\n",
                "        try:\n",
                "            w, sr = processor.process_full_sota(t['path'])\n",
                "            torchaudio.save(tmp_f, w, sr, bits_per_sample=16)\n",
                "            mastering.apply_matchering(tmp_f, out_f)\n",
                "            if os.path.exists(tmp_f): os.remove(tmp_f)\n",
                "        except Exception as e: print(f\"Error: {e}\")\n",
                "        if (j+1)%2==0: gc.collect(); torch.cuda.empty_cache()\n",
                "\n",
                "shutil.make_archive('SPECTRAL_SOTA_v1.8_MASTER', 'zip', OUT_DIR)\n",
                "display(FileLink('SPECTRAL_SOTA_v1.8_MASTER.zip'))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}