{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŒŒ Spectral Resynthesis Pro v1.7: TRUE NEURAL SOTA\n",
                "### *\"Deep Learning Reconstruction: No more DSP Marketing\"*\n",
                "\n",
                "Esta versi\u00f3n elimina los parches matem\u00e1ticos (Splines, Excitation) y los reemplaza por modelos de **Deep Learning Reconstructivo**. Entramos en la era de la inferencia neuronal real para restaurar Suno.\n",
                "\n",
                "**La Pipeline Cient\u00edfica SOTA:**\n",
                "1. \ud83d\udee0\ufe0f **DeepFilterNet 3**: Inferencia en tiempo real para eliminaci\u00f3n de ruido y reverb (SOTA en Speech/Audio Enhancement).\n",
                "2. \ud83e\uddec **htdemucs_ft**: Separaci\u00f3n por Transformadores H\u00edbridos (Fine-Tuned) para m\u00e1xima pureza de stems.\n",
                "3. \ud83d\uddef\ufe0f **VoiceFixer (Vocals Stage)**: Reconstrucci\u00f3n generativa de voces usando un Vocoder Neuronal. Restaura el brillo y aire perdido en las voces de la IA.\n",
    "4. ðŸ§¬ **Elastic Phase Rotator**: Correcci\u00f3n de fase quir\u00furgica (matem\u00e1tica sÃ³lida).\n",
                "5. \ud83c\udf9b\ufe0f **Matchering 2.0**: Calibraci\u00f3n final contra el track de referencia eslavo.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# \ud83d\udee0\ufe0f Instalaci\u00f3n SOTA REAL \ud83d\ude80\n",
                "try:\n",
                "    from df.enhance import enhance, init_df, load_audio, save_audio\n",
                "    from voicefixer import VoiceFixer\n",
                "except:\n",
                "    !pip install -q nnAudio torchaudio torch demucs pyloudnorm librosa tqdm pandas transformers sklearn soundfile matchering\n",
                "    !pip install -q deepfilternet voicefixer\n",
                "\n",
                "import os, torch, torchaudio, librosa, shutil, json, time, warnings, gc\n",
                "import numpy as np; import pandas as pd\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "from tqdm.auto import tqdm\n",
                "import torchaudio.transforms as T; import torchaudio.functional as F\n",
                "from df.enhance import enhance, init_df, load_audio, save_audio\n",
                "from voicefixer import VoiceFixer\n",
                "from IPython.display import display, FileLink, HTML\n",
                "\n",
                "warnings.filterwarnings(\"ignore\"); os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "MASTER_SR = 44100\n",
                "\n",
                "display(HTML(\"\"\"\n",
                "<style>\n",
                "    .sota-v7 {{ background: #0c0014; border: 2px solid #9d00ff; border-radius: 15px; padding: 25px; color: #fff; font-family: 'Courier New', monospace; box-shadow: 0 0 20px #9d00ff88; }}\n",
                "    .sota-glitch {{ text-shadow: 2px 2px #ff0055, -2px -2px #00ffcc; font-weight: bold; font-size: 1.4em; }}\n",
                "</style>\n",
                "<div class='sota-v7'>\n",
                "    <div class='sota-glitch'>\u2622\ufe0f TRUE NEURAL PIPELINE v1.7 READY</div>\n",
                "    <p style='color: #00ffcc; margin-top:10px;'>Models Loaded: DeepFilterNet3, VoiceFixer TSTNN, HTDemucs-FT</p>\n",
                "</div>\n",
                "\"\"\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83e\udde0 1. El Cerebro Cient\u00edfico: Modelos SOTA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SotaNeuralProcessor:\n",
                "    def __init__(self, device='cuda'):\n",
                "        self.device = device\n",
                "        # DeepFilterNet3: SOTA for Dereverb/Denoise\n",
                "        self.df_model, self.df_state, _ = init_df()\n",
                "        # VoiceFixer: SOTA for Vocals Reconstruction (44.1k BWE)\n",
                "        self.vfixer = VoiceFixer()\n",
                "        # Demucs Fine-Tuned (HTDemucs-FT)\n",
                "        from demucs.pretrained import get_model; from demucs.apply import apply_model\n",
                "        self.demucs = get_model(\"htdemucs_ft\").to(device)\n",
                "        self.apply_demucs = apply_model\n",
                "\n",
                "    def deep_cleanup(self, wav_path):\n",
                "        \"\"\"Fase 1: DeepFilterNet para limpiar la se\u00f1al completa\"\"\"\n",
                "        audio, _ = load_audio(wav_path, sr=self.df_state.sr())\n",
                "        enhanced = enhance(self.df_model, self.df_state, audio)\n",
                "        # Convert back to torch tensor\n",
                "        return enhanced[0] if isinstance(enhanced, tuple) else enhanced\n",
                "\n",
                "    def neural_vocal_fix(self, wav, sr, tmp_name=\"vocal_tmp.wav\"):\n",
                "        \"\"\"Fase 3: VoiceFixer para reconstruir el brillo y aire de las voces\"\"\"\n",
                "        torchaudio.save(tmp_name, wav.cpu(), sr)\n",
                "        out_tmp = tmp_name.replace(\".wav\", \"_fix.wav\")\n",
                "        # Mode 2: Dereverb + Denoise + BWE\n",
                "        self.vfixer.restore(tmp_name, out_tmp, mode=0, cuda=(self.device=='cuda'))\n",
                "        fixed_wav, _ = torchaudio.load(out_tmp)\n",
                "        if os.path.exists(tmp_name): os.remove(tmp_name)\n",
                "        if os.path.exists(out_tmp): os.remove(out_tmp)\n",
                "        return fixed_wav.to(self.device)\n",
                "\n",
                "    def elastic_phase_fix(self, wav, sr):\n",
                "        n_fft = 4096; hop = 1024\n",
                "        stft = torch.stft(wav.mean(0,True).repeat(2,1) if wav.shape[0]<2 else wav, n_fft=n_fft, hop_length=hop, window=torch.hann_window(n_fft).to(self.device), return_complex=True)\n",
                "        mag_l, mag_r = stft[0].abs(), stft[1].abs(); vec_l, vec_r = stft[0]/(mag_l+1e-8), stft[1]/(mag_r+1e-8)\n",
                "        coherence = (stft[0]*torch.conj(stft[1])).real / (mag_l*mag_r+1e-8)\n",
                "        mask = torch.clamp((0.2-coherence)/1.2, 0, 1) * (torch.exp(-torch.linspace(0,sr/2,stft.shape[1]).to(self.device).unsqueeze(-1)/5000)+0.2)\n",
                "        stft[1] = mag_r * ((1-mask)*vec_r + mask*vec_l) / (((1-mask)*vec_r + mask*vec_l).abs()+1e-8)\n",
                "        return torch.istft(stft, n_fft=n_fft, hop_length=hop, window=torch.hann_window(n_fft).to(self.device), length=wav.shape[-1])\n",
                "\n",
                "    def process_full_sota(self, input_path):\n",
                "        # 1. Clean\n",
                "        w_clean = self.deep_cleanup(input_path).to(self.device)\n",
                "        if w_clean.ndim == 1: w_clean = w_clean.unsqueeze(0)\n",
                "        \n",
                "        # 2. Separate (SOTA FT Model)\n",
                "        with torch.no_grad(): stems = self.apply_demucs(self.demucs, w_clean.unsqueeze(0))[0]\n",
                "        \n",
                "        # 3. Vocals Reconstruction (The Generative Part)\n",
                "        vocal_fixed = self.neural_vocal_fix(stems[3], MASTER_SR)\n",
                "        \n",
                "        # 4. Drums Transient Shaping (HPSS is the best for this specific job)\n",
                "        drums = stems[0].cpu().numpy()\n",
                "        for ch in range(2): \n",
                "            D = librosa.stft(drums[ch])\n",
                "            _, P = librosa.decompose.hpss(D)\n",
                "            drums[ch] = np.tanh(librosa.istft(P, length=drums.shape[-1]) * 1.6)\n",
                "        \n",
                "        # 5. Hybrid Mixdown\n",
                "        w_mix = torch.from_numpy(drums).to(self.device) + stems[1] + stems[2]*1.1 + vocal_fixed\n",
                "        \n",
                "        # 6. Final Phase Surgery\n",
                "        w_final = self.elastic_phase_fix(w_mix, MASTER_SR)\n",
                "        \n",
                "        pk = w_final.abs().max()\n",
                "        return (w_final*(0.95/pk)).cpu(), MASTER_SR"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## \ud83d\ude80 2. Main Execution (Kaggle True SOTA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "INPUT_DIR = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "REF_TRACK = '/kaggle/input/datasets/danieldobles/slavic-songs/REF.flac'\n",
                "OUT_DIR = '/kaggle/working/MASTER_RESULTS_V7'\n",
                "os.makedirs(OUT_DIR, exist_ok=True)\n",
                "\n",
                "files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(('.mp3','.wav','.flac')) and f!='REF.flac' ]\n",
                "\n",
                "# Se asumen NeuralAnalyzer y las funciones de clustering/secuenciaci\u00f3n definidas antes.\n",
                "print(\"\ud83e\udde0 Analyzing Semantic Library...\")\n",
                "analyzer = NeuralAnalyzer(device=DEVICE)\n",
                "library = []\n",
                "for i in tqdm(range(0, len(files), 16)): library.extend(analyzer.analyze_batch(files[i:i+16]))\n",
                "\n",
                "sets = sequence_sets(pd.DataFrame(library), 60) # Usando la lÃ³gica de agrupaciÃ³n previa\n",
                "\n",
                "processor = SotaNeuralProcessor(device=DEVICE)\n",
                "mastering = MasteringEngine(REF_TRACK)\n",
                "\n",
                "for i, h_set in enumerate(sets):\n",
                "    sd = os.path.join(OUT_DIR, f'Set_{i+1}'); os.makedirs(sd, exist_ok=True)\n",
                "    print(f\"  \u2622\ufe0f SOTA Master | Set {i+1}\")\n",
                "    for j, t in enumerate(h_set):\n",
                "        tmp_f = f\"temp_sota_{j}.wav\"\n",
                "        out_f = os.path.join(sd, f\"{str(j+1).zfill(2)} - [{t['camelot']}] {clean_name(t['path'])}.flac\")\n",
                "        try:\n",
                "            w, sr = processor.process_full_sota(t['path'])\n",
                "            torchaudio.save(tmp_f, w, sr, bits_per_sample=16)\n",
                "            mastering.apply_matchering(tmp_f, out_f)\n",
                "            if os.path.exists(tmp_f): os.remove(tmp_f)\n",
                "        except Exception as e: print(f\"Error: {e}\")\n",
                "        if (j+1)%2==0: gc.collect(); torch.cuda.empty_cache()\n",
                "\n",
                "shutil.make_archive('SPECTRAL_TRUE_SOTA_v1.7', 'zip', OUT_DIR)\n",
                "display(FileLink('SPECTRAL_TRUE_SOTA_v1.7.zip'))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}