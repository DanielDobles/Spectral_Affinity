{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.14"
        },
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "dockerImageVersionId": 30787,
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5,
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cell-00-banner",
            "metadata": {},
            "source": [
                "# ğŸŒŒ Spectral Affinity v3.0 â€” Music-CLAP Edition\n",
                "### *The Ultimate AI Librarian for Semantic Clustering & Camelot-based Harmonic Flow*\n",
                "\n",
                "---\n",
                "\n",
                "| Module | Technology | Role |\n",
                "|--------|-----------|------|\n",
                "| ğŸ§  Neural Key Detection | nnAudio CQT1992v2 | Chromagram â†’ Camelot notation |\n",
                "| ğŸµ Semantic Embeddings | Microsoft Music-CLAP | Vibe / genre / mood vectors |\n",
                "| ğŸ¥ Rhythm Analysis | librosa beat_track | BPM per track |\n",
                "| ğŸ”€ Semantic Clustering | KMeans (CLAP space) | Group tracks by acoustic vibe |\n",
                "| ğŸ›ï¸ Harmonic Sequencing | Camelot Wheel Engine | DJ-grade BPM-ascending playlist flow |\n",
                "| ğŸ“¦ Export | shutil + zipfile | Renamed files + ZIP download |\n",
                "\n",
                "> **This tool is a read-only AI Librarian.**  \n",
                "> It analyses, classifies, renames and copies your files â€” it never alters audio samples.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-01-install",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 1 â€” Install Dependencies (Deep Recovery Mode)\n",
                "# ============================================================\n",
                "import subprocess, sys, os\n",
                "\n",
                "def run(cmd):\n",
                "    subprocess.check_call([sys.executable, '-m', 'pip', *cmd])\n",
                "\n",
                "print('â³ Performing deep dependency recovery...')\n",
                "\n",
                "try:\n",
                "    # 1. Limpieza total de NumPy para evitar el error 'numpy.char'\n",
                "    run(['uninstall', '-y', 'numpy'])\n",
                "    \n",
                "    # 2. Instalacion limpia de dependencias core\n",
                "    # Forzamos 1.26.4 porque es la ultima v1 estable para audio neural\n",
                "    run(['install', '-q', '--no-warn-conflicts', 'numpy==1.26.4'])\n",
                "    \n",
                "    # 3. Instalacion de librerias de Spectral Affinity\n",
                "    run(['install', '-q', '--no-warn-conflicts', \n",
                "         'nnAudio>=0.3.3', \n",
                "         'msclap>=1.3.3', \n",
                "         'librosa>=0.10.0', \n",
                "         'scikit-learn>=1.3.0', \n",
                "         'tqdm', \n",
                "         'soundfile'])\n",
                "\n",
                "    print('\\nâœ… Installation complete!')\n",
                "    print('âš ï¸  IMPORTANT: You MUST restart the kernel now (Run -> Restart Kernel)')\n",
                "    print('   to load the corrected NumPy structure.')\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f'âŒ Critical Error during install: {e}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-02-imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 2 â€” Imports & GPU Setup\n",
                "# ============================================================\n",
                "import os\n",
                "import re\n",
                "import shutil\n",
                "import zipfile\n",
                "import warnings\n",
                "import math\n",
                "from pathlib import Path\n",
                "from typing import List, Dict, Optional, Tuple\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import librosa\n",
                "import soundfile as sf\n",
                "from tqdm.auto import tqdm\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.preprocessing import normalize\n",
                "\n",
                "# nnAudio GPU spectrogram\n",
                "from nnAudio.features import CQT1992v2\n",
                "\n",
                "# Music-CLAP\n",
                "from msclap import CLAP\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'ğŸ–¥ï¸  Device: {DEVICE}')\n",
                "if DEVICE.type == 'cuda':\n",
                "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
                "    print(f'   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
                "else:\n",
                "    print('âš ï¸  No GPU detected â€” analysis will run on CPU (slower but functional).')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-03-camelot",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 3 â€” Camelot Wheel Definitions & Harmonic Engine\n",
                "# ============================================================\n",
                "\n",
                "# ---------------------------------------------------------------------------\n",
                "# Krumhansl-Schmuckler key-profile templates (24 keys: 12 major + 12 minor)\n",
                "# ---------------------------------------------------------------------------\n",
                "KS_MAJOR = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09,\n",
                "                     2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
                "KS_MINOR = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n",
                "                     2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
                "\n",
                "# Pitch class names (starting from C)\n",
                "PITCH_NAMES = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
                "\n",
                "# ---------------------------------------------------------------------------\n",
                "# Camelot Wheel mapping  key_string -> camelot_code\n",
                "# Format: 'Note Mode' -> 'NNX'  (NN = 01-12, X = A/B)\n",
                "#   A = minor (inner ring)   B = major (outer ring)\n",
                "# ---------------------------------------------------------------------------\n",
                "CAMELOT_MAP: Dict[str, str] = {\n",
                "    # Minor keys  (A = inner ring)\n",
                "    'Ab minor': '01A', 'G# minor': '01A',\n",
                "    'Eb minor': '02A', 'D# minor': '02A',\n",
                "    'Bb minor': '03A', 'A# minor': '03A',\n",
                "    'F minor':  '04A',\n",
                "    'C minor':  '05A',\n",
                "    'G minor':  '06A',\n",
                "    'D minor':  '07A',\n",
                "    'A minor':  '08A',\n",
                "    'E minor':  '09A',\n",
                "    'B minor':  '10A',\n",
                "    'F# minor': '11A', 'Gb minor': '11A',\n",
                "    'C# minor': '12A', 'Db minor': '12A',\n",
                "    # Major keys  (B = outer ring)\n",
                "    'B major':  '01B',\n",
                "    'F# major': '02B', 'Gb major': '02B',\n",
                "    'Db major': '03B', 'C# major': '03B',\n",
                "    'Ab major': '04B', 'G# major': '04B',\n",
                "    'Eb major': '05B', 'D# major': '05B',\n",
                "    'Bb major': '06B', 'A# major': '06B',\n",
                "    'F major':  '07B',\n",
                "    'C major':  '08B',\n",
                "    'G major':  '09B',\n",
                "    'D major':  '10B',\n",
                "    'A major':  '11B',\n",
                "    'E major':  '12B',\n",
                "}\n",
                "\n",
                "# Reverse map: camelot -> canonical key name (for display)\n",
                "CAMELOT_REVERSE: Dict[str, str] = {v: k for k, v in CAMELOT_MAP.items() if 'b' not in k.split()[0] or k.split()[0] in ('Bb','Db','Eb','Gb','Ab')}\n",
                "\n",
                "\n",
                "def key_to_camelot(pitch_class: int, is_major: bool) -> str:\n",
                "    \"\"\"Convert a detected pitch class (0=C..11=B) and mode to Camelot notation.\"\"\"\n",
                "    note = PITCH_NAMES[pitch_class]\n",
                "    mode = 'major' if is_major else 'minor'\n",
                "    key_str = f'{note} {mode}'\n",
                "    return CAMELOT_MAP.get(key_str, '??')\n",
                "\n",
                "\n",
                "def camelot_neighbours(code: str) -> List[str]:\n",
                "    \"\"\"\n",
                "    Return the 3 safe harmonic neighbours of a Camelot code:\n",
                "      1. Same position (identity)        e.g. 08A -> 08A\n",
                "      2. Â±1 step clockwise/anticlockwise e.g. 08A -> 07A, 09A\n",
                "      3. Relative mode switch            e.g. 08A -> 08B\n",
                "    \"\"\"\n",
                "    if not re.match(r'^\\d{2}[AB]$', code):\n",
                "        return []\n",
                "    num  = int(code[:2])   # 1-12\n",
                "    mode = code[2]         # A or B\n",
                "    alt  = 'B' if mode == 'A' else 'A'\n",
                "\n",
                "    prev_num = ((num - 2) % 12) + 1\n",
                "    next_num = (num % 12) + 1\n",
                "\n",
                "    fmt = lambda n, m: f'{n:02d}{m}'\n",
                "    return [\n",
                "        fmt(num,      mode),   # same\n",
                "        fmt(prev_num, mode),   # -1 step\n",
                "        fmt(next_num, mode),   # +1 step\n",
                "        fmt(num,      alt),    # relative mode switch\n",
                "    ]\n",
                "\n",
                "\n",
                "def get_next_harmonic(current_code: str, candidates: List[Dict]) -> Optional[Dict]:\n",
                "    \"\"\"\n",
                "    Given the current Camelot code and a list of candidate track dicts\n",
                "    (each with 'camelot' and 'bpm' keys), return the best next track:\n",
                "      - Must be a harmonic neighbour\n",
                "      - Prefer ascending BPM within compatible keys\n",
                "    Returns None if no harmonic match found.\n",
                "    \"\"\"\n",
                "    neighbours = set(camelot_neighbours(current_code))\n",
                "    compatible = [t for t in candidates if t.get('camelot', '??') in neighbours]\n",
                "    if not compatible:\n",
                "        return None\n",
                "    # Among compatible, pick the one with BPM closest to current (ascending preference)\n",
                "    compatible.sort(key=lambda t: t.get('bpm', 0))\n",
                "    return compatible[0]\n",
                "\n",
                "\n",
                "print('âœ… Camelot engine loaded.')\n",
                "print(f'   Wheel codes available: {len(set(CAMELOT_MAP.values()))}')\n",
                "# Quick sanity-check\n",
                "assert camelot_neighbours('08A') == ['08A', '07A', '09A', '08B'], 'Neighbour check failed'\n",
                "print('   Sanity check passed: 08A â†’ [08A, 07A, 09A, 08B]')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-04-analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 4 â€” Audio Analysis Engine (CQT Key + librosa BPM)\n",
                "# ============================================================\n",
                "\n",
                "# Build the CQT transform module once (reused across all tracks)\n",
                "_cqt_transform = CQT1992v2(\n",
                "    sr=22050,\n",
                "    hop_length=512,\n",
                "    fmin=librosa.note_to_hz('C2'),\n",
                "    n_bins=84,          # 7 octaves Ã— 12 bins/octave\n",
                "    bins_per_octave=12,\n",
                "    output_format='Magnitude',\n",
                "    verbose=False,\n",
                ").to(DEVICE)\n",
                "\n",
                "\n",
                "def detect_key_cqt(y: np.ndarray, sr: int) -> str:\n",
                "    \"\"\"\n",
                "    Detect musical key using GPU CQT + Krumhansl-Schmuckler profile matching.\n",
                "\n",
                "    Steps:\n",
                "    1. Resample to 22050 Hz\n",
                "    2. Compute CQT spectrogram on GPU\n",
                "    3. Sum energy per pitch class (chroma vector)\n",
                "    4. Correlate chroma against all 24 KS templates (12-step circular shift)\n",
                "    5. Return best-matching key in Camelot notation\n",
                "    \"\"\"\n",
                "    if sr != 22050:\n",
                "        y = librosa.resample(y, orig_sr=sr, target_sr=22050)\n",
                "        sr = 22050\n",
                "\n",
                "    # Mono tensor on GPU\n",
                "    y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        cqt_mag = _cqt_transform(y_tensor)  # (1, n_bins, T)\n",
                "\n",
                "    # Average across time, then fold into 12 pitch classes\n",
                "    cqt_mean = cqt_mag.squeeze(0).mean(dim=-1).cpu().numpy()  # (84,)\n",
                "    chroma = np.zeros(12)\n",
                "    for i in range(84):\n",
                "        chroma[i % 12] += cqt_mean[i]\n",
                "\n",
                "    # Normalize chroma\n",
                "    chroma_norm = chroma / (chroma.sum() + 1e-8)\n",
                "\n",
                "    # Correlate against all 24 key profiles (circular shifts of KS templates)\n",
                "    best_score = -np.inf\n",
                "    best_pc    = 0\n",
                "    best_major = True\n",
                "\n",
                "    for pc in range(12):\n",
                "        shifted_major = np.roll(KS_MAJOR, -pc)\n",
                "        shifted_minor = np.roll(KS_MINOR, -pc)\n",
                "\n",
                "        score_major = np.corrcoef(chroma_norm, shifted_major / shifted_major.sum())[0, 1]\n",
                "        score_minor = np.corrcoef(chroma_norm, shifted_minor / shifted_minor.sum())[0, 1]\n",
                "\n",
                "        if score_major > best_score:\n",
                "            best_score = score_major\n",
                "            best_pc    = pc\n",
                "            best_major = True\n",
                "        if score_minor > best_score:\n",
                "            best_score = score_minor\n",
                "            best_pc    = pc\n",
                "            best_major = False\n",
                "\n",
                "    return key_to_camelot(best_pc, best_major)\n",
                "\n",
                "\n",
                "def detect_bpm(y: np.ndarray, sr: int) -> float:\n",
                "    \"\"\"\n",
                "    Compute BPM using librosa beat tracking.\n",
                "    Clamps to [60, 200] BPM to handle half-time / double-time artefacts.\n",
                "    \"\"\"\n",
                "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
                "    bpm = float(tempo[0]) if hasattr(tempo, '__len__') else float(tempo)\n",
                "\n",
                "    # Halve / double until in range\n",
                "    while bpm > 200:\n",
                "        bpm /= 2\n",
                "    while bpm < 60:\n",
                "        bpm *= 2\n",
                "\n",
                "    return round(bpm, 1)\n",
                "\n",
                "\n",
                "print('âœ… Audio analysis engine ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-05-clap",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 5 â€” Music-CLAP Embedding Extractor\n",
                "# ============================================================\n",
                "# Model: microsoft/msclap  â€”  checkpoint: music_2023\n",
                "# Downloads ~1 GB on first run, cached afterwards.\n",
                "\n",
                "print('Loading Music-CLAP model (this may download ~1 GB on first run)...')\n",
                "_clap_model = CLAP(version='music_2023', use_cuda=(DEVICE.type == 'cuda'))\n",
                "print('âœ… Music-CLAP model loaded.')\n",
                "\n",
                "\n",
                "def get_clap_embedding(audio_path: str) -> np.ndarray:\n",
                "    \"\"\"\n",
                "    Extract a 512-d semantic embedding for a single audio file using Music-CLAP.\n",
                "    Returns a L2-normalized numpy vector.\n",
                "    \"\"\"\n",
                "    emb = _clap_model.get_audio_embeddings([audio_path], resample=True)  # (1, 512)\n",
                "    emb_np = emb.squeeze(0).cpu().numpy() if isinstance(emb, torch.Tensor) else np.array(emb).squeeze(0)\n",
                "    # L2-normalize\n",
                "    norm = np.linalg.norm(emb_np)\n",
                "    return emb_np / (norm + 1e-8)\n",
                "\n",
                "\n",
                "print('   CLAP embedding function ready. Output shape: (512,)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-06-pipeline",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 6 â€” Batch GPU Analysis Pipeline\n",
                "# ============================================================\n",
                "# Processes every audio file in INPUT_DIR and returns a list of track dicts.\n",
                "\n",
                "SUPPORTED_EXTS = {'.wav', '.mp3', '.flac', '.ogg', '.aac', '.m4a'}\n",
                "\n",
                "\n",
                "def scan_audio_files(directory: str) -> List[Path]:\n",
                "    \"\"\"Recursively find all supported audio files in directory.\"\"\"\n",
                "    root = Path(directory)\n",
                "    files = [p for p in root.rglob('*') if p.suffix.lower() in SUPPORTED_EXTS]\n",
                "    files.sort(key=lambda p: p.name.lower())\n",
                "    return files\n",
                "\n",
                "\n",
                "def analyse_track(path: Path) -> Optional[Dict]:\n",
                "    \"\"\"\n",
                "    Full neural analysis of a single audio file.\n",
                "    Returns a dict with keys: path, name, camelot, bpm, embedding.\n",
                "    Returns None on error.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Load at 22050 Hz mono (read-only)\n",
                "        y, sr = librosa.load(str(path), sr=22050, mono=True)\n",
                "\n",
                "        camelot = detect_key_cqt(y, sr)\n",
                "        bpm     = detect_bpm(y, sr)\n",
                "        emb     = get_clap_embedding(str(path))\n",
                "\n",
                "        return {\n",
                "            'path':      path,\n",
                "            'name':      path.stem,\n",
                "            'ext':       path.suffix,\n",
                "            'camelot':   camelot,\n",
                "            'bpm':       bpm,\n",
                "            'embedding': emb,\n",
                "        }\n",
                "    except Exception as e:\n",
                "        print(f'  âš ï¸  Error analysing {path.name}: {e}')\n",
                "        return None\n",
                "\n",
                "\n",
                "def run_batch_analysis(input_dir: str, batch_size: int = 4) -> List[Dict]:\n",
                "    \"\"\"\n",
                "    Analyse all audio files in input_dir in batches.\n",
                "    Returns a list of track metadata dicts.\n",
                "    batch_size: number of tracks to process per VRAM flush.\n",
                "    \"\"\"\n",
                "    files = scan_audio_files(input_dir)\n",
                "    if not files:\n",
                "        raise ValueError(f'No supported audio files found in {input_dir}')\n",
                "\n",
                "    print(f'\\nğŸ” Found {len(files)} audio file(s) in {input_dir}')\n",
                "    print(f'   Batch size: {batch_size} | Device: {DEVICE}\\n')\n",
                "\n",
                "    results = []\n",
                "    for i in tqdm(range(0, len(files), batch_size), desc='Analysing tracks'):\n",
                "        batch = files[i:i + batch_size]\n",
                "        for path in batch:\n",
                "            tqdm.write(f'  â†’ {path.name}')\n",
                "            track = analyse_track(path)\n",
                "            if track is not None:\n",
                "                results.append(track)\n",
                "\n",
                "        # Clear VRAM cache between batches\n",
                "        if DEVICE.type == 'cuda':\n",
                "            torch.cuda.empty_cache()\n",
                "\n",
                "    print(f'\\nâœ… Analysis complete: {len(results)}/{len(files)} tracks processed successfully.')\n",
                "    return results\n",
                "\n",
                "\n",
                "print('âœ… Batch analysis pipeline ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-07-clustering",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 7 â€” KMeans Semantic Clustering\n",
                "# ============================================================\n",
                "# Groups tracks by their Music-CLAP embeddings into N_CLUSTERS vibes.\n",
                "\n",
                "\n",
                "def cluster_tracks(tracks: List[Dict], n_clusters: int) -> Dict[int, List[Dict]]:\n",
                "    \"\"\"\n",
                "    Apply KMeans clustering to CLAP embedding vectors.\n",
                "    Returns a dict mapping cluster_id -> list of track dicts.\n",
                "\n",
                "    If n_clusters > number of tracks, falls back to 1 cluster.\n",
                "    \"\"\"\n",
                "    if not tracks:\n",
                "        return {}\n",
                "\n",
                "    n_clusters = min(n_clusters, len(tracks))\n",
                "    embeddings = np.stack([t['embedding'] for t in tracks])  # (N, 512)\n",
                "\n",
                "    print(f'\\nğŸ”€ Running KMeans clustering:')\n",
                "    print(f'   Tracks     : {len(tracks)}')\n",
                "    print(f'   Clusters   : {n_clusters}')\n",
                "    print(f'   Embedding  : {embeddings.shape}')\n",
                "\n",
                "    km = KMeans(\n",
                "        n_clusters=n_clusters,\n",
                "        n_init=20,\n",
                "        max_iter=500,\n",
                "        random_state=42,\n",
                "    )\n",
                "    labels = km.fit_predict(embeddings)\n",
                "\n",
                "    clusters: Dict[int, List[Dict]] = {i: [] for i in range(n_clusters)}\n",
                "    for track, label in zip(tracks, labels):\n",
                "        track['cluster'] = int(label)\n",
                "        clusters[int(label)].append(track)\n",
                "\n",
                "    # Print summary\n",
                "    print(f'\\n   Cluster sizes:')\n",
                "    for cid, members in sorted(clusters.items()):\n",
                "        print(f'   Cluster {cid + 1:02d}: {len(members):3d} tracks')\n",
                "\n",
                "    return clusters\n",
                "\n",
                "\n",
                "print('âœ… Clustering module ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-08-sequencer",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 8 â€” Harmonic Sequencer (Camelot + BPM Ascending Flow)\n",
                "# ============================================================\n",
                "\n",
                "\n",
                "def build_harmonic_sequence(tracks: List[Dict]) -> List[Dict]:\n",
                "    \"\"\"\n",
                "    Arrange tracks within a cluster into a DJ-ready harmonic sequence:\n",
                "\n",
                "    Algorithm:\n",
                "    1.  Sort all tracks by BPM ascending as the base order.\n",
                "    2.  Start from the lowest-BPM track.\n",
                "    3.  Greedily pick the next track using get_next_harmonic() from the\n",
                "        remaining pool â€” prioritising harmonic compatibility first,\n",
                "        then ascending BPM.\n",
                "    4.  If no harmonic match exists, pick the next unvisited track by BPM\n",
                "        (graceful fallback â€” marked with a warning flag).\n",
                "\n",
                "    Returns the ordered list of track dicts with a 'harmonic_ok' boolean.\n",
                "    \"\"\"\n",
                "    if not tracks:\n",
                "        return []\n",
                "\n",
                "    pool = sorted(tracks, key=lambda t: t.get('bpm', 0))\n",
                "    sequence: List[Dict] = []\n",
                "    current_camelot = pool[0]['camelot']\n",
                "\n",
                "    while pool:\n",
                "        nxt = get_next_harmonic(current_camelot, pool)\n",
                "        if nxt is not None:\n",
                "            nxt['harmonic_ok'] = True\n",
                "        else:\n",
                "            # Graceful fallback: take lowest-BPM remaining\n",
                "            nxt = pool[0]\n",
                "            nxt['harmonic_ok'] = False\n",
                "\n",
                "        sequence.append(nxt)\n",
                "        current_camelot = nxt['camelot']\n",
                "        pool.remove(nxt)\n",
                "\n",
                "    return sequence\n",
                "\n",
                "\n",
                "def sequence_all_clusters(clusters: Dict[int, List[Dict]]) -> Dict[int, List[Dict]]:\n",
                "    \"\"\"Apply harmonic sequencing to every cluster.\"\"\"\n",
                "    sequenced = {}\n",
                "    for cid, tracks in clusters.items():\n",
                "        sequenced[cid] = build_harmonic_sequence(tracks)\n",
                "        fallbacks = sum(1 for t in sequenced[cid] if not t.get('harmonic_ok', True))\n",
                "        print(f'  Cluster {cid + 1:02d}: {len(tracks):3d} tracks sequenced '\n",
                "              f'| {fallbacks} BPM-only fallbacks')\n",
                "    return sequenced\n",
                "\n",
                "\n",
                "print('âœ… Harmonic sequencer ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-09-export",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 9 â€” Export: Rename, Copy & ZIP\n",
                "# ============================================================\n",
                "\n",
                "\n",
                "def _sanitize(name: str) -> str:\n",
                "    \"\"\"Remove filesystem-unsafe characters from a filename.\"\"\"\n",
                "    return re.sub(r'[\\\\/:*?\"<>|]', '_', name)\n",
                "\n",
                "\n",
                "def export_results(\n",
                "    sequenced_clusters: Dict[int, List[Dict]],\n",
                "    out_dir: str,\n",
                "    zip_name: str = 'spectral_affinity_results.zip',\n",
                ") -> str:\n",
                "    \"\"\"\n",
                "    Copy and rename each track into structured output folders:\n",
                "\n",
                "    out_dir/\n",
                "      cluster_01_vibe/\n",
                "        01 - [08A] 120BPM TrackName.wav\n",
                "        02 - [09A] 122BPM TrackName.wav\n",
                "        ...\n",
                "      cluster_02_vibe/\n",
                "        ...\n",
                "      spectral_affinity_results.zip\n",
                "\n",
                "    Returns the path to the generated ZIP file.\n",
                "    Audio originals are NEVER modified â€” only copied.\n",
                "    \"\"\"\n",
                "    out_root = Path(out_dir)\n",
                "    out_root.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    cluster_dirs = []\n",
                "\n",
                "    for cid, tracks in sorted(sequenced_clusters.items()):\n",
                "        # Named folder: cluster_01_vibe, cluster_02_vibe...\n",
                "        folder_name = f'cluster_{cid + 1:02d}_vibe'\n",
                "        cluster_dir = out_root / folder_name\n",
                "        cluster_dir.mkdir(parents=True, exist_ok=True)\n",
                "        cluster_dirs.append(cluster_dir)\n",
                "\n",
                "        print(f'\\nğŸ“‚ {folder_name} ({len(tracks)} tracks)')\n",
                "\n",
                "        for idx, track in enumerate(tracks, start=1):\n",
                "            camelot = track.get('camelot', '??')\n",
                "            bpm     = int(round(track.get('bpm', 0)))\n",
                "            orig    = _sanitize(track['name'])\n",
                "            ext     = track['ext']\n",
                "            flag    = '' if track.get('harmonic_ok', True) else ' âš ï¸'\n",
                "\n",
                "            new_name = f'{idx:02d} - [{camelot}] {bpm}BPM {orig}{ext}'\n",
                "            dst      = cluster_dir / new_name\n",
                "\n",
                "            shutil.copy2(str(track['path']), str(dst))  # preserves timestamps\n",
                "            print(f'  {idx:02d}  [{camelot}] {bpm} BPM  {orig}{ext}{flag}')\n",
                "\n",
                "    # â”€â”€ Pack into a single ZIP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "    zip_path = out_root / zip_name\n",
                "    print(f'\\nğŸ“¦ Packaging ZIP â†’ {zip_path}')\n",
                "\n",
                "    with zipfile.ZipFile(str(zip_path), 'w', zipfile.ZIP_STORED) as zf:\n",
                "        for cdir in cluster_dirs:\n",
                "            for f in sorted(cdir.iterdir()):\n",
                "                arcname = f'{cdir.name}/{f.name}'\n",
                "                zf.write(str(f), arcname)\n",
                "\n",
                "    zip_size_mb = zip_path.stat().st_size / 1e6\n",
                "    print(f'âœ… ZIP created: {zip_path.name}  ({zip_size_mb:.1f} MB)')\n",
                "\n",
                "    return str(zip_path)\n",
                "\n",
                "\n",
                "print('âœ… Export module ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-10-main",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 10 â€” âš™ï¸ CONFIGURATION & MAIN EXECUTION\n",
                "# ============================================================\n",
                "# ğŸ‘‡ Edit ONLY the variables in this block.\n",
                "# Everything else runs automatically.\n",
                "\n",
                "# â”€â”€â”€ USER CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "INPUT_DIR  = '/kaggle/input/datasets/danieldobles/slavic-songs'\n",
                "OUT_DIR    = '/kaggle/working/HARMONIC_RESULTS'\n",
                "\n",
                "# Number of semantic clusters (vibes).\n",
                "# Rule of thumb: 1 cluster per ~20-30 tracks, or set manually.\n",
                "N_CLUSTERS = 6\n",
                "\n",
                "# Tracks processed per GPU memory flush\n",
                "# Reduce to 2 if you hit CUDA OOM; increase to 8 on A100.\n",
                "BATCH_SIZE = 4\n",
                "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "\n",
                "\n",
                "def main():\n",
                "    print('=' * 64)\n",
                "    print('  ğŸŒŒ Spectral Affinity v3.0 â€” Music-CLAP Edition')\n",
                "    print('=' * 64)\n",
                "    print(f'  INPUT  : {INPUT_DIR}')\n",
                "    print(f'  OUTPUT : {OUT_DIR}')\n",
                "    print(f'  CLUSTERS: {N_CLUSTERS}  |  BATCH: {BATCH_SIZE}')\n",
                "    print('=' * 64)\n",
                "\n",
                "    # â”€â”€ STEP 1: Deep neural analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "    print('\\nâœ¨ STEP 1/3  Neural Analysis (Key + BPM + CLAP embeddings)')\n",
                "    tracks = run_batch_analysis(INPUT_DIR, batch_size=BATCH_SIZE)\n",
                "\n",
                "    if not tracks:\n",
                "        print('ğŸš« No tracks analysed. Check INPUT_DIR path and audio formats.')\n",
                "        return\n",
                "\n",
                "    # Print analysis summary table\n",
                "    print('\\n  Track Metadata Summary:')\n",
                "    print(f'  {\"#\":<4} {\"File\":<45} {\"Key\":>5} {\"BPM\":>6}')\n",
                "    print(f'  {\"-\"*4} {\"-\"*45} {\"-\"*5} {\"-\"*6}')\n",
                "    for i, t in enumerate(tracks, 1):\n",
                "        name_short = t['name'][:44] + (\"â€¦\" if len(t['name']) > 44 else \"\")\n",
                "        print(f'  {i:<4} {name_short:<45} {t[\"camelot\"]:>5} {t[\"bpm\"]:>6.1f}')\n",
                "\n",
                "    # â”€â”€ STEP 2: Semantic clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "    print('\\nâœ¨ STEP 2/3  Semantic Clustering (KMeans on CLAP Space)')\n",
                "    clusters = cluster_tracks(tracks, n_clusters=N_CLUSTERS)\n",
                "\n",
                "    # â”€â”€ STEP 3: Harmonic sequencing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "    print('\\nâœ¨ STEP 3/3  Harmonic Sequencing (Camelot Wheel + BPM Flow)')\n",
                "    sequenced = sequence_all_clusters(clusters)\n",
                "\n",
                "    # â”€â”€ EXPORT: Copy, rename, ZIP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                "    print('\\nğŸ“¦ Exporting results...')\n",
                "    zip_path = export_results(sequenced, out_dir=OUT_DIR)\n",
                "\n",
                "    print('\\n' + '=' * 64)\n",
                "    print('  âœ… Spectral Affinity v3.0 complete!')\n",
                "    print(f'  ğŸ“‚ Results: {OUT_DIR}')\n",
                "    print(f'  ğŸ“¦ ZIP    : {zip_path}')\n",
                "    print('  ğŸ§ Your harmonic playlists are ready to download.')\n",
                "    print('=' * 64)\n",
                "\n",
                "    # Kaggle notebook: trigger file download panel\n",
                "    try:\n",
                "        from IPython.display import FileLink, display\n",
                "        display(FileLink(zip_path.replace(\"/kaggle/working/\", \"\")))\n",
                "    except Exception:\n",
                "        pass\n",
                "\n",
                "\n",
                "# Run!\n",
                "main()"
            ]
        }
    ]
}